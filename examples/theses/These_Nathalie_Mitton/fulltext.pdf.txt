AUTO-ORGANISATION DES RESEAUX SANS FIL
MULTI-SAUTS A GRANDE ECHELLE.
Nathalie Mitton
To cite this version:
Nathalie Mitton. AUTO-ORGANISATION DES RESEAUX SANS FIL MULTI-SAUTS A
GRANDE ECHELLE.. Computer Science. INSA de Lyon, 2006. French. <tel-00599147>
HAL Id: tel-00599147
https://tel.archives-ouvertes.fr/tel-00599147
Submitted on 8 Jun 2011
HAL is a multi-disciplinary open access L’archive ouverte pluridisciplinaire HAL, est
archive for the deposit and dissemination of sci- destine´e au de´poˆt et a` la diffusion de documents
entific research documents, whether they are pub- scientifiques de niveau recherche, publie´s ou non,
lished or not. The documents may come from e´manant des e´tablissements d’enseignement et de
teaching and research institutions in France or recherche franc¸ais ou e´trangers, des laboratoires
abroad, or from public or private research centers. publics ou prive´s.
Me´moire
pre´sente´ par
Nathalie MITTON
en vue de l’obtention du diploˆme
DOCTORAT EN INFORMATIQUE ET
RESEAUX
de l’INSA de Lyon
AUTO-ORGANISATION DES RE´ SEAUX
SANS FIL MULTI-SAUTS A` GRANDE
E´ CHELLE.
Soutenue le 27/03/2006.
Nume´ro d’ordre : 2006-ISAL-0023.
Apre`s avis de : Franc¸ois BACCELLI
Catherine ROSENBERG
David SIMPLOT-RYL
Devant la commission d’examen forme´e de :
Bartlomiej (Bartek) BLASZCZYSZYN
Charge´ de recherche a` l’INRIA - TREC
Serge FDIDA
Professeur a` l’Universite´ Pierre et Marie Curie – Paris VI
E´ ric FLEURY (Directeur de the`se)
Professeur a` l’INSA de LYON
Isabelle GUE´ RIN LASSOUS (Directrice de the`se)
Charge´e de recherche habilite´e a` l’INRIA - ARES
David SIMPLOT-RYL (Rapporteur)
Professeur a` l’Universite´ de Lille
pour les travaux effectue´s au Centre d’Innovations en Te´le´communications & Inte´gration
de services de l’INSA de Lyon (CITI) sous la direction du Pr. E´ ric Fleury et du Dr. Isabelle
Gue´rin-Lassous.
Table des matie`res
1 Introduction 7
1.1 Me´thodologies et notations . . . . . . . . . . . . . . . . . . . . . . . 10
1.1.1 Mode`le utilise´ dans les analyses stochastiques . . . . . . . . . 10
1.1.2 Mode`le de simulation . . . . . . . . . . . . . . . . . . . . . . 11
2 E´ tat de l’art 13
2.1 Clusters a` 1 saut . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
2.2 Clusters a` k sauts . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
2.3 Clusters hie´rarchiques . . . . . . . . . . . . . . . . . . . . . . . . . . 21
2.4 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
3 Algorithme de clustering 23
3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
3.2 La me´trique de densite´ . . . . . . . . . . . . . . . . . . . . . . . . . 24
3.3 La formation des clusters . . . . . . . . . . . . . . . . . . . . . . . . 24
3.4 Maintenance de la structure . . . . . . . . . . . . . . . . . . . . . . . 28
3.5 Analyse de la me´trique . . . . . . . . . . . . . . . . . . . . . . . . . 28
3.5.1 Recherche de la meilleure k-densite´ . . . . . . . . . . . . . . 28
3.5.2 Densite´ moyenne . . . . . . . . . . . . . . . . . . . . . . . . 29
3.5.3 Re´partition des valeurs de densite´ . . . . . . . . . . . . . . . 31
3.6 Analyse de la structure . . . . . . . . . . . . . . . . . . . . . . . . . 31
3.6.1 Analyse the´orique du nombre de clusters . . . . . . . . . . . 31
3.6.2 Caracte´ristiques des clusters . . . . . . . . . . . . . . . . . . 33
3
4 TABLE DES MATIE`RES
3.7 Comparaison a` d’autres heuristiques . . . . . . . . . . . . . . . . . . 36
3.7.1 Comparaison avec DDR . . . . . . . . . . . . . . . . . . . . 36
3.7.2 Comparaison avec l’heuristique Max-Min d-cluster . . . . . . 39
3.8 Analyse de l’auto-stabilisation . . . . . . . . . . . . . . . . . . . . . 42
3.8.1 Pre´-requis . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43
3.8.2 Construction d’un DAG de hauteur constante . . . . . . . . . 44
3.8.3 Analyse de la construction du DAG de couleurs . . . . . . . . 45
3.8.4 Utilisation des couleurs pour le clustering . . . . . . . . . . . 48
3.8.5 Validation des proprie´te´s auto-stabilisantes . . . . . . . . . . 50
3.9 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52
3.10 Publications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53
3.11 Annexes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54
3.11.1 Analyse de la densite´ moyenne . . . . . . . . . . . . . . . . . 54
3.11.2 Calcul analytique du nombre de clusters . . . . . . . . . . . . 56
3.11.3 Temps de transmission borne´ . . . . . . . . . . . . . . . . . . 58
4 Diffusion 61
4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61
4.2 E´ tat de l’art . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62
4.3 Analyse the´orique . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64
4.4 Notre contribution a` la diffusion . . . . . . . . . . . . . . . . . . . . 66
4.4.1 Se´lection des passerelles . . . . . . . . . . . . . . . . . . . . 66
4.4.2 L’algorithme de diffusion . . . . . . . . . . . . . . . . . . . . 71
4.5 Analyses et re´sultats de simulations . . . . . . . . . . . . . . . . . . 72
4.5.1 E´ lection et utilisation des passerelles . . . . . . . . . . . . . . 72
4.5.2 Performances de la diffusion . . . . . . . . . . . . . . . . . . 74
4.5.3 Robustesse de la diffusion . . . . . . . . . . . . . . . . . . . 79
4.6 Analyse de la se´lection des MPR dans OLSR . . . . . . . . . . . . . 82
4.6.1 La se´lection des MPR . . . . . . . . . . . . . . . . . . . . . 82
4.6.2 Analyse . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84
4.6.3 Re´sultats nume´riques et simulations . . . . . . . . . . . . . . 88
4.6.4 Conse´quences . . . . . . . . . . . . . . . . . . . . . . . . . . 90
4.7 Conclusion et perspectives . . . . . . . . . . . . . . . . . . . . . . . 91
4.8 Publications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92
4.9 Annexes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93
TABLE DES MATIE`RES 5
5 Localisation et routage 97
5.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97
5.2 Localisation et routage . . . . . . . . . . . . . . . . . . . . . . . . . 100
5.2.1 Re´sume´ et analyse de complexite´ . . . . . . . . . . . . . . . 101
5.3 Notre proposition . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102
5.3.1 Pre´liminaires . . . . . . . . . . . . . . . . . . . . . . . . . . 102
5.3.2 Distribution des partitions de l’espace virtuel - ILS . . . . . . 103
5.3.3 Enregistrement . . . . . . . . . . . . . . . . . . . . . . . . . 104
5.3.4 De´parts et arrive´es . . . . . . . . . . . . . . . . . . . . . . . 104
5.3.5 Ajouter de la redondance et de la robustesse . . . . . . . . . . 106
5.3.6 Ope´ration de look-up . . . . . . . . . . . . . . . . . . . . . . 106
5.3.7 Routage sur le re´seau physique . . . . . . . . . . . . . . . . . 112
5.4 Simulations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114
5.4.1 SAFARI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114
5.4.2 Comparaison des structures . . . . . . . . . . . . . . . . . . 116
5.4.3 Look-up et routage . . . . . . . . . . . . . . . . . . . . . . . 118
5.5 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122
5.6 Publications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124
6 Conclusion et perspectives 125
6.1 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125
6.2 Perspectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126
6 TABLE DES MATIE`RES
Chapitre 1
Introduction
De nos jours, les gens se de´placent et communiquent de plus en plus. Ils ont de´sormais
besoin de nouvelles technologies leur permettant de fac¸on simple et rapide de re´cupe´rer
diverses informations et de communiquer avec des personnes distantes pouvant eˆtre
n’importe ou` dans le monde. Ces dernie`res anne´es ont vu le de´veloppement technolo-
gique de nombreux composants et appareils e´lectroniques de toute sorte pour re´pondre
a` ces nouveaux besoins. Ces appareils communicants sont de plus en plus petits, ont
des capacite´s de calcul de plus en plus performantes et sont de plus en plus re´pandus.
On les rencontre partout dans notre quotidien : a` la maison, au bureau, dans les voi-
tures, etc. Les acce`s a` l’information deviennent omnipre´sents a` travers les te´le´phones
portables, ordinateurs portables, PDA et les technologies de communications sans fil.
Cependant, l’apparition et l’expansion de ces phe´nome`nes ont e´galement conduit a`
une explosion de la complexite´ a` tout niveau, a` un point de´passant les capacite´s hu-
maines a` controˆler et se´curiser. L’intervention humaine doit eˆtre remplace´e par une
auto-gestion du syste`me par les machines. C’est ce qu’on appelle l’autonomic compu-
ting. Afin d’assurer l’ubiquite´ des informations, les entite´s technologiques doivent eˆtre
mises en re´seau et eˆtre capables de re´pondre aux de´fis suivants :
Auto-configuration et auto-organisation. Chaque entite´ doit eˆtre capable de se
configurer elle-meˆme a` partir d’interactions locales avec les autres entite´s afin
de faire e´merger un comportement global qui assure le bon fonctionnement
du re´seau. Elle doit s’adapter aux modifications de la topologie du re´seau. Par
exemple, les entite´s doivent eˆtre capables d’e´tablir des routes pour joindre les
personnes souhaite´es ou acce´der a` une information donne´e.
Auto-gue´rison. Lorsqu’une panne se produit, le re´seau doit eˆtre capable de la loca-
liser, de l’identifier et de l’isoler afin qu’elle ne contamine pas l’ensemble du
re´seau, et si possible de la corriger.
Auto-optimisation. Chaque entite´ doit pre´server les ressources globales du re´seau afin
de lui assurer une dure´e de vie aussi longue que possible, tout en effectuant
correctement les taˆches qui lui sont alloue´es.
7
8 CHAPITRE 1. INTRODUCTION
Auto-protection. Le re´seau doit eˆtre capable d’apprendre de ses fautes et des at-
taques exte´rieures qui surviennent. Il doit pouvoir les identifier rapidement et
se prote´ger contre elles.
Tous ces de´fis doivent pouvoir eˆtre adresse´s en tenant compte des contraintes
intrinse`ques des entite´s technologiques et des technologies de communication.
L’autonomic computing couvre ainsi un tre`s large domaine des re´seaux informatiques,
tous pre´sentant des contraintes supple´mentaires spe´cifiques. Au sein de ce large spectre
que repre´sente l’autonomic computing et qui repre´sente un re´el de´fi scientifique pour
les anne´es a` venir, je me suis oriente´e lors de ma the`se vers le domaine des re´seaux
sans fil tels que les re´seaux ad hoc ou les re´seaux de capteurs, qui offre l’avantage
d’eˆtre plus cible´ en termes d’applications, tout en englobant un grand nombre des de´fis
scientifiques pre´sente´s ci dessus.
Les re´seaux sans fil multi-sauts sont des re´seaux radio mobiles sans aucune infrastruc-
ture, ce qui leur permet une implantation rapide. Ils peuvent aussi eˆtre couple´s a` un
LAN pour e´tendre la couverture d’une infrastructure existante. Les entite´s peuvent
apparaıˆtre, disparaıˆtre, se de´placer inde´pendamment les unes des autres. La topolo-
gie du re´seau est e´volutive. Les terminaux peuvent communiquer dans la limite de
la porte´e de leur communication radio. Un sche´ma de communication multi-sauts est
ne´cessaire pour permettre a` deux correspondants distants de communiquer. Dans ce
sche´ma de communication, chaque terminal peut eˆtre utilise´ comme routeur pour re-
layer les communications d’autres terminaux. La configuration de ces routes multi-
sauts est re´alise´e par un protocole de routage. Afin d’eˆtre efficaces, ces protocoles
de routage doivent conside´rer les caracte´ristiques intrinse`ques du re´seau (topologie en
constante e´volution), des terminaux (taille me´moire et capacite´s de calcul limite´es...)
et du me´dium de communication (bande passante limite´e, interfe´rences...).
Il existe aujourd’hui de nombreux protocoles de routage pour de tels re´seaux. Cepen-
dant, bien qu’efficaces sur des re´seaux peu denses ou de petite ou moyenne taille, aucun
d’eux ne peut eˆtre utilise´ sur de grandes e´chelles car ils ge´ne´reraient trop de trafic de
controˆle ou ne´cessiteraient des tables de routage trop importantes. L’une des solutions
commune´ment propose´es pour le routage sur de grandes e´chelles est d’introduire un
routage hie´rarchique en regroupant ge´ographiquement des entite´s proches en clusters
et en utilisant des sche´mas de routage diffe´rents au sein des clusters et entre les clus-
ters. Une telle approche permet a` chaque entite´ de stocker la totalite´ des informations
de son cluster et seulement une partie des informations concernant les autres clusters
et de cette fac¸on, permet une extensibilite´ du re´seau.
Dans ce document, je pre´sente une solution d’utilisation de re´seau sans fil multi-sauts
dense. Ce document est organise´ suivant les diffe´rentes e´tapes de cette solution : or-
ganisation du re´seau, diffusion, localisation et routage. A` chaque e´tape, les re´sultats
obtenus ont e´te´ analyse´s par simulation, par des e´tudes comparatives avec des solu-
tions existantes et, lorsque cela e´tait possible par une analyse the´orique. Le premier
chapitre est la pre´sente introduction, dans laquelle je pre´sente les notations utilise´es au
cours du document et les mode`les utilise´s pour les e´tudes analytiques et les simula-
tions. Dans le chapitre 2, les diffe´rentes approches propose´es dans la litte´rature pour
organiser un re´seau en clusters sont pre´sente´es. Seules les me´thodes qui proposent une
9organisation du re´seau sont mentionne´es. Il existe e´galement de nombreuses e´tudes sur
l’apport de cette organisation sur la capacite´ du re´seau comme c’est le cas de [37] mais
cet aspect n’est pas l’objet de cette the`se et ces e´tudes ne sont donc pas pre´sente´es dans
ce chapitre.
Le chapitre 3 de´crit notre solution de clustering et en e´tudie les diffe´rentes ca-
racte´ristiques. L’algorithme de clustering se base sur une nouvelle me´trique qui permet
de lisser des petits changements de topologie. Les clusters sont construits en s’adap-
tant a` la topologie sous-jacente, sans contrainte ni parame`tre fixe´ a priori. Une analyse
the´orique permet de de´gager certaines proprie´te´s comme une borne supe´rieure sur le
nombre de clusters obtenus sur une surface donne´e. Des simulations de´gagent des ca-
racte´ristiques de la structure obtenue et comparent ses performances aux structures
obtenues a` partir d’autres protocoles de clustering existants. Il en ressort que notre
algorithme construit des clusters qui offrent le meilleur comportement face a` la dy-
namicite´ des entite´s du re´seau. Dans ce chapitre, nous montrons e´galement que notre
algorithme est auto-stabilisant localement, ce qui lui confe`re de bonnes proprie´te´s pour
le passage a` l’e´chelle et la re´sistance aux fautes.
A` partir des caracte´ristiques de´gage´es de la structure de clusters, nous proposons deux
grandes applications indispensables a` tout re´seau : une diffusion efficace d’information
et un processus de routage. Nous construisons donc une seule structure pour diverses
applications. Le processus de diffusion est pre´sente´ et e´tudie´ dans le chapitre 4. Ce
protocole de diffusion a pour avantage d’avoir deux de´clinaisons : il peut permettre une
diffusion globale a` l’ensemble du re´seau et/ou une diffusion limite´e au sein d’un cluster.
Il ne demande que peu d’e´changes et de calculs. La diffusion ainsi ge´ne´re´e s’ave`re
solliciter moins d’entite´s que les protocoles de diffusion existants et donc consomme
moins d’e´nergie, tout en e´tant plus robuste face a` des cassures de liens.
Le chapitre 5 aborde le processus de routage hie´rarchique applique´ a` la structure. Il
s’agit d’un protocole de routage indirect (c.a`.d. effectue´ en deux temps) qui pre´sente
une approche originale, en conside´rant le sche´ma inverse de celui ge´ne´ralement utilise´
dans la litte´rature. En effet, les caracte´ristiques des clusters ont montre´ qu’un sche´ma
classique pre´senterait les meˆmes proble`mes d’extensibilite´ rencontre´s dans un re´seau a`
plat, comme nous le verrons. Ce processus de routage inte`gre un processus de locali-
sation base´ sur les tables de hachage distribue´es et sur la mise en œuvre d’un routage
adapte´ aux re´seaux sans fil, comme le routage par intervalle. Le protocole de rou-
tage fournit des routes proches de l’optimal tout en maintenant O(1) informations sur
chaque entite´.
Le dernier chapitre conclut ce document et donne plusieurs perspectives a` l’ensemble
des travaux mene´s au cours de cette the`se. Ce travail a e´te´ re´alise´ dans le cadre de ma
the`se effectue´e au sein du laboratoire CITI de l’INSA de Lyon et de l’e´quipe INRIA
ARES, sous la direction d’E´ ric FLEURY et d’Isabelle GUE´RIN LASSOUS.
10 CHAPITRE 1. INTRODUCTION
1.1 Me´thodologies et notations adopte´es au cours de la
the`se
Un re´seau sans fil multi-sauts peut eˆtre mode´lise´ par un graphe G = (V,E) ou` V
repre´sente l’ensemble des terminaux mobiles etE repre´sente les liaisons radios existant
entre ces stations. Dans notre approche, nous n’avons conside´re´ que des liens radios bi-
directionnels, c.a`.d qu’un lien e = (u, v) existe si les stations u et v sont a` porte´e de
communication radio l’une de l’autre.
Nous notons dist(u, v) la distance euclidienne de u a` v et d(u, v) la distance dans
le graphe (en nombre de sauts) entre les nœuds u et v. Cette distance correspond au
nombre de sauts minimum que l’on doit faire pour rejoindre v depuis u. Nous notons
Γk(u) le k-voisinage (ou le voisinage a` k sauts) du nœud u. Le k-voisinage d’un nœud
est l’ensemble des nœuds a` k sauts de lui : Γk(u) = {v 6= u | d(u, v) ≤ k}. Nous
notons δk(u) = |Γk(u)| la cardinalite´ de cet ensemble. On note ge´ne´ralement Γ(u)
pour Γ1(u). On remarquera que u n’appartient pas Γk(u) (∀k > 0, u ∈/ Γk(u)). Par
de´finition, δ1(u) = δ(u) = |Γ1(u)| est le degre´ du nœud u.
Nous de´signons par C(u) le cluster auquel appartient le nœud u et H(u) son cluster-
head.
Nous utilisons e(u/C) pour de´noter l’excentricite´ du nœud u dans un cluster C. L’ex-
centricite´ d’un nœud est la plus grande distance entre u et tout autre nœud du meˆme
cluster C : e(u/C) = maxv∈C(u)(d(u, v)). Le diame`tre d’un cluster C, note´ D(C), est
la plus grande excentricite´ dans ce cluster : D(C) = maxu∈C(e(u/C)).
1.1.1 Mode`le utilise´ dans les analyses stochastiques
Lors des diffe´rentes analyses the´oriques que nous avons mene´es, nous repre´sentons un
re´seau sans fil multi-sauts par un processus ponctuel de Poisson d’intensite´ constante
λ.
Un processus de Poisson est un processus ponctuel pour lequel la disposition des points
est comple`tement ale´atoire a` chaque re´alisation. L’une des proprie´te´s caracte´risant le
processus de Poisson est que le nombre de points dans une zone donne´e est inde´pendant
des autres points du processus. Le processus de Poisson est le processus repre´sentant
le mieux la distribution des nœuds du re´seau dans l’espace. Dans cette the`se, nous
n’avons conside´re´ que des processus de Poisson homoge`ne (intensite´ constante dans le
plan) et isotrope (proprie´te´s invariantes par rotation).
Pour simuler une re´alisation d’un processus de Poisson homoge`ne d’intensite´ λ dans
un carre´ de surface S, on de´finit d’abord le nombre de points N du semis en tirant un
nombre pseudo-ale´atoire dans une loi de Poisson de parame`tre λ × S. Le nombre de
λkpoints N prend les valeurs k avec la probabilite´ suivante : P(N = k) = k! exp(−λS).
λ repre´sente alors le nombre moyen de nœuds par unite´ de surface. Pour chaque point
i, l’abscisse xi et l’ordonne´e yi sont ensuite de´finies par un nombre pseudo-ale´atoire
tire´ dans une loi uniforme.
1.1. ME´THODOLOGIES ET NOTATIONS 11
Si Φ est le processus de Poisson conside´re´, on de´signe par Φ(S) l’ensemble des points
du processus Φ distribue´s dans la surface S. Nous conside´rons qu’il existe un lien entre
deux points du processus u et v si dist(u, v) ≤ R ou` R est la porte´e de communication
radio des nœuds (u et v sont voisins).
1.1.2 Mode`le de simulation
1+2R
1
           
           
           
           
           
w
           
           
           
            W
           
           
           
FIG. 1.1 – Seuls les nœuds de w sont conside´re´s pour les mesures simule´es mais le
processus de point est distribue´ dans W afin d’e´liminer les effets de bord.
Toutes les simulations mene´es lors de cette the`se suivent le meˆme mode`le. Nous avons
utilise´ un simulateur que nous avons de´veloppe´. Ce simulateur suppose une couche
MAC ide´ale, c.a`.d qui ne ge´ne`re aucune collision. Utiliser ce simulateur plutoˆt qu’un
simulateur re´seau qui prend en compte les collisions et caracte´ristiques des protocoles
de niveaux infe´rieurs nous permet de focaliser notre e´tude sur le comportement des
protocoles de niveau 3 uniquement, sans tenir compte des ale´as des protocoles utilise´s
au niveau des autres couches.
Les nœuds sont de´ploye´s ale´atoirement suivant un processus de Poisson dans une
feneˆtre carre´e de (1 + 2R) × (1 + 2R) avec diffe´rentes intensite´s λ. On conside`re
que deux nœuds u et v sont voisins si dist(u, v) ≤ R ou` R est la porte´e de communi-
cation radio des nœuds. Dans chaque cas, chaque statistique est la moyenne sur plus de
1000 simulations. Les mesures ne sont prises en compte que si l’ensemble des nœuds
forment une composante connexe (aucune entite´ n’est isole´e dans le re´seau).
De fac¸on a` e´liminer les effets de bords de cette feneˆtre, les diffe´rentes mesures ne sont
calcule´es que sur les nœuds se trouvant dans une feneˆtre centralew de taille 1×1 (voir
Figure 1.1), l’ensemble des points du processus e´tant distribue´s dans la feneˆtreW et les
points de w restant impacte´s par les points en dehors de w. Cette technique est appele´e
”minus-sampling”. Pour une description plus de´taille´e, se re´fe´rer a` [76] page 132.
12 CHAPITRE 1. INTRODUCTION
Chapitre 2
E´ tat de l’art
Un re´seau ad hoc ne repose sur aucune infrastructure fixe. Les entite´s sont
inde´pendantes les unes des autres et communiquent entre elles par radio, sans utiliser
de station de base. Afin de permettre des communications entre deux stations n’e´tant
pas a` porte´e radio l’une de l’autre, les nœuds interme´diaires doivent relayer le message.
Afin que le relais des messages soit efficace, il faut e´tablir des routes entre les nœuds,
de fac¸on a` ce que chaque entite´ sache vers quelle autre station envoyer le message pour
qu’il puisse atteindre sa destination. C’est le roˆle principal des protocoles de routage.
Les protocoles de routage classiques standardise´s au sein du groupe de travail MANET
(Mobile Ad hoc NETwork) de l IETF1’ se montrent efficaces sur des re´seaux de petite
ou moyenne taille mais passent difficilement a` l’e´chelle [46, 71].
Il existe classiquement deux grandes familles de protocoles de routage dans la
litte´rature et au sein du groupe MANET :
– pro-actif : les routes sont e´tablies et maintenues en permanence sur chaque nœud.
L’avantage d’un tel processus est qu’une route est disponible imme´diatement quelle
que soit la destination. Les inconve´nients sont la taille des tables de routage a` main-
tenir sur chaque nœud (taille en O(n) si n est le nombre de nœuds dans le re´seau) et
le nombre de messages de controˆle a` envoyer pe´riodiquement pour maintenir a` jour
les routes qui ne sont pas toujours employe´es.
– re´actif : les routes sont cherche´es a` la demande. L’avantage d’un tel protocole
est qu’il permet d’alle´ger en moyenne les tables de routage et de ne pas envoyer
pe´riodiquement des messages de recherche de route. L’inconve´nient est que lors-
qu’une route est ne´cessaire, la recherche de route vers le nœud destination peut eˆtre
tre`s longue, incluant une forte latence et ne´cessitant une inondation du re´seau.
Ainsi, avec de tels protocoles ”a` plat”, lorsque la taille re´seau grandit, le trafic de
controˆle a tendance a` devenir pre´-dominant laissant une part congrue aux communi-
cations re´elles. Cela se traduit e´galement par une augmentation de la latence et/ou
une explosion de la table de routage. Pour palier ce proble`me, une des solutions com-
1http ://www.ietf.org/html.charters/manet-charter.html
13
14 CHAPITRE 2. E´TAT DE L’ART
mune´ment propose´es est d’introduire un routage hie´rarchique et d’organiser des nœuds
en groupes aussi nomme´s clusters.
Le clustering consiste en un de´coupage virtuel du re´seau en groupes de nœuds proches
ge´ographiquement. Ces groupes sont appele´s clusters. Ils sont ge´ne´ralement identifie´s
par un nœud particulier, un chef de groupe aussi nomme´ cluster-head. Dans la plupart
des algorithmes de clustering, les clusters sont construits a` partir d’une me´trique par-
ticulie`re qui permet d’assigner un chef a` chaque nœud ; le cluster e´tant alors constitue´
du cluster-head et de tous les nœuds qui lui sont rattache´s. L’ide´e initiale du routage
hie´rarchique est de permettre a` chaque entite´ de stocker la totalite´ des informations de
son cluster et seulement une partie des informations concernant les autres clusters. Cela
minimise la taille des tables de routage et la quantite´ de trafic ge´ne´re´.
Outre le fait de rendre le routage plus efficace, le clustering pre´sente e´galement d’autres
avantages. Il peut faciliter le partage des ressources et/ou la synchronisation au sein
d’un cluster et permettre une re´-utilisation spatiale des fre´quences radio pour minimiser
les interfe´rences [50]. Plus important encore, l’organisation d’un re´seau apporte aussi
plus de stabilite´ [61].
De nombreuses solutions de clustering ont e´te´ propose´es. La majorite´ d’entre elles pro-
posent l’utilisation d’une me´trique qui permet aux nœuds de se choisir un chef. Cette
me´trique peut eˆtre par exemple l’identifiant ou le degre´ des nœuds, une valeur de mobi-
lite´ des nœuds ou encore une somme ponde´re´e de tous ces e´le´ments. D’autres solutions
cherchent dans un premier temps a` de´terminer un ensemble dominant connecte´ sur le-
quel les clusters sont baˆtis. Une grande partie des solutions de clustering construisent
des clusters a` 1 saut (dits 1-clusters), c.a`.d des clusters ou` chaque nœud est a` un saut
de son chef de cluster. Les protocoles donnant naissance a` des k-clusters (clusters ou`
chaque nœud est a` au plus k sauts de son cluster-head) sont plus re´cents et plus rares.
Dans ce chapitre, nous dressons un e´tat de l’art qui permet de passer en revue les
principaux types de solutions propose´es dans la litte´rature pour organiser un re´seau ad
hoc en clusters.
2.1 Clusters a` 1 saut
De nombreux algorithmes de clustering produisent des clusters a` 1 saut. L’un des al-
gorithmes les plus anciens est ”l’algorithme du plus petit ID” ou LCA, propose´ initia-
lement par Ephremides, Wieselthier et Baker dans [28]. Chaque nœud se de´signe ou
non cluster-head en se basant sur son identifiant et celui de ses voisins. Un nœud peut
avoir trois statuts diffe´rents : cluster-head, passerelle ou nœud ordinaire. A` l’origine,
tous ont un statut de nœud ordinaire. Si un nœud u a le plus petit identifiant parmi les
nœuds de son voisinage, il se de´clare cluster-head. Sinon, il attend que tous ses voisins
ayant un identifiant plus petit que le sien ait de´clare´ leur statut. Si au moins l’un d’eux
s’est de´clare´ chef, u de´clare a` son voisinage son statut de nœud ordinaire. u appartient
alors a` chacun des clusters de ses voisins s’e´tant de´clare´ chef. Si tous les voisins de u
ayant un identifiant plus petit que celui de u se sont de´clare´s nœuds ordinaires (car ils
2.1. CLUSTERS A` 1 SAUT 15
se sont attache´s a` un autre de leur voisin de plus petit ID), u se de´clare cluster-head.
Une fois que chaque nœud a de´clare´ son statut de nœud ordinaire ou de cluster-head,
si un nœud entend parmi ses voisins plus d’un cluster-head, il se de´clare passerelle.
Le protocole LCA est notamment utilise´ par le routage CBRP (Cluster Based Routing
Protocol) [42], pour la formation des clusters.
Par la suite, avec le protocole HCC (High Connectivity Clustering), Gerla et Tsai [36]
ont cherche´ a` apporter plus de stabilite´ a` la structure de clusters forme´s par le LCA, en
utilisant le degre´ des nœuds plutoˆt que leur identifiant. Le nœud ayant le plus fort degre´
dans son voisinage se de´clare cluster-head. Si deux voisins ont le meˆme degre´, c’est ce-
lui de plus petit identifiant qui prend sa de´cision le premier. L’ide´e est que des nœuds
de fort degre´ sont de bons candidats pour eˆtre cluster-heads car ils couvrent un grand
nombre de nœuds et le nombre de clusters re´sultant en sera re´duit. Par ailleurs, l’identi-
fiant d’un nœud e´tant unique, un nœud de faible ID aura tendance a` rester cluster-head
longtemps, malgre´ la mobilite´ des nœuds. Ne´anmoins, si ce nœud est tre`s mobile, il
de´truira constamment la structure.
Ainsi, ces protocoles construisent des clusters a` 1 saut qui se recouvrent (les passerelles
appartiennent a` plusieurs clusters). Cette structure a e´te´ propose´e pour acheminer les
messages de controˆle et de routage ou` seuls les cluster-heads et les passerelles agissent.
Leur maintenance s’ave`re couˆteuse car le mouvement d’un nœud peut engendrer des
re´actions en chaıˆne et ne´cessiter une reconstruction totale de la structure. C’est pour-
quoi les auteurs de [24] ont propose´ ”Least Cluster Change” (LCC). LCC ajoute une
e´tape de maintenance des clusters forme´s avec le LCA ou le HCC. Les clusters ne
sont reconstruits que si deux cluster-heads se retrouvent voisins (le nœud de plus faible
degre´ et/ou de plus fort ID suivant le cas abandonne le roˆle de cluster-head) ou si un
nœud ordinaire n’a plus aucun cluster-head dans son voisinage (il relance le processus
de clustering). De cette fac¸on, LCC ame´liore la stabilite´ de la structure. Cependant, les
re´actions en chaıˆne de re-construction ne sont que limite´es et ne sont pas comple`tement
supprime´es du fait qu’un seul nœud peut re-lancer la proce´dure de clustering s’il n’a
plus aucun cluster-head dans son voisinage.
Le protocole MOBIC [13], autre protocole de clustering a` 1 saut, applique le meˆme
algorithme que LCA et HCC mais utilise une me´trique base´e sur la mobilite´ plutoˆt que
le degre´ ou l’identifiant des nœuds. Cette me´trique cherche a` caracte´riser la mobilite´
relative d’un nœud. L’ide´e est qu’un nœud peu mobile est un bon candidat pour eˆtre
cluster-head car stable. Pour calculer sa mobilite´ relative, un nœud mesure le niveau
de signal qui l’unit a` chacun de ses voisins. La mobilite´ d’un nœud u est calcule´e a`
partir des rapports entre ce niveau de signal et celui mesure´ a` l’e´tape pre´ce´dente pour
chaque voisin de u, l’atte´nuation du signal e´tant de´pendante de la distance se´parant les
nœuds. Le nœud dont la mobilite´ est la plus faible dans son voisinage devient cluster-
head. Les auteurs de MOBIC utilise l’algorithme LCC pour la maintenance de leur
structure en ajoutant une re`gle supple´mentaire : si deux cluster-heads u et v arrivent
dans le voisinage l’un de l’autre, le cluster-head v de plus fort identifiant n’abandonne
son roˆle de cluster-head que si u fait toujours partie de ses voisins apre`s une certaine
pe´riode de temps. Cela permet de ne pas reconstruire la structure si deux cluster-heads
ne se retrouvent voisins que pour une courte pe´riode. La mobilite´ des nœuds n’est plus
reconside´re´e par la suite a` moins d’avoir a` reconstruire toute la structure. Cependant, les
16 CHAPITRE 2. E´TAT DE L’ART
inconve´nients du LCC ne sont pas e´limine´s. Bien que la prise en compte de la mobilite´
des nœuds semble inte´ressante pour de´terminer les cluster-heads, cette me´thode est un
peu complexe et ne´cessite que les nœuds soient en mesure d’estimer les puissances de
signal. De plus, elle ne conside`re pas certains phe´nome`nes physiques qui provoquent
des atte´nuations he´te´roge`nes du signal.
Plutoˆt que d’utiliser l’identifiant ou le degre´ des nœuds, d’autres protocoles de clus-
tering utilisent une somme ponde´re´e de plusieurs me´triques. Cette cate´gorie d’algo-
rithmes vise a` e´lire le cluster-head le plus adapte´ a` une topologie pour une utilisation
donne´e. Par exemple, dans un re´seau de senseurs ou` l’e´nergie est un facteur impor-
tant, le parame`tre d’e´nergie re´siduelle peut obtenir un poids plus e´leve´ dans la somme
ponde´re´e de la me´trique re´sultante. WCA [20] est un protocole utilisant une somme
ponde´re´e de quatre crite`res : la diffe´rence de degre´ Dv , la somme des distances avec
les voisinsPv , la vitesse relative moyenneMv et le temps de service en tant que cluster-
head. Pour un nœud v, la diffe´rence de degre´ Dv est la diffe´rence entre le degre´ de v
et une constante M repre´sentant le nombre de nœuds qu’un cluster-head peut servir.
Cependant, les auteurs n’explicitent pas le moyen de de´terminer M . La mobilite´ rela-
tive Mv est obtenue comme dans MOBIC. Les distances Pv entre v et ses voisins sont
calcule´es a` l’aide d’un GPS. L’e´lection se fait en se basant la` encore sur l’algorithme
de LCA, le nœud dont la somme ponde´re´e de ces crite`res est la plus petite devenant
cluster-head. Les clusters sont ensuite maintenus sans plus reconside´rer la me´trique
ponde´re´e. Le processus de clustering est relance´ quand un nœud arrive dans une zone
couverte par aucun cluster-head, ceci pouvant entraıˆner des re´actions de reconstruction
en chaıˆne comme dans les algorithmes pre´ce´dents.
Ainsi, plusieurs me´thodes de clustering a` 1 saut se basent sur l’algorithme du LCA
et changent juste le crite`re de de´cision. C’est pourquoi Basagni, dans [12] reprend
l’algorithme de LCA en donnant comme crite`re un poids ge´ne´rique que chacun de´finit
comme il le souhaite. Il en e´tudie alors the´oriquement les diffe´rentes proprie´te´s.
Toutes les me´thodes de clustering mentionne´es jusqu’a` maintenant produisent des clus-
ters recouvrants, c.a`.d. une structure dans laquelle un nœud peut appartenir a` plusieurs
clusters. Leur inconve´nient majeur est que le mouvement d’un nœud peut provoquer
la re-construction d’un cluster, qui, par re´action en chaıˆne, provoque le re-construction
de la structure entie`re. Afin d’e´viter cela, d’autres protocoles de clustering ont e´te´ pro-
pose´s, produisant des clusters non re-couvrants : un nœud appartient a` exactement un
cluster.
Dans 3HBAC [82], les auteurs proposent un protocole qui impose trois sauts entre deux
cluster-heads. Le nœud ayant le plus fort degre´ dans son voisinage se de´clare cluster-
head. Ses voisins s’attachent a` lui et se de´clarent ”nœuds membres”. Les nœuds voisins
de ces nœuds membres et non voisins d’un cluster-head se de´clarent ”unspecified” et ne
peuvent plus eˆtre cluster-head. Lorsque deux cluster-heads se retrouvent dans le voisi-
nage l’un de l’autre, celui de plus grand identifiant abandonne son roˆle de cluster-head
et devient un nœud membre. Ses voisins deviennent soit membres (s’ils sont voisins du
cluster-head) soit non spe´cifie´s. Les re´actions en chaıˆne de re-construction sont ainsi
e´vite´es.
Dans ”Adaptive Clustering” [50], les auteurs n’utilisent le statut de cluster-head que
2.1. CLUSTERS A` 1 SAUT 17
pour la formation des clusters. Une fois les clusters forme´s, la notion de cluster-head
disparaıˆt, chaque nœud du cluster tenant alors le meˆme roˆle. La motivation des au-
teurs est que les cluster-heads peuvent devenir des goulots d’e´tranglement par la suite,
sources de perte de trafic et saturation de bande passante. De plus, les cluster-heads
seraient appele´s a` de´penser leur e´nergie plus vite que les autres nœuds. Pour construire
de tels clusters, chaque nœud maintient un ensemble Γ qui initialement contient les
identifiants de tous ses 1-voisins. Un nœud n’est autorise´ a` diffuser son statut (cluster-
head, membre, non spe´cifie´) que s’il posse`de un identifiant plus petit que les nœuds de
Γ. Il ne se de´clare cluster-head que s’il a un identifiant plus petit que tous les nœuds
de son ensemble Γ. Sur re´ception du statut d’un nœud u, les voisins de u suppriment
u de leur ensemble Γ. Si u a annonce´ qu’il e´tait cluster-head, ses voisins s’attachent
a` lui s’ils n’e´taient encore membres d’aucun cluster ou si le cluster-head auquel ils
s’e´taient attache´s avait un identifiant plus grand que u. Le processus s’arreˆte lorsque
l’ensemble Γ de chaque nœud est vide. Comme le roˆle de cluster-head disparaıˆt une
fois les clusters forme´s, la maintenance de la structure est un peu diffe´rente que dans
les cas pre´ce´dents. Chaque nœud doit connaıˆtre son voisinage a` deux sauts. De cette
fac¸on, il sait si les membres de son cluster restent a` deux sauts de lui. Si deux nœuds
du meˆme cluster se retrouvent e´loigne´s de plus de deux sauts, seul celui encore voisin
du nœud de plus fort degre´ dans le cluster reste dans le cluster. L’autre doit se rattacher
a` un autre cluster. Bien que n’utilisant pas la notion de cluster-head, la maintenance de
cet algorithme maintient le nœud de plus fort degre´ au centre du cluster, ce qui peut
revenir au meˆme que de l’e´lire comme cluster-head. Le protocole de maintenance de
l’”Adaptive Clustering” a ensuite e´te´ repris par les auteurs de [44] qui se proposent de
l’appliquer au LCA.
Tous les algorithmes de´crits jusqu’a` pre´sent peuvent eˆtre qualifie´s de protocoles de
”clustering actif”, c.a`.d. que des messages de controˆle sont envoye´s dans le but de
construire et maintenir les clusters. A` l’oppose´, les auteurs de [47] proposent un proto-
cole de ”clustering passif”, c.a`.d. qu’ils n’utilisent aucun message de´die´ a` la construc-
tion des clusters. Les clusters ne sont cre´e´s que lorsque ne´cessaires, c.a`.d. lorsqu’un
nœud a une information a` diffuser. Le protocole de clustering passif utilise alors ces
messages d’information pour construire les clusters, en ajoutant des champs aux pa-
quets d’information. Un nœud a quatre statuts possibles : cluster-head, passerelle, nœud
ordinaire et non de´fini. Par de´faut, le statut des nœuds est non de´fini. Seul un nœud
ayant un statut non de´fini peut devenir cluster-head. Si un tel nœud a un message a`
envoyer, il se de´clare cluster-head et diffuse son statut en l’ajoutant a` l’information
qu’il devait envoyer. Les nœuds voisins d’un cluster-head deviennent des nœuds or-
dinaires, les nœuds voisins de plusieurs cluster-heads deviennent des passerelles. Les
nœuds ordinaires ne relaient pas les messages de diffusion. Aucun message n’e´tant
de´die´ a` la maintenance de la structure, les passerelles et les nœuds ordinaires activent
des compteurs lorsqu’ils rec¸oivent des nouvelles de leur(s) cluster-head(s). S’ils restent
sans nouvelle d’eux le temps que leur compteur expire, les nœuds ordinaires reprennent
un statut non de´fini et les passerelles prennent le statut de nœud ordinaire ou non de´fini
suivant le nombre de cluster-heads qu’elles entendent encore.
Comme nous venons de le voir, il existe de nombreux protocoles de clustering a` 1
saut. Les solutions les plus anciennes proposaient des clusters recouvrants. Ce type de
18 CHAPITRE 2. E´TAT DE L’ART
clusters permet principalement de baˆtir un ensemble dominant connecte´ sur le re´seau
(constitue´ des cluster-heads et des passerelles) pour pouvoir diffuser une information
(principalement pour le routage) sur le re´seau sans solliciter tous les nœuds. Puis
d’autres e´tudes ont donne´ des clusters non-recouvrants, plus robustes face a` la mo-
bilite´ des nœuds. Ce type de clusters permet e´galement d’autres applications comme la
re´utilisation spatiale de fre´quences ou de codes (les nœuds de deux clusters non voisins
peuvent utiliser la meˆme fre´quence). Puis, des propositions plus re´centes sont apparues
permettant la construction de clusters a` k sauts, encore plus robustes et permettant de
nouvelles applications comme l’application de zones de services ou de protocole de
routage hie´rarchique.
2.2 Clusters a` k sauts
La me´thode la plus re´pandue pour la construction de clusters a` k sauts est une extension
des algorithmes de clustering a` 1 saut. Par exemple, les auteurs de [23] ge´ne´ralisent
l’algorithme de Lin et Gerla [50]. Leur algorithme suppose que chaque nœud connaıˆt
ses voisins situe´s jusqu’a` k sauts de lui. Le nœud ayant le plus petit identifiant parmi
les nœuds a` au plus k sauts de lui, diffuse son statut de cluster-head a` ses k-voisins.
Lorsque tous les nœuds de son k-voisinage ayant un plus identifiant que lui ont dif-
fuse´ leur de´cision d’eˆtre chef de cluster ou de s’attacher a` un autre chef, le nœud u
peut prendre sa propre de´cision de s’attacher au nœud de son k-voisinage de plus pe-
tit identifiant s’e´tant de´clare´ chef de cluster s’il existe, ou de cre´er son propre cluster
sinon. De la meˆme fac¸on que pour les clusters a` 1 sauts, ce meˆme algorithme est uti-
lise´ en utilisant diffe´rentes me´triques. Dans le meˆme papier [23], les auteurs proposent
e´galement d’utiliser le k-degre´ (δk) des nœuds (nombre de voisins a` au plus k sauts)
pour de´terminer le cluster-head : le nœud de plus fort k-degre´ et de plus petit identifiant
en cas d’e´galite´ est promu chef de cluster. Les clusters re´sultants sont des k-clusters
(chaque nœud est a` au plus k sauts de son chef) recouvrants (un nœud peut appartenir a`
plusieurs clusters). Deux chefs sont e´loigne´s d’au moins k + 1 sauts. Cependant, nous
retrouvons les meˆmes inconve´nients que pour les algorithmes de clusters a` 1 saut, a`
savoir qu’un petit changement de nœuds peut engendrer une reconstruction comple`te
de la structure.
Les auteurs de [67] introduisent une me´trique qu’ils appellent ”associativite´” qui se
veut repre´senter la stabilite´ relative des nœuds dans leur voisinage. Pour chaque nœud,
l’associativite´ comptabilise le temps que chacun des nœuds de son voisinage reste ef-
fectivement dans son voisinage et en fait la somme sur chaque voisin. A` chaque pe´riode
de temps, un nœud u conside`re quels sont ses voisins actuels de´ja` pre´sents lors de la
pe´riode pre´ce´dente et ajoute +1 a` la valeur associe´e a` chacun d’eux. Si un voisin a
disparu, la valeur qui lui e´tait associe´e passe a` 0, si un autre apparaıˆt, il prend la valeur
1. A` chaque pe´riode de temps, l’associativite´ de u est la somme des valeurs associe´es a`
chacun de ses voisins. Cette valeur prend donc en compte la stabilite´ de u (si u est rela-
tivement stable dans son voisinage, il aura une forte associativite´) et le degre´ des nœuds,
cette valeur n’e´tant pas normalise´e. L’algorithme de formation des clusters est le sui-
vant. Un nœud conside`re les nœuds de son k-voisinage ayant un degre´ supe´rieur a` une
2.2. CLUSTERS A` K SAUTS 19
valeur seuil et e´lit parmi eux celui ayant la plus forte associativite´. Le plus fort degre´
et le plus faible identifiant sont ensuite utilise´s pour rompre les e´galite´s. Les clusters
re´sultants sont e´galement des k-clusters recouvrants mais qui visent a` eˆtre plus stables
dans le temps et dans l’espace que ceux se basant sur le simple degre´ ou identifiant.
Dans [51], Lin et Chu proposent une approche base´e sur aucune me´trique particulie`re.
Lorsqu’un nœud u arrive dans le re´seau, il est en phase ”d’initialisation”. Il demande
alors a` ses voisins s’ils sont comme lui en phase d’initialisation ou s’ils ont un cluster-
head et dans ce cas, a` quelle distance ce cluster-head se situe-t-il. Si tous les voisins
de u sont en phase d’initialisation, u s’e´lit chef de cluster et diffuse cette information.
Tous les r-voisins de u qui n’ont aucun autre chef plus proche que u s’attache au cluster
de u. Sinon, u s’attache au cluster de son voisin dont le chef est le plus proche et a` au
plus r sauts de lui. Si tous les cluster-heads des clusters de ses voisins sont a` plus de r
sauts de u, u se de´clare chef de cluster et rallie a` son cluster tous ses voisins a` moins
de r sauts dont le chef est plus e´loigne´ que u. Si deux cluster-heads se retrouvent a`
moins deD sauts l’un de l’autre,D < r, le chef de cluster de plus faible identifiant doit
ce´der son roˆle et tous les membres de son cluster doivent se trouver un autre chef. Cette
me´thode de clustering est inte´ressante dans la mesure ou` elle produit des r-clusters non
recouvrants ou` les chefs sont e´loigne´s de au moins D sauts. Cela assure une certaine
stabilite´ a` la structure. Cependant, l’abandon du roˆle de cluster-head par un nœud peut
engendrer de fortes re´actions en chaıˆne.
Une approche plus originale est celle propose´e par Fernandess et Malkhi dans [32].
Leur algorithme se de´compose en deux phases. La premie`re e´tape consiste a` trou-
ver un arbre couvrant du re´seau base´ sur un ensemble dominant connecte´ de cardi-
nalite´ minimale (MCDS). Les auteurs proposent d’utiliser l’algorithme de [2] pour
construire le MCDS mais pre´cisent que n’importe quelle me´thode peut eˆtre utilise´e. La
seconde phase de l’algorithme consiste en une partition de l’arbre couvrant en 2k-sous-
arbres, un 2k-sous-arbre e´tant un arbre de diame`tre au plus 2k sauts. Chaque sous-arbre
consiste en un k-cluster. Cependant, une telle approche a une complexite´ temporelle et
une complexite´ en messages en O(n) (n e´tant le nombre de nœuds dans le re´seau)
et est par conse´quent difficilement extensible. De plus, les auteurs n’abordent pas la
maintenance d’une telle construction, qui ne semble pas triviale.
Les auteurs de Max-Min d-cluster [4] utilisent l’identifiant des nœuds pour construire
des k-clusters non recouvrants. Cependant, leur algorithme est un peu plus complexe
que ceux vus jusqu’a` maintenant. Il se de´compose en trois phases. Lors de la premie`re
phase, chaque nœud collecte l’identifiant de ses voisins jusqu’a` d sauts et en garde le
plus grand qu’il diffuse de nouveau a` d sauts lors de la seconde phase. Chaque nœud
garde alors le plus petit des identifiants qu’il rec¸oit lors de cette deuxie`me phase (le
plus petit parmi les plus grands). La troisie`me e´tape consiste au choix du cluster-head
base´ sur les identifiants collecte´s lors des deux phases pre´ce´dentes. Si un nœud u a
vu passer son propre identifiant lors de la deuxie`me phase, il devient chef de cluster.
Sinon, si u a vu passer un identifiant durant chacune des phases 1 et 2, il e´lit le nœud
portant cet identifiant comme chef. Sinon, u e´lit comme chef le nœud de plus grand
identifiant dans son d voisinage. La structure re´sultante s’ave`re robuste, cependant la
latence induite par l’algorithme est non ne´gligeable.
20 CHAPITRE 2. E´TAT DE L’ART
Dans [3], les meˆmes auteurs introduisent une notion d’identifiant virtuel. Le but est
d’apporter une certaine e´quite´ entre les nœuds et d’e´viter qu’un meˆme nœud soit trop
longtemps cluster-head et e´puise ainsi ses ressources, tout en assurant qu’il le reste
suffisamment longtemps pour apporter une stabilite´ a` la structure. Les nœuds prennent
le roˆle de cluster-head tour a` tour. Initialement, l’identifiant virtuel d’un nœud est e´gal
a` son propre identifiant. A` chaque pe´riode de temps, chaque nœud non cluster-head
incre´mente de 1 son identifiant virtuel jusqu’a` atteindre un maximum MAXV ID. Le
nœud ayant l’identifiant virtuel le plus fort parmi ses k-voisins devient le cluster-head.
En cas de conflits, c’est le nœud qui a le moins ope´re´ en tant que chef qui devient
cluster-head (et de plus fort identifiant normal si toujours e´galite´). Un nœud qui de-
vient cluster-head prend ajoute a` son ancienne valeur d’identifiant virtuelle MAXV ID
de fac¸on a` assurer qu’il conserve le plus fort identifiant virtuel et reste cluster-head.
Un nœud reste cluster-head pendant une pe´riode de temps ∆(t) au bout de laquelle
il passe son identifiant virtuel a` 0 et abandonne son roˆle de chef. Lorsque deux chefs
entrent dans le voisinage l’un de l’autre, celui de plus faible identifiant virtuel aban-
donne son roˆle. Dans le meˆme papier, les auteurs proposent e´galement une construction
ou` l’identifiant virtuel de base serait le degre´ des nœuds. Cet algorithme permet donc
la formation de k-clusters en assurant une certaine stabilite´ de la structure. Ne´anmoins,
elle ne´cessite une synchronisation des nœuds afin que chacun se base sur la meˆme
pe´riode de temps pour incre´menter son identifiant virtuel et surtout pour comptabili-
ser la pe´riode durant laquelle il est cluster-head. Or, une synchronisation dans de tels
re´seaux est non triviale et ne´cessite beaucoup de messages.
Les auteurs de [45] proposent un autre type d’algorithme, formant cette fois des clusters
sans chef de cluster. Pour cela, chaque nœud ne´cessite e´galement la connaissance de
son k-voisinage. Un cluster est forme´ par un ensemble de nœuds tel qu’il existe entre
deux nœuds de cet ensemble un chemin d’au plus k-sauts. Si k = 1, chaque cluster
est une clique. Un nœud appartenant a` plusieurs clusters est dit nœud frontie`re. Les
clusters sont donc recouvrants. Malheureusement, cet algorithme implique beaucoup
de messages de controˆle, de maintenance et de donne´es a` ge´rer par les nœuds.
Les auteurs de DDR [59] proposent e´galement une structure sans cluster-head. Contrai-
rement a` la plupart des algorithmes de formation de k-clusters, les nœuds ne ne´cessitent
que de la connaissance de leur 1-voisinage. La formation des clusters se base sur la
construction d’un arbre. Chaque nœud choisit comme pe`re son voisin de plus faible
identifiant. Il existe alors exactement une areˆte sortante par nœud. Cela conduit a` la
formation d’un arbre. Tous les nœuds du meˆme arbre appartiennent au meˆme cluster.
Le diame`tre de tels clusters n’est pas fixe´ a priori et s’adapte automatiquement a` la to-
pologie sous-jacente. Cet algorithme a e´te´ ensuite repris par Baccelli [7] en y ajoutant
la notion de cluster-head et en controˆlant la taille des clusters. Pour cela, un nœud a
le droit de se choisir comme pe`re s’il a le plus fort identifiant dans son 1-voisinage. Il
existe alors des nœuds sans areˆte sortante qui deviennent des cluster-heads. Ces cluster-
heads ont alors la possibilite´ de borner la hauteur des arbres a` d sauts en diffusant l’in-
formation le long des branches de l’arbre. Si la branche est trop longue, le nœud se
trouvant a` d+1 sauts de son cluster-head doit s’attacher a` un autre pe`re (et donc casser
la branche).
D’autres algorithmes comme ceux propose´s dans [39, 60] ne proposent qu’une solution
2.3. CLUSTERS HIE´RARCHIQUES 21
de maintenance. Par exemple, les auteurs de [60] proposent de maintenir un certain
nombre de nœuds dans un cluster, qui de´pendrait du nombre d’entite´s que le cluster-
head est en mesure de ge´rer. L’ide´e est de maintenir en permanence le nombre de nœuds
entre deux seuils. Si un cluster est trop petit, le chef de cluster doit e´lire parmi ses
clusters voisins celui le plus adapte´ pour une fusion, c’est-a`-dire celui dont le nombre
de nœuds permet la fusion des deux clusters. Si aucun ne correspond, le chef de cluster
doit de´terminer un cluster qui peut lui ce´der des entite´s pour un meilleur e´quilibrage du
nombre de nœuds. Si les clusters sont trop gros, le chef doit e´lire parmi ses membres
un autre cluster-head et scinder son cluster en deux. Il reste cluster-head d’un cluster
re´sultant tandis que le nœud qu’il a e´lu devient chef du second cluster. Cette me´thode
est cependant tre`s couˆteuse en calculs, latence et messages et supporte mal le passage
a` l’e´chelle du re´seau.
2.3 Clusters hie´rarchiques
Il existe e´galement des propositions de structures hie´rarchiques a` plusieurs niveaux,
c’est-a`-dire ou` les clusters sont ensuite regroupe´s en d’autres clusters de niveaux
supe´rieurs et ainsi de suite. Bien que la majorite´ des algorithmes vus jusqu’a` main-
tenant peuvent eˆtre applique´s re´cursivement sur les clusters pour former des clusters de
niveau supe´rieur, ils n’ont pas e´te´ e´crits dans ce but contrairement aux exemples que
nous e´nonc¸ons ici.
Dans [11], Banerjee et Khuller se basent sur un arbre couvrant, construit graˆce a` un
parcours en largeur, pour la construction de k-clusters. Les clusters sont forme´s par
branche, en fusionnant re´cursivement deux sous-arbres de l’arbre couvrant jusqu’a`
obtenir une taille correcte. Le processus est alors re´-ite´re´ jusqu’a` obtenir un certain
nombre de niveaux.
Dans [5], les auteurs cherchent a` combiner les partitions physiques et logiques des
nœuds ainsi que leur mobilite´. Pour cela, ils utilisent un GPS. Les auteurs supposent
que les nœuds re´pondent a` un mode`le de mobilite´ de groupe. L’algorithme consiste
ensuite a` regrouper en un meˆme cluster les nœuds proches ge´ographiquement et qui
se de´placent a` un vitesse semblable dans une meˆme direction. Le processus est ensuite
re´-ite´re´ jusqu’a` obtenir le nombre de niveaux voulu.
La structure de cellules hie´rarchiques de SAFARI [69] est base´e sur une auto-se´lection
des nœuds en tant que drums (cluster-heads). Le nombre de niveaux hie´rarchiques
s’e´tablit automatiquement en fonction de la topologie sous-jacente des nœuds. Les
clusters de niveau i sont groupe´s en clusters de niveau i+1 et ainsi de suite, les simples
nœuds e´tant conside´re´s comme des cellules de niveau 0. Chaque cluster-head de niveau
i se choisit un cluster-head de niveau i + 1. Tous les cluster-heads de niveau i ayant
choisi le meˆme cluster-head de niveau i+ 1 appartiennent au meˆme cluster de niveau
i + 1. Un cluster-head u de niveau i de´cide de monter ou descendre son niveau en
fonction du nombre de cluster-heads de niveau i + 1 et i − 1 qui existent a` une cer-
taine distance. S’il n’existe aucun cluster-head de niveau supe´rieur a` une distance plus
petite que Di (Di constante de´pendant du niveau i du cluster-head) de u, u de´cide
22 CHAPITRE 2. E´TAT DE L’ART
d’augmenter son niveau. Si deux cluster-heads de meˆme niveau sont a` moins de h×Di
(0 < h < 1, facteur d’hyste´resis) sauts, le cluster-head de plus grand identifiant des-
cend son niveau. Un cluster-head de niveau i est e´galement cluster-head de tout niveau
j tel 0 < j < i. Cet algorithme construit des k-clusters hie´rarchiques, ou` k de´pend du
niveau du nœud i : k = Di. D1 doit eˆtre fixe´. A` partir de la`, Di de´pendant de Di−1, le
rayon des clusters de chaque niveau est fixe´. Cette structure hie´rarchique peut cepen-
dant n’eˆtre utilise´e que dans un cadre pre´cis de routage, propose´ par les auteurs. Nous
verrons cette utilisation plus en de´tail dans le chapitre 5.
2.4 Conclusion
Ainsi, il existe de nombreux protocoles de clustering dans la litte´rature. Tous cependant
ne sont pas adapte´s a` une extension du re´seau comme nous avons pu le constater. En
effet, des clusters a` 1 saut ne peuvent pas eˆtre utilise´s dans ce cadre du fait du nombre
de clusters qu’ils ge´ne´reraient sur de la larges e´chelles et du fait que le moindre chan-
gement a` l’e´chelle d’un nœud provoquerait une reconstruction de la structure. En effet,
si le re´seau compte beaucoup d’entite´s, ces changements peuvent eˆtre fre´quents et mi-
nimes a` l’e´chelle du re´seau. Les clusters a` k sauts sont moins de´veloppe´s. Beaucoup
s’inspirent des protocoles de clustering a` 1 saut et en gardent les inconve´nients. Dans
ma the`se, j’ai propose´ un nouvel algorithme de clustering a` k sauts pouvant s’adap-
ter aux petites modifications du re´seau. Cet algorithme prend note des inconve´nients
des protocoles existants et tente de les e´viter, comme nous le verrons de`s le chapitre
suivant.
Chapitre 3
Algorithme de clustering, stable
et robuste
3.1 Introduction
Notre principal objectif est de proposer un moyen d’utiliser des re´seaux sans fil tre`s
denses. Comme nous l’avons vu, l’une des solutions possibles est d’introduire une
hie´rarchie dans le re´seau en construisant des clusters. Afin de permettre une extensibi-
lite´ totale et ne pas avoir a` reconstruire les clusters apre`s chaque mouvement individuel
d’un nœud, nous avons cherche´ a` construire des clusters qui n’aient aucun parame`tre
fixe´ a` l’avance, qu’il s’agisse du rayon, du diame`tre ou de nombre de nœuds par clus-
ter. Ces parame`tres doivent s’adapter d’eux-meˆmes a` la topologie du re´seau, qui e´volue
au cours du temps. De plus, l’heuristique se doit d’eˆtre distribue´e et asynchrone tout
en minimisant le nombre d’informations a` e´changer. Notre algorithme n’utilise que
des messages de type ”PAQUET HELLO” comme ceux utilise´s dans OLSR [25] afin
de de´couvrir le 2-voisinage d’un nœud. Les clusters forme´s doivent eˆtre stables (les
cluster-heads doivent conserver ce statut suffisamment longtemps pour limiter le trafic
de controˆle ne´cessaire a` la reconstruction des clusters) tout en s’adaptant aux change-
ments de la topologie sous-jacente. Enfin, afin d’ame´liorer la stabilite´ de la structure,
e´tant donne´ que les nœuds trop mobiles pour initier une communication n’ont aucun
besoin de la structure, ils ne participent pas a` la phase de construction et restent des
nœuds inde´pendants. Dans le cas contraire, de par leur mobilite´, ils pourraient obliger
le re´seau a` re-construire inutilement les clusters.
Comme mentionne´ dans le chapitre 2, diffe´rentes me´triques ont e´te´ utilise´es pour le
choix des cluster-heads dans les algorithmes de clustering. L’identifiant des nœuds
e´tant immuable, il permet de conserver les chefs de cluster tre`s longtemps. Cependant
de tels clusters sont inde´pendants de la topologie sous-jacente et ne sont pas toujours
adapte´s. Le degre´ des nœuds s’ave`re l’une des me´triques les plus adapte´es, l’ide´e e´tant
23
24 CHAPITRE 3. ALGORITHME DE CLUSTERING
qu’un chef de fort degre´ permet de couvrir un grand nombre de nœuds, ce qui per-
met d’en minimiser le nombre. Cependant, un mouvement individuel d’un nœud dans
des clusters base´s sur cette me´trique peut conduire a` une re´-organisation comple`te du
re´seau, alors que la structure globale du re´seau reste inchange´e.
Base´s sur cette constatation, nous avons introduit une nouvelle me´trique, que nous
avons appele´e densite´. L’ide´e est que, si un petit changement de topologie intervient
dans le voisinage d’un nœud, son degre´ δ peut changer alors que globalement son
voisinage est conserve´. Notre me´trique est une densite´ de liens et cherche a` lisser les
petits changements de topologie qui interviennent au niveau individuel d’un nœud, tout
en permettant aux clusters de s’adapter a` la topologie sous-jacente.
3.2 La me´trique de densite´
La k-densite´ d’un nœud, note´e ρk(u), est le ratio du nombre de liens par le nombre de
nœuds dans le k-voisinage d’un nœud.
De´finition 1 (densite´) La k-densite´ d’un nœud u ∈ V est
|e = (v, w) ∈ E |w ∈ {u,Γk(u)} et v ∈ Γk(u)|
ρk(u) =
δk(u)
La 1-densite´ (e´galement note´e ρ(u)) est donc le rapport entre le nombre de liens entre
u et ses voisins plus le nombre de liens entre les voisins de u et le nombre de ses voisins
(par de´finition, son degre´).
Afin d’illustrer cette me´trique, prenons l’exemple repre´sente´ sur la Figure 3.1.
Conside´rons le nœud p et calculons sa 1-densite´ ρ(p). ρ(p) est le ratio entre le nombre
d’areˆtesL(p) et le nombre de nœuds (|Γ(p)|) dans le 1-voisinage Γ(p) de p. Les nœuds
de Γ(p) sont les nœuds gris fonce´ (Γ(p) = {a, b, c, d, e, f}). L(p) repre´sente alors le
nombre de liens entre p et ces nœuds (liens en pointille´s) et le nombre de liens entre ces
nœuds (liens tiret). Ainsi, L(p) = 4 + 6 = 10 et δ(p) = 6 d’ou` ρ(p) = 10/6 = 5/3.
On remarquera que pour calculer ρk(p), p doit connaıˆtre Γk+1(p) afin de connaıˆtre les
liens existant entre ses k-voisins.
3.3 La formation des clusters
Chaque nœud u surveille son voisinage et juge ainsi de sa mobilite´ relative. Si cette
dernie`re n’est pas trop importante, alors u participe a` l’algorithme de clustering, si-
non, il reste un nœud inde´pendant. L’ide´e est qu’un nœud trop mobile ne pourra pas
instancier de communications avec les autres entite´s du re´seau. Il n’a donc pas besoin
d’appartenir a` un cluster puisqu’il ne pourrait pas en tirer avantage. De meˆme, si un
3.3. LA FORMATION DES CLUSTERS 25
b a
p f
c
d e
FIG. 3.1 – Illustration de la me´trique de densite´.
nœud trop mobile est pris en compte dans la construction des clusters, il risque de
casser la structure inutilement de par les nombreuses cassures de liens induites par sa
forte mobilite´ et obligera le re´seau a` reconstruire les clusters. Cette valeur de mobilite´
relative d’un nœud u peut eˆtre calcule´e en ve´rifiant la constance du voisinage de u, en
conside´rant par exemple le nombre de nœuds restant dans le voisinage de u pendant un
certain temps.
Pe´riodiquement, chaque nœud suffisamment stable calcule sa densite´ et la diffuse lo-
calement a` son 1-voisinage. Chacun est alors en mesure de comparer sa propre densite´
a` celle de ses voisins ”suffisamment stables”. A` partir de la`, un nœud de´cide soit de
s’e´lire comme cluster-head (s’il posse`de la plus forte densite´), soit de choisir comme
pe`re son voisin de plus forte densite´. En cas d’e´galite´, afin de privile´gier la stabilite´
de la structure, le nœud choisi sera celui de´ja` e´lu au tour pre´ce´dent s’il est en course,
sinon celui de plus petit identifiant. De cette fac¸on, deux voisins ne peuvent pas eˆtre
tous deux cluster-heads. Cette me´thode d’e´lection construit implicitement une foreˆt
couvrante oriente´e.
Si un nœud u choisit le nœud w, on dit que w est le pe`re de u (note´ P(u) = w)
dans l’arbre de clustering et que u est un fils de w (note´ u ∈ Ch(w)). Si aucun nœud
n’a e´lu le nœud u comme pe`re (Ch(u) = ∅), u est une feuille d’un des arbres, sinon,
u est qualifie´ de nœud interne. Le pe`re d’un nœud peut s’eˆtre choisi comme pe`re un
autre nœud de son voisinage et ainsi de suite. Un arbre s’e´tend automatiquement, sans
contrainte sur sa hauteur, jusqu’a` atteindre les frontie`res d’un autre arbre. Tous les
nœuds appartenant au meˆme arbre appartiennent alors au meˆme cluster. Afin d’apporter
une stabilite´ plus importante, un chef de cluster ne doit pas eˆtre trop excentre´ dans son
propre cluster. En effet, si un chef de cluster se trouve a` la frontie`re de son cluster et
qu’il bouge, il a plus de chance d’entrer en compe´tition avec un autre chef et ainsi de
casser les deux clusters. C’est pourquoi, nous ajoutons une re`gle supple´mentaire qui
indique que tout nœud voisin d’un cluster-head doit s’attacher a` ce cluster-head. Si un
nœud est voisin de plusieurs cluster-heads, une fusion est instancie´e entre ces clusters
et le cluster re´sultant a pour chef le cluster-head en compe´tition de plus forte densite´.
De cette fac¸on, deux cluster-heads sont distants de 3 sauts minimum. Supposons un
nœud u voisin d’un chef de cluster H ( H ∈ Γ1(u)) mais qui ne l’a pas choisi comme
pe`re (P(u) 6= H), alors, deux cas sont possibles :
– soit le pe`re de u est e´galement cluster-head ; dans ce cas les deux clusters fusionnent.
26 CHAPITRE 3. ALGORITHME DE CLUSTERING
Le cluster-head final est le nœud le plus fort parmi ceux en compe´tition : P(u).
(Puisque u pouvait choisir entre H et P(u) et a choisi P(u)). H n’est plus cluster-
head, il choisit u comme son pe`re ;
– soit le pe`re de u s’est attache´ a` un autre de ses voisins et n’est pas cluster-head ; cela
signifie que u se situe a` au moins deux sauts de son chef. Il change alors de pe`re et
choisit H.
E´ tant donne´ un nœud v ∈ V , pour tout nœud u ∈ Γ1(v), on de´finit Age(u)
comme le nombre de pe´riodes successives ou` un nœud u a choisi v comme pe`re. On
de´finit e´galement ≺ comme un indicateur d ordre binaire tel que pour (u, v) ∈ V 2’ , ,
u ≺ v si et seulement si {ρk(u) < ρk(v)} ou {ρk(u) = ρk(v) ∧Age(u) < Age(v)}
ou {ρk(u) = ρk(v) ∧Age(u) = Age(v) ∧ Id(v) < Id(u)}.
L’algorithme s’auto-stabilise quand chaque nœud connaıˆt l’identite´ de son cluster-head.
Algorithm 1 Formation des clusters
Pour tout nœud u ∈ V
⊲ Initialisation des variables.
H(u) = P(u) = −1
∀v ∈ Γ1(u), Age(v) = 0
while ((H(u) = −1) ou (H(u) 6= Hold(u)))
⊲ Boucle jusqu’a` stabilisation
Hold(u) = H(u)
Scrutation du voisinage
Calcul de la valeur de mobilite´
if (Mobilite < SeuilMobilite)
Re´cupe`re Γk+1(u)
Calcule ρk(u)
Diffuse localement ρk(u) a` ses 1-voisins.
⊲ Cette diffusion locale peut s’effectuer par exemple en ajoutant la valeur de ρk(u) dans
un paquet HELLO.
⊲ A` ce moment, le nœud u connaıˆt la k-densite´ de tous ses voisins et peut choisir son pe`re.
if (∀v ∈ Γ1(u), v ≺ u) then H(u) = u ⊲ u devient cluster-head.
else
⊲ ∃w ∈ Γ1(u) t.q.∀v ∈ {u} ∪ Γ1(u), v ≺ w
P(u) = w
H(u) = H(w)
⊲ Soit P(w) = H(w) = w donc u est directement lie´ a` son chef de cluster, soit w
a choisi un autre nœud x comme pe`re (∃ x ∈ Γ1(w) | P(w) = x) et re´cursivement
H(u) = H(w) = H(x).
end
if ((H(u) = u) et (∃v ∈ Γ1(u) | P(v) 6= u)) then
⊲ u est cluster-head, mais tous ses voisins ne l’ont pas choisi comme pe`re.
if (P(v) = H(v)) then
⊲ Au moins deux cluster-heads (H(u) et H(v)) ont un voisin commun v. Si P(v) =
H(v) alors u ≺ H(v). u s’e´crase et choisit v comme pe`re (les clusters C(u) et C(v)
fusionnent).
P(u) = v et H(u) = H(v)
Age(v)++ et ∀w ∈ Γ1(u), Age(w) = 0.
end
3.3. LA FORMATION DES CLUSTERS 27
end
if (∃v ∈ Γ1(u) t.q. {(H(v) = v) et (H(P(u)) 6= H((u))})
⊲ u n’est pas chef et est a` plus de 2 sauts de son chef (son pe`re n’est pas chef) alors qu’il
compte un chef parmi ses voisins. Il change de pe`re.
P(u) = v et H(u) = v
Age(v)++ et ∀w ∈ Γ1(u)Age(w) = 0.
end
Diffuse localement P(u) et H(u)
end
Exemple
Afin d’illustrer cette heuristique, exe´cutons l’Algorithme 1 sur le graphe de la figure 3.2
en conside´rant la 1-densite´. Dans le 1-voisinage du nœud a, on a deux voisins (Γ1(a) =
{d, i}) et deux liens ({(a, d), (a, i)}), d’ou` ρ(a) = 1 ; le voisinage du nœud b compte
4 voisins (Γ1(b) = {c, d, h, i}) et cinq liens ({(b, c), (b, d), (b, h), (b, i), (h, i)}), d’ou`
ρ(b) = 54 . La table 3.1 montre les valeurs finales des densite´s des nœuds.
c b h e
j
l
d
g
i
a k
f m
FIG. 3.2 – Exemple.
Nœuds a b c d e f g h i j k l m
Degre´ 2 4 1 4 2 2 2 3 4 2 4 2 2
Nb Liens 2 5 1 5 2 3 2 4 5 3 5 3 3
Densite´ 1 1.25 1 1.25 1 1.5 1 1.33 1.25 1.5 1.25 1.5 1.5
TAB. 3.1 – Densite´ des nœuds du graphe de la figure 3.2.
Dans cet exemple, le nœud c e´lit son voisin b (P(c) = b) dont la densite´ est la plus
forte dans Γ1(c) ∪ {c} (∀v ∈ Γ1(c) ∪ {c} , v ≺ b). Le nœud de plus forte densite´
dans le voisinage de b est h, d’ou` P(b) = h. Comme h a la plus forte densite´ dans
son voisinage, il devient son propre pe`re et donc cluster-head : H(h) = h. Le nœud
c choisit b qui choisit h et tous trois appartiennent au meˆme cluster de cluster-head
h et donc : H(c) = H(b) = H(h) = h. ρ(j) = ρ(f) : ni j ni f n’e´taient choisis
auparavant, c’est donc le plus petit identifiant qui tranche. Supposons j ≺ f , alors
P(j) = f et P(f) = f d’ou`H(f) = H(j) = f . Aucun nœud n’ayant choisi a, j, c, e,
i, g et m comme pe`re, ils deviennent des feuilles. Finalement, nous obtenons une foreˆt
couvrante du re´seau, compose´e de trois arbres de racines h, l et f (figure 3.3(a)), qui
donnent naissance a` trois clusters (figure 3.3(b)).
28 CHAPITRE 3. ALGORITHME DE CLUSTERING
c b h e c b h e
j j
l l
d d
g g
i i
a k a k
f m f m
(a) Arbres de clustering. (b) Clusters.
FIG. 3.3 – Arbres (a) et clusters (b) construits avec l’Algorithme 1 sur le graphe de la
figure 3.2 (Les cluster-heads/racines apparaissent en blanc).
3.4 Maintenance de la structure
La maintenance de cette structure construite a` partir de l’heuristique de la k-densite´
est simple, e´tant donne´ que chaque nœud n’a besoin que de son k + 1-voisinage pour
la construire. En effet, d’apre`s la taxonomie e´tablie par [81], un algorithme peut eˆtre
qualifie´ de local si chaque nœud n’a besoin que de la connaissance de son 1 et 2 voi-
sinage pour l’exe´cuter, ou de quasi-local, si les nœuds ne´cessitent une information
dans un voisinage borne´. Cela implique une maintenance rapide. Chaque nœud calcule
pe´riodiquement ses valeurs de mobilite´ et de densite´. S’il est suffisamment stable, il
compare sa densite´ a` celle de ses voisins et choisit pe´riodiquement son pe`re. Un nœud
non stable a` l’origine et dont le voisinage se stabilise peut ainsi s’attacher a` la structure
sans la de´truire.
3.5 Analyse de la me´trique
Dans cette section, nous nous sommes inte´resse´s aux diffe´rentes caracte´ristiques de
notre me´trique de densite´.
Dans un premier temps, nous avons calcule´ sa valeur the´orique moyenne a` l’aide de la
ge´ome´trie stochastique et des calculs de Palm. Puis, nous avons compare´ les diffe´rentes
k-densite´s. Nous verrons ainsi que la 1-densite´ est non seulement la densite´ la moins
couˆteuse mais e´galement la plus stable face a` la mobilite´ des nœuds et que les cluster-
heads se´lectionne´s agissent comme des bassins d’attraction. Nous terminerons cette
partie par une analyse de la re´partition des valeurs de densite´ parmi les nœuds du
re´seau.
3.5.1 Recherche de la meilleure k-densite´
Nous nous sommes interroge´s sur les diffe´rentes k-densite´s : laquelle est la plus
ade´quate ? En effet, nous avons vu que pour calculer une k-densite´, chaque nœud doit
connaıˆtre son k+1 voisinage. Ainsi, plus k augmente, plus la k-densite´ est couˆteuse en
3.5. ANALYSE DE LA ME´TRIQUE 29
messages, utilisation de bande passante et latence. C’est pourquoi, nous avons compare´
par simulation les structures forme´es par la 1-densite´ et la 2-densite´.
Comme le montre la table 3.2, la 2-densite´ construit moins de clusters que la 1-densite´.
Un nœud est plus excentre´ dans son cluster avec k = 2. Ne´anmoins, ces caracte´ristiques
tre`s similaires ne nous permettent pas de trancher entre les diffe´rentes densite´s. C’est
pourquoi, nous avons e´galement compare´ le comportement des structures obtenues
avec les densite´s 1 et 2 face a` la mobilite´ des nœuds. En effet, la densite´ la plus
inte´ressante sera celle qui offre la meilleure stabilite´, c.a`.d qui reconstruit moins sou-
vent les clusters lorsque les nœuds se de´placent, limitant ainsi les e´changes de messages
de controˆle et de mise a` jour des tables de routage. Un nœud peut quitter son cluster et
migrer dans un autre sans que cela ne casse la structure de clusters.
750 nœuds 3000 nœuds 5000 nœuds
k-densite´ 1 2 1 2 1 2
Nb clusters 4.67 3.01 4.23 2.53 4.42 2.43
D(C) 7.1 9.72 9.25 11.67 9.4 12.15
e˜(u/C) 4.86 6.45 6.21 7.03 6.02 8.42
TAB. 3.2 – Comparaison des k-densite´s.
Pour cela, nous avons simule´ un re´seau ou` les nœuds peuvent choisir ale´atoirement
de bouger a` diffe´rentes vitesses allant de 0 a` 1.6m/s (pie´tons) dans des directions
ale´atoires (Mode`le de mobilite´ Random Way Point) pendant 500s . La table 3.3 donne
le nombre moyen de reconstructions de clusters durant la simulation.
Moy Min Max
1-densite´ 7.5 2 13
2-densite´ 9.4 4 14
TAB. 3.3 – Nombre de clusters re-contruits apre`s mobilite´ des nœuds.
La 2-densite´ reconstruit plus souvent la structure que la 1-densite´. La 1-densite´ s’ave`re
donc la densite´ la plus robuste et la moins couˆteuse puisqu’elle ne ne´cessite la connais-
sance que du 2-voisinage d’un nœud, tout comme dans OLSR. De plus, utiliser une
k-densite´ avec k > 2 serait trop couˆteux et impliquerait une maintenance moins effi-
cace. C’est pourquoi, par la suite, on ne conside´rera que la 1-densite´.
3.5.2 Densite´ moyenne
Nous analysons ici la 1-densite´ moyenne ρ˜(u) d’un nœud u. On conside`re un re´seau
sans fil multi-sauts ou` les nœuds sont distribue´s suivant un processus de Points de Pois-
son d’intensite´ constante λ. Nous calculons alors la 1-densite´ moyenne en conside´rant
une distribution de Palm. Dans une telle distribution, un nœud 0 est artificiellement
30 CHAPITRE 3. ALGORITHME DE CLUSTERING
ajoute´ a` la distribution poissonienne. Ce nœud 0, place´ a` l’origine du plan, sert de base
d’observation pour les calculs. Sous la probabilite´ de Palm, ce nœud existe presque
suˆrement. Puisque le processus est stationnaire, la densite´ moyenne de 0 est valide
pour tout autre point du processus.
Soit ρ(0) la densite´ moyenne du nœud 0. Φ de´signe le processus ponctuel : Φ(S)
repre´sente le nombre de points du processus se trouvant sur une surface S donne´e.
S i l b l d d y ′o t B(u,R) a ou e e centre u et e ra on R et Bu la boule centre´e en u de rayon
R prive´e du singleton {u} ′: B = B(u,R)\ {u} o et o, u . E P de´signent respectivement
l’espe´rance et la probabilite´ sous la distribution de Palm.
Nous cherchons donc a` calculer la densite´ moyenne ρ˜(u) = oE [ρ(0)] d’un nœud quel-
conque u.
Lemme 1 La 1-densite´ moyenne d(e tout nœud)u s’e´crit :√ ( − {− })o 1 3 3 1 exp λpiR2ρ˜(u) = E [ρ(0)] = 1 + pi − λR2 −
2 4 pi
La preuve de ce lemme est donne´e en annexes 3.11.1. L’ide´e est de compter le nombre
de liens dans le voisinage d’un nœud. Un lien existe entre deux nœuds s’ils sont a`
une distance infe´rieure ou e´gale a` R. Si v est un voisin de u, alors, il existe autant
de liens entre v et un autre voisin de u que de voisins communs a` u et v (nœuds a`
distance infe´rieure a` R a` la fois de u et de v). Le nombre de voisins communs a` u et v
correspond au nombre de points se trouvant a` l’intersection des zones de transmission
de u et v. Cette surface est la zone repre´sente´e en bleu sur la figure 3.4. Par la suite,
nous de´noterons par A(r) cette surface. Le calcul de ρ˜ consiste a` sommer le nombre
de points se trouvant en moyenne dans cette zone pour chacun des voisins v de u en
fonction de la distance euclidienne r de u a` v. Les liens e´tant ainsi compte´s deux fois,
la somme finale est divise´e par deux.
R u v R
r
FIG. 3.4 – Intersection du voisinage de deux nœuds voisins u et v. Les nœuds se trou-
vant dans la zone bleue sont des voisins communs a` u et v.
3.6. ANALYSE DE LA STRUCTURE 31
Afin de ve´rifier la validite´ de nos re´sultats analytiques, nous avons compare´ les valeurs
de densite´ moyenne obtenues par analyses et par simulation. Le mode`le de simulation
utilise´ est celui de´crit dans le Chapitre 1.1. La table 3.4 donne les re´sultats pour une
valeur de R = 0.1 et diffe´rentes valeurs d’intensite´ λ du processus de Poisson. Notons
que la the´orie et la simulation s’accordent parfaitement.
500 nœuds 600 nœuds 700 nœuds
The´orie Simulation The´orie Simulation The´orie Simulation
δ˜ 15.7 15.3 18.8 18.3 22.0 21.2
ρ˜ 4.7 5.0 5.6 5.9 6.5 6.8
800 nœuds 900 nœuds 1000 nœuds
The´orie Simulation The´orie Simulation The´orie Simulation
δ˜ 25.1 25.0 28.3 27.9 31.4 31.0
ρ˜ 7.5 7.1 8.4 8.6 9.3 9.4
TAB. 3.4 – Degre´ et densite´ moyens des nœuds.
3.5.3 Re´partition des valeurs de densite´
La figure 3.5 montre comment les valeurs de densite´ sont re´parties. La figure 3.5(a)
donne le nombre de nœuds ayant une valeur de densite´ donne´e. Les barres verticales
indiquent les valeurs prises par les cluster-heads. La figure 3.5(b) donne un exemple
de distribution des densite´s dans le plan. Les cluster-heads apparaissent en bleu. Plus
la couleur des nœuds est jaune, plus leur densite´ est forte. Nous pouvons constater que
dans chaque cluster, les densite´s les plus fortes se situent autour des chefs de cluster.
Plus un nœud est loin d’un cluster-head, plus sa densite´ est faible. Les cluster-heads
forment des sortes de bassin d’attraction, ce qui apporte une stabilite´ a` la structure.
3.6 Analyse de la structure
Afin de pouvoir au mieux utiliser la structure de clusters forme´e par notre heuristique,
nous en avons e´tudie´ certaines caracte´ristiques par simulation et quand nous le pou-
vions, par analyse the´orique en utilisant la ge´ome´trie stochastique.
3.6.1 Analyse the´orique du nombre de clusters
Dans cette section, nous avons cherche´ a` calculer analytiquement le nombre de clus-
ters (ou de cluster-heads) produit par l’algorithme de clustering (algorithme 1). Comme
pour le calcul de la densite´ moyenne (section 3.5.2), nous utilisons la ge´ome´trie sto-
chastique suivant le mode`le de´fini dans la section 1.1.
32 CHAPITRE 3. ALGORITHME DE CLUSTERING
(a) Histogramme. Nombre de nœuds du re´seau ayant une (b) Plus la couleur est rouge, plus la
densite´ donne´e. densite´ est grande. Cluster-heads en
bleu.
FIG. 3.5 – Distribution des valeurs de densite´ parmi les nœuds. Les cluster-heads ap-
paraissent en bleu. Plus la couleur des nœuds est jaune, plus leur densite´ est forte.
Nous utilisons les meˆmes notations et la meˆme mode´lisation que pre´ce´demment, a`
savoir que l’on conside`re un re´seau sans fil multi-sauts ou` les nœuds sont distribue´s
suivant un processus ponctuel de Poisson Φ d’intensite´ constante λ.
On cherche dans un premier temps a` calculer le nombre de clusters (ou cluster-heads)
dans un espace C.
Lemme 2 Le nombre moyen de cluster-heads appartenant a` un domaine C est :
[Nombre de cluster heads dans C] = λν(C) oE - PΦ (0 est chef )
ou` ν(C) repre´sente la mesure de Lebesgue1 dans IR2.
Pour de´terminer le nombre moyen de cluster-heads, il nous faut donc dans un premier
temps calculer oPΦ (0 est chef ), probabilite´ qu’un nœud soit chef. Les nœuds e´tant dis-
tribue´s uniforme´ment et inde´pendamment, cette probabilite´ est la meˆme pour tous les
nœuds. Cela revient a` calculer la probabilite´ qu’un nœud ait la plus forte densite´ dans
son voisinage.
Lemme 3 La probabilite´ qu’un point 0 so(it chef sous la probabilite´ d)e Palm est :
o o
PΦ (0 est chef) = PΦ ρ(0) > max ρ(Yk)
k=1,..,Φ(B0)
Nous avons cherche´ a` calculer cette quantite´ mais n’avons pu obtenir qu’une borne
supe´rieure.
1La mesure de Lebesgue sur IR d’un intervalle coı¨ncide avec sa longueur, la mesure de Lebesgue d’une
re´gion de l espace sur IR2’ coı¨ncide avec la surface de cet espace. Pour une de´finition plus formelle, se re´fe´rer
a` [76], chapitre 1.
3.6. ANALYSE DE LA STRUCTURE 33
Conjectu(re 1 Une borne supe´rieure)pou(r la probabili∑+∞ (
te´ qu’u)n n)œud soit chef est :
1 λpiR2
n
o 2
PΦ ρ(0) > max ρ(Yk) ≤ 1 + exp {−λpiR }
k=1,..,Φ(B0) n n!
n=1
Les de´tails du calcul sont donne´s en annexes 3.11.2. L’ide´e est dans un premier temps
de conditionner la probabilite´ que 0 soit chef par le fait qu’il ait ou non des voisins. Si
0 n’a pas de voisin, 0 est chef avec la probabilite´ 1. Dans le cas contraire, on majore
cette probabilite´ par la probabilite´ qu’un voisin v de 0 ait la plus forte densite´ parmi
Γ(0), les voisins de 0, probabilite´ que l’on peut calculer sous Palm.
La figure 3.6 repre´sente la borne supe´rieure du nombre de clusters pour diffe´rentes
valeurs de R et de λ (avec R diminuant de bas en haut). On peut voir que lorsque
que l’intensite´ des nœuds augmente, la borne supe´rieure du nombre de clusters tend
asymptotiquement vers une constante, ce qui permet a` notre structure de supporter le
passage a` l’e´chelle du re´seau.
Upper bound of the number of clusters in function of the process intensity
160
140
120
100
80
60
40
500 1000 1500 2000 2500 3000
lambda
FIG. 3.6 – Borne supe´rieure du nombre de clusters en fonction de λ (en abscisse) et de
R (diffe´rentes courbes : de bas en haut R = 0.1, 0.09, 0.08, 0.07, 0.06, 0.05 m).
3.6.2 Caracte´ristiques des clusters
Les re´sultats donne´s dans cette section ont e´te´ obtenus par simulation, en utilisant le
mode`le de´crit dans la section 1.1. La table 3.5 re´sume les caracte´ristiques principales
des clusters pour R = 0.1 et diffe´rentes valeurs de λ.
On remarquera que malgre´ l’augmentation de l’intensite´ des nœuds, l’excentricite´
moyenne e˜(u/C) d’un nœud dans son cluster et la hauteur moyenne des arbres de
clustering restent constante, du fait du nombre constant de clusters. Ceci va s’ave´rer
eˆtre un atout lors de l’utilisation de notre structure pour effectuer une diffusion (cf.
chapitre 4) ou pour router sur cette structure (cf. chapitre 5). Nous pouvons e´galement
noter qu’une grande partie des nœuds sont des feuilles dans l’arbre de clustering (en-
viron 75%). Comme nous le verrons dans le chapitre 4, cette proprie´te´ va elle aussi
s’ave´rer fort utile lors d’une diffusion d’un message sur une telle structure.
34 CHAPITRE 3. ALGORITHME DE CLUSTERING
500 nœuds 600 nœuds 700 nœuds
# clusters/arbres 11.76 11.51 11.45
e˜(u/C) 3.70 3.75 3.84
e˜(H(u)/C(u)) 3.01 3.09 3.37
Hauteur des arbres 3.27 3.34 3.33
% feuilles 73,48% 74,96% 76,14%
Degre´ dans l’arbre des nœuds non feuilles 3.82 3.99 4.19
Voronoı¨ : distance euclidienne 84.17% 84.52% 84.00%
Voronoı¨ : nombre de sauts 85.43% 84.55% 84.15%
800 nœuds 900 nœuds 1000 nœuds
# clusters/arbres 11.32 11.02 10.80
e˜(u/C) 3.84 3.84 3.84
e˜(H(u)/C(u)) 3.17 3.19 3.23
Hauteur des arbres 3.34 3.43 3.51
% feuilles 76,81% 77,71% 78,23%
Degre´ dans l’arbre des nœuds non feuilles 4.36 4.51 4.62
Voronoı¨ : distance euclidienne 83.97% 83.82% 83.70%
Voronoı¨ : nombre de sauts 83.80% 83.75% 83.34%
TAB. 3.5 – Caracte´ristiques des clusters.
Forme des clusters.
Comme le montre la figure 3.7, les clusters ressemblent a` un diagramme de Vo-
ronoı¨ construit autour des chefs de clusters. Si S est un ensemble de n sites de l’espace
euclidien, pour chaque site p de S, la cellule de Voronoı¨ V (p) de p est l’ensemble des
points de l’espace qui sont ge´ographiquement plus proches de p que de tous les autres
sites de S. Le diagramme de Voronoı¨ de V (S) est la de´composition de l’espace en
cellules de Voronoı¨ des sites de l’espace.
Ainsi, cela signifierait qu’e´tant donne´s les cluster-heads, un nœud s’est attache´ a` celui
le proche de lui en distance euclidienne. Afin d’e´valuer cette caracte´ristique, nous avons
mene´ des simulations pour connaıˆtre le pourcentage de nœuds se situant dans la cellule
de Voronoı¨ de leur chef et e´tant donc plus pre`s de lui que de tout autre chef en distance
euclidienne. De plus, comme dans un re´seau sans fil, on ne conside`re pas la distance
euclidienne mais la distance en nombre de sauts, nous avons e´galement regarde´ quelle
proportion de nœuds e´taient plus proches en nombre de sauts de leur propre chef plutoˆt
que de tout autre. Les re´sultats nume´riques sont donne´s dans la table 3.5. La figure 3.8
donne pour une topologie de clusters (figure 3.8(a)) la proportion des nœuds se situant
dans la ”bonne” cellule de Voronoı¨ en distance euclidienne (figure 3.8(b)) et en nombre
de sauts (figure 3.8(c)). On remarquera que plus de 80% sont plus proches de leur
cluster-head que d’un autre aussi bien en distance euclidienne qu’en nombre de sauts.
Ceci pre´sente un avantage e´galement pour la diffusion d’un message dans un cluster,
comme nous le verrons plus tard dans le chapitre 4.
3.6. ANALYSE DE LA STRUCTURE 35
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
FIG. 3.7 – Structure de clusters (sche´mas de gauche) et diagramme de Voronoı¨ corres-
pondants (sche´mas de droite) pour λ = 1000 et λ = 500.
(a) Topologie (b) Voronoı¨ euclidien (c) Voronoı¨ sauts
FIG. 3.8 – Pour une structure de clusters (a), les nœuds dans la ”bonne” cellule de
Voronoı¨ en distance euclidienne (b) ou en nombre de sauts (c) apparaissent en noir.
36 CHAPITRE 3. ALGORITHME DE CLUSTERING
3.7 Comparaison a` d’autres heuristiques
Dans le but d’e´valuer notre heuristique et d’eˆtre en mesure de la situer parmi les
heuristiques existantes, nous la comparons a` d’autres heuristiques de la litte´rature :
DDR [59] et Max-Min d-cluster [4]. Ces heuristiques, de´crites dans le chapitre 2
construisent des clusters dont le rayon est supe´rieur a` 1 saut comme notre heuristique.
Max-Min d-cluster utilise l’identifiant des nœuds mais cherche a` ne pas toujours fa-
voriser l’identifiant le plus fort et ainsi e´viter que les plus grands identifiants soient
toujours cluster-heads. DDR, quant a` lui, est tre`s semblable a` notre algorithme mais
se base sur le degre´ des nœuds.
3.7.1 Comparaison avec DDR
L’heuristique de DDR [59] construit des clusters de fac¸on assez similaire a` la noˆtre
mais utilise le degre´ des nœuds comme me´trique au lieu de la densite´. Tout comme dans
notre cas, le rayon des clusters n’est pas fixe´ a` l’avance et s’adapte automatiquement a`
la topologie sous-jacente. Le degre´ est moins couˆteux que la densite´ puisqu’il ne´cessite
la connaissance du 1-voisinage seulement. C’est pourquoi, nous avons voulu comparer
les structures de clusters obtenues pour chacune des heuristiques.
(a) Clusters DDR (b) Clusters Densite´
FIG. 3.9 – Exemple de structure obtenue pour λ = 1000 et R = 0.1 avec DDR (a) et
avec la 1-densite´ (b).
Nb clusters Nb nœuds par cluster D˜(C) e˜(u/C)
DDR 10.0 100 5.8 4.2
densite´ 11.1 90.9 5.0 3.8
TAB. 3.6 – Comparaison des clusters de DDR et de ceux obtenus par notre heuristique.
3.7. COMPARAISON A` D’AUTRES HEURISTIQUES 37
Les re´sultats sont donne´s par la figure 3.9 et la table 3.6. On remarquera que les struc-
tures sont tre`s semblables. Nous avons alors compare´ la robustesse des structures face
a` la mobilite´ des nœuds. Afin de permettre le passage a` l’e´chelle de la structure et de
limiter les e´changes entre les nœuds, les chefs de cluster doivent rester chefs aussi long-
temps que possible tout en maintenant des clusters adapte´s a` la topologie sous-jacente.
Les auteurs de [66] donnent la de´finition suivante de la robustesse : ”one measure of ro-
bustness of the topology is given by the maximum number of nodes that need to change
their topology information as a result of a movement of a node 2” . C’est pourquoi,
nous avons mene´ des simulations en appliquant une mobilite´ sur les nœuds et releve´
la proportion de chefs e´tant re´-e´lus. Plus ce ratio est grand, moins importants sont les
changements des informations des tables de routage des nœuds.
Dans nos simulations, chaque nœud peut bouger ale´atoirement dans une direction
ale´atoire a` une vitesse ale´atoire allant de 0 a` 10m/s (mode`le voiture) et de 0 a` 1.6m/s
(mode`le pie´ton) durant 15 minutes (Mode`le Random Way Point). La table 3.7 donne le
pourcentage de cluster-heads re´-e´lus toutes les 2 secondes par chacune des heuristiques.
Les re´sultats montrent qu’en moyenne, notre heuristique reconstruit moins souvent les
clusters que DDR. Elle s’ave`re donc eˆtre plus robuste.
500 nœuds 600 nœuds 800 nœuds 1000 nœuds
ρ DDR ρ DDR ρ DDR ρ DDR
1.6m/s 68.7% 65% 67.2% 63.5% 64.5% 62.4% 62.2% 56.8%
10m/s 30.1% 27.5% 27% 25.3% 26.2% 23.1% 24.8% 20.35%
TAB. 3.7 – % de cluster-heads re´-e´lus.
De par la mobilite´ des nœuds, un nouveau nœud peut apparaıˆtre dans le voisinage
d’un autre. De fac¸on a` comprendre pourquoi la me´trique de densite´ est plus stable que
le degre´ utilise´ par DDR, nous avons analyse´ comment le voisinage d’un nœud est
perturbe´ par l’apparition de ce nouveau nœud. La structure de clusters se re-construit si
le nœud qui avait le plus fort degre´ ou la plus forte densite´ dans son voisinage se trouve
un voisin dont le degre´ ou la densite´ est devenu(e) plus fort(e) que le/la sien(ne), donc
si l’ordre des degre´s ou densite´s entre les nœuds a change´.
Nous conside´rons un processus ponctuel de Poisson d’intensite´ λ, distribue´ dans une
boule de rayon 2R centre´e en un point 0 : B(0, 2R). Nous conside´rons alors le degre´ et
la densite´ de ce point 0 ainsi que ceux d’un de ses voisins y choisi arbitrairement. Nous
ajoutons alors le nœud mobile u dans le voisinage de 0. u est un nœud uniforme´ment
distribue´ dans B(0, R). Nous pouvons alors calculer la probabilite´ que l’ordre des
degre´s de 0 et y change a` cause de la pre´sence de u. Cela ne peut se faire que si u
n’est pas voisin de y et si δ(0) = δ(y) ou δ(0) = δ(y)− 1. En effet, si u est voisin a` la
fois de 0 et de y, l’ordre ne changera pas. Si u n’est voisin que de 0 et si δ(0) > δ(y),
seul le degre´ de 0 augmente, ce qui ne change pas l’ordre. De meˆme si δ(0) < δ(y)−1,
meˆme si le degre´ de 0 augmente de 1, il reste infe´rieur a` δ(y).
2Une mesure de la robustesse de la topologie est donne´e par le nombre maximum de nœuds qui doivent
changer leur information sur la topologie pour le mouvement d’un nœud.
38 CHAPITRE 3. ALGORITHME DE CLUSTERING
Soit C une variable de´signant la re´gion du plan B(0, R)\B(y,R). C correspond a` la
zone de voisinage du nœud 0 dans laquelle les nœuds ne sont pas voisins de y (Voisi-
nage de 0 non colore´ sur la figure 3.4 ou` on prend u = 0 et v = y). ν(C) est la mesure
de Lebesgue de C = B(0, R)\B(y,R).
La probabilite´ P1 que u ne soit voisin que du nœud 0 revient a` la probabilite´ que u se
t d l d C D P = ν(C)rouve ans a zone e . ’ou` : 1 piR2 .
La probabilite´ P2 que δ(0) = δ(y) est la probabilite´ que 0 et y aient autant de voisins
non communs avant l’arrive´e de u. D’ou` :
∑∞
P2 = P(Φ(B(0, R)\B(y,R)) = k)× P(B(y,R)\B(0, R) = k)
k∑=0∞ λ2kν(C)2k
= exp−2λν(C)
k!k!
k=0
La probabilite´P3 que δ(0) = δ(y)−1 est la probabilite´ que y ait un voisin non commun
avec 0 en plus de 0. D’ou` :
∑∞
P3 = P(Φ(B(0, R)\B(y,R)) = k)× P(Φ(B(y,R)\B(0, R)) = k + 1)
k∑=0∞ λ2k+1ν(C)2k+1
= exp−2λν(C)
k!(k + 1)!
k=0
A` partir de la`, pour obtenir la probabilite´ Pp que l’ordre change, il nous faut faire la
moyenne sur tous les points y, en multipliant par la probabilite´ que y existe, c.a`.d. par
la probabilite´ P(Φ(B(0, R)) > 0) que le nœud 0 ait au moins un voisin. Sachant que
y est uniforme´ment distribue´ dans B(0, 2R), la probabilite´ Pp que l’ordre change peut
alors s’e´crire :
Pp = E [P1(P2 + P3)]P( (Φ(B(0, R)) > 0)− {− })= E [[P1(P2 + P )] 1 exp λpiR2∑ 3 ]+∞ 2nν(C) (λν(C)) λν(C) ( − {− })= E (1 + ) 1 exp λpiR2
piR2 n!n! n+ 1
n=0
Malheureusement, nous n’avons pas e´te´ en mesure de donner un re´sultat analytique
donnant la probabilite´ que l’ordre des densite´s des nœuds 0 et y soit perturbe´ par l’ar-
rive´e du nœud u. Ne´anmoins, nous avons obtenu une approximation par simulation. La
figure 3.10 donne les probabilite´s que l’ordre change pour les deux me´triques (obtenues
par simulation) et la probabilite´ Pp obtenue analytiquement pour le degre´.
Ces re´sultats correspondent a` ceux obtenus pre´ce´demment dans la table 3.7. La pro-
babilite´ que l’ordre des me´triques change avec l’apparition d’un nœud mobile dans un
voisinage est plus importante pour le degre´ que pour la densite´. Cela tend a` prouver
que la structure base´e sur la densite´ est plus stable que celle base´e sur le degre´.
3.7. COMPARAISON A` D’AUTRES HEURISTIQUES 39
 0.1
degree
density
theoritical probability for the degree as metric
 0.09
 0.08
 0.07
 0.06
 0.05
 0.04
 0.03
 15  20  25  30  35  40  45  50  55
mean number of neighbors
FIG. 3.10 – Probabilite´ que l’ordre des me´triques change entre deux voisins.
3.7.2 Comparaison avec l’heuristique Max-Min d-cluster
L’heuristique Max-Min d-cluster [4] produit e´galement des clusters dont le rayon est
supe´rieur a` 1. La structure de Max-Min a obtenu de tre`s bons re´sultats de stabilite´. Elle
utilise l’identifiant des nœuds mais tente de contrebalancer le fait qu’un cluster-head
e´lu sur cette me´trique garde son roˆle quasi-inde´finiment, en e´lisant non pas le plus
grand ou plus petit identifiant mais le nœud posse´dant le plus petit identifiant parmi les
plus grands identifiants des nœuds se trouvant a` au plus d sauts de lui. Le parame`tre d
est le rayon des clusters et doit eˆtre fixe´ a priori.
Structure.
Nb clusters Nb de nœuds par cluster D˜(C) e˜(u/C)
densite´ 11.1 90.9 5.0 3.8
Max-Min 2-cluster 28.6 34.9 3.6 3.1
Max-Min 3-cluster 13.3 75.2 4.9 3.4
Max-Min 4-cluster 8.2 122.0 6.5 4.9
TAB. 3.8 – Caracte´ristiques des clusters de la densite´ et de Max-Min d-cluster.
Dans un premier temps, nous avons simule´ Max-Min d-cluster pour plusieurs valeurs
du rayon d. Les re´sultats donne´s dans la table 3.8 nous montrent que l’heuristique Max-
Min pour d = 3 est la plus proche de notre heuristique. Par la suite, c’est celle que nous
conside´rerons.
La figure 3.11 donne le nombre de clusters produits par notre heuristique et par Max-
Min 3-cluster pour λ = 1000 et diffe´rentes valeurs de R.
On remarquera que le nombre de clusters obtenu est similaire pour les deux me´triques
mais Max-Min 3-cluster construit des clusters plus petits lorsque le re´seau est peu
probabilities
40 CHAPITRE 3. ALGORITHME DE CLUSTERING
55
MaxMin
Density
50
45
40
35
30
25
20
15
10
5
60 70 80 90 100 110 120 130 140 150
Radius (meters)
FIG. 3.11 – Nombre de clusters forme´s pour diffe´rentes valeurs de R avec la densite´
(−×−) et Max-Min 3-cluster (−+−).
dense. Notre heuristique s’adapte mieux aux re´seaux peu denses puisqu’il produit des
clusters plus adapte´s et en plus petit nombre. De plus, contrairement a` l’heuristique de
Max-Min, notre algorithme n’autorise pas la formation de clusters a` un seul nœud qui
sont inutiles.
Les figures 3.12 (a) et (b) donnent un exemple de structure de clusters obtenue par
simulation par chacune des heuristiques sur une meˆme distribution des nœuds. Dans
les deux cas, les clusters semblent homoge`nes. Les chefs de clusters sont bien re´partis
dans l’espace.
(a) Clusters obtenus par Max-Min 3- (b) Clusters obtenus par notre heuris-
cluster tique
FIG. 3.12 – Exemple d’une structure de clusters pour une topologie a` 1000 nœuds de
rayon de transmission R = 0.1 obtenue avec Max-Min 3-cluster (a) et avec l’heuris-
tique utilisant la densite´ (b).
# of clusters
3.7. COMPARAISON A` D’AUTRES HEURISTIQUES 41
Comparaison face a` la mobilite´ des nœuds.
De la meˆme fac¸on que pour DDR, nous avons compare´ l’heuristique de Max-Min
et la noˆtre face a` la mobilite´ des nœuds, en effectuant des simulations ou` les nœuds
bougeaient a` diffe´rentes vitesses ale´atoires. Nous avons pu constater que Max-Min d-
cluster re´-e´lit les meˆmes cluster-heads dans plus de 90% des cas. Cela e´tait pre´visible
e´tant donne´ que l’e´lection conside`re l’identite´ des nœuds qui ne change pas lorsque les
nœuds bougent. En se basant seulement sur ces re´sultats, on pourrait donc pre´tendre
que Max-Min est plus stable que notre heuristique. Seulement, l’identifiant des nœuds
e´tant inde´pendant de la topologie sous-jacente, les clusters nouvellement reforme´s ne
sont pas toujours adapte´s a` la topologie. Afin d’e´valuer cela, nous avons conside´re´ plus
en de´tail l’apparition des nœuds.
Dans les re´sultats suivants, pre´sente´s dans la table 3.9, nous conside´rons une topologie
initiale de 500 nœuds dans laquelle apparaissent progressivement de fac¸on ale´atoire,
dix vagues de 100 nouveaux nœuds, avec des identifiants ale´atoires. Ces re´sultats
donnent le pourcentage de cluster-heads re´-e´lus et le pourcentage d’augmentation du
nombre de clusters dans le re´seau.
% cluster-heads re´-e´lus Evolution du nombre de clusters
densite´ 94.3% +0%
Max-Min 3-cluster 100% +46%
TAB. 3.9 – Comparaison de Max-Min 3-cluster et de l’heuristique de densite´ face a`
l’arrive´e des nœuds.
On remarque que meˆme si Max-Min re´-e´lit toujours les meˆmes chefs de cluster, l’heu-
ristique en e´lit e´galement d’autres. L’heuristique de densite´ quant a` elle incorpore les
nouveaux nœuds dans les clusters existants. Le comportement de Max-Min est duˆ au
fait que si un nouveau nœud a un identifiant supe´rieur au chef de´ja` en place, il cre´e´ son
propre cluster en ne modifiant les clusters existants que s’il est dans le voisinage d’un
ancien chef. Dans le cas contraire, les anciens clusters restent inchange´s. Le nouveau
nœud e´tant souvent le seul nœud de son cluster nouvellement forme´.
Comparaison des structures sur des topologies non uniformes.
Enfin, nous avons compare´ les structures obtenues par notre heuristique et Max-Min sur
des topologies de nœuds non uniformes. Les nœuds sont distribue´s autour de quelques
points choisis ale´atoirement qui pourraient repre´senter des villes. Les figures 3.13 (a)
et (b) illustrent une telle topologie. On peut remarquer que notre heuristique ge´ne`re
moins de clusters avec des cluster-heads mieux centre´s. Max-Min ge´ne`re la` aussi des
clusters a` 1 nœud ou des clusters-heads voisins. Par exemple, sur une meˆme topologie
de 1000 nœuds, notre heuristique ge´ne`re 8.7 clusters en moyenne contre 15.25 clusters
pour Max-Min.
42 CHAPITRE 3. ALGORITHME DE CLUSTERING
(a) Clusters obtenus par Max-Min 3- (b) Clusters obtenus par notre heuris-
cluster tique
FIG. 3.13 – Distribution non uniforme de nœuds : clusters obtenus avec Max-Min 3-
cluster (a) et avec la me´trique de densite´ (b).
Complexite´.
L’heuristique de Max -Min d-cluster se compose de 3 phases de diffusion de messages
a` d sauts : une phase re´cupe´rant le plus grand identifiant a` d sauts, une phase re´cupe´rant
le plus petit identifiant parmi les plus grands a` d sauts et enfin une phase pour diffuser
l’identite´ du chef de cluster. Notre heuristique, quant a` elle, est purement locale et
ne ne´cessite qu’une information sur le 2-voisinage obtenue par des messages diffuse´s
uniquement dans le 1-voisinage. Max-Min d-cluster s’ave`re donc plus couˆteux en terme
de messages et de latence que notre algorithme.
3.8 Analyse de l’auto-stabilisation
Comme nous avons pu le constater dans le chapitre 2, il existe de nombreux proto-
coles de clustering pour les re´seaux sans fil. Cependant, seulement tre`s peu ve´rifient
la robustesse de leur algorithme et, meˆme quand c’est le cas, l’e´valuation est mene´e
par simulation et jamais via une analyse the´orique. Dans cette section, nous appliquons
les principes d’auto-stabilisation a` notre algorithme de clustering. L’auto-stabilisation
est la proprie´te´ d’un syste`me a` atteindre seul une configuration dans laquelle il a un
comportement correct, en partant de n’importe quelle configuration arbitraire. A` l’aide
d’une approche the´orique, nous montrons que, sous certaines hypothe`ses, l’algorithme
est auto-stabilisant localement et que le temps de convergence est faible et borne´. Nous
validons ensuite cette proprie´te´ par simulation.
3.8. ANALYSE DE L’AUTO-STABILISATION 43
3.8.1 Pre´-requis
Nous pre´sentons dans un premier temps les diffe´rentes hypothe`ses. Nous conside´rons
que l’algorithme se stabilise lorsque chaque nœud connaıˆt l’identite´ de son cluster-
head. Le temps de stabilisation est donc lie´ a` la hauteur des arbres de clustering, l’iden-
tite´ du chef devant eˆtre transmise jusqu’aux feuilles de l’arbre. Nous suivons les meˆmes
principes et hypothe`ses que dans [38] :
Hypothe`ses. Nous supposons qu’il existe une constante τ > 0 telle que la probabilite´
qu’un paquet soit transmis sans collision entre deux nœuds voisins est au moins τ . Cela
implique que nous supposons que tous les nœuds parviennent a` e´mettre avec succe`s
un message en une e´tape de temps de´pendant de τ . Cela correspond aux hypothe`ses
classiques concernant les canaux multi-acce`s [14]. Cette hypothe`se est justifie´e en an-
nexes 3.11.3. Nous supposons e´galement qu’il existe une constante∆ connue, telle que
pour tout nœud u, δ(u) ≤ ∆. Ceci peut eˆtre ve´rifie´ par un controˆle de topologie qui est
en mesure d’ajuster la porte´e de communication ou la puissance de transmission des
nœuds lorsque le re´seau est trop dense.
Notation. Nous de´crivons les algorithmes sous la forme de re`gles garde´es. G → S
repre´sente une telle re`gle, ou` G est un pre´dicat sur les variables locales d’un nœud,
S une affectation de ces meˆmes variables locales. Si le pre´dicat G (la garde) est
vrai, l’affectation S est exe´cute´e, sinon elle est ignore´e. Certaines gardes peuvent eˆtre
de´clenche´es sur e´ve´nement, par exemple lors de la re´ception d’un message. Nous sup-
posons que ces e´ve´nements s’exe´cutent de manie`re atomique lors de la re´ception d’un
message. Pour toute configuration du syste`me, quand une garde G est vraie, G est
dite activable dans cette configuration. L’ope´rateur [] correspond a` la composition non-
de´terministe des re`gles garde´es ; ([]q : q ∈ Mp : Gq → Sq) est une formula-
tion re´duite de l’expression Gq1 → Sq [] Gq → Sq [] · · · [] Gq → Sq , ou`1 2 2 k k
Mp = {q1, q2, . . . , qk}.
Se´mantique de l’exe´cution. L’exe´cution du syste`me consiste pour chaque nœud a`
e´valuer pe´riodiquement ses re`gles garde´es. Nous supposons que chaque re`gle acti-
vable est exe´cute´e en un temps constant (ou ignore´e si la re`gle n’est pas activable).
De manie`re ge´ne´rale, nous conside´rons que lorsqu’un nœud exe´cute son programme,
toutes ses re`gles activables sont effectivement exe´cute´es en un temps constant (par
exemple en suivant le mode`le du tourniquet).
Propagation des variables partage´es. Certaines variables des nœuds sont dites par-
tage´es. Suivant le sche´ma pre´sente´ en [38], les nœuds diffusent pe´riodiquement les
valeurs de leurs variables partage´es. Cela signifie que lorsqu’un nœud affecte une va-
leur a` une variable partage´e, nous supposons que cette instruction est transforme´e de
telle sorte que, d’une part la variable partage´e est re´gulie`rement transmise au voisinage
du nœud, et que d’autre part cette retransmission s’effectue de manie`re probabiliste
pour e´viter les collisions. Une implantation possible peut eˆtre trouve´e dans [38]. Dans
la suite, nous supposons e´galement que le sche´ma de [38] est utilise´ pour obtenir Γ(u)
et Γ2(u) pour chaque nœud u.
44 CHAPITRE 3. ALGORITHME DE CLUSTERING
3.8.2 Construction d’un DAG de hauteur constante
Un DAG ou Directed Acyclic Graph est un graphe simple oriente´ et sans boucle. Dans
notre algorithme, comme dans tout algorithme utilisant l’identifiant des nœuds comme
crite`re de de´cision finale sans contrainte sur le rayon du cluster (comme dans DDR),
le pire cas en terme de stabilisation et de formation de clusters se rencontre quand
tous les nœuds ont la meˆme valeur de de´cision (comme le degre´ ou la densite´) et que
les identifiants des nœuds sont uniques et mal distribue´s. L’algorithme peut alors ne
construire qu’un seul cluster dont le diame`tre est aussi grand que celui du re´seau, le
temps de stabilisation de´pendant de ce diame`tre. De plus, il est e´vident que construire
un tel cluster est inutile puisque nous pourrions tout aussi bien utiliser directement
le re´seau. Pour pallier cet inconve´nient, il peut s’ave´rer utile d’allouer une couleur aux
nœuds, couleur choisie dans un espaceΩ constant et plus petit que celui des identifiants,
de fac¸on a` ce que les couleurs soient localement uniques (dans notre cas, les couleurs
doivent eˆtre uniques a` distance 2 pour qu’un nœud puisse choisir entre deux voisins en
compe´tition) et d’utiliser ces couleurs comme crite`re de de´cision finale. Un DAG peut
alors eˆtre construit a` partir de ces couleurs en orientant les areˆtes entre les voisins de la
couleur la plus grande vers la plus petite.
Notre construction de DAG a` hauteur constante est base´e sur la technique ale´atoire
de´crite dans [38], mais utilise un espace de couleur beaucoup plus petit Ω (|Ω| =
∆6 dans [38] tandis que ∆2, ou meˆme ∆ est suffisant dans notre cas avec ∆ =
maxu∈V δ(u)).
Soit Coloru ∈ Ω une variable partage´e de´signant la couleur du nœud u. Soit
ColorΓ(u) = {)Color v | v ∈ Γ(u)}, ou` )Colorv re´fe`re a` la copie en cache de
la variable partage´e Colorv au nœud u. En d’autres termes, Color v correspond a` la
couleur que u pense que v a.
Supposons que random(S) choisit avec une probabilite´ uniforme un e´le´ment dans un
ensemble S. Le nœud u{utilise la fonction suivante pour calculer Coloru :
)Coloru si )Color ∈6 Color( ) = u Γ(u)newColor Coloru
random(Ω \ ColorΓ(u)) sinon
L’algorithme de construction d’un DAG a` hauteur constante est le suivant :
N1 : VRAI → Coloru := newColor(Coloru)
The´ore`me 1 L’algorithme N1 stabilise avec probabilite´ 1 en un temps constant vers
un DAG de hauteur infe´rieure ou e´gale a` |Ω|+ 1.
Preuve 1 La preuve de ce the´ore`me est similaire a` celle de [38]. Supposons que la
hauteur du DAG soit supe´rieure a` |Ω| + 1. Cela signifie qu’il existe au moins deux
nœuds de meˆme couleur sur une branche du DAG (sur un chemin reliant la racine a`
une feuille). Or, les areˆtes du DAG sont oriente´es en fonction des couleurs des nœuds
qui sont ordonne´es. Si sur la meˆme branche, il existe deux nœuds u et v de meˆme
couleur, cela implique que Coloru < Colorv , ce qui contredit l’hypothe`se d’ordre total
des couleurs. 
3.8. ANALYSE DE L’AUTO-STABILISATION 45
3.8.3 Analyse de la construction du DAG de couleurs
Nous avons cherche´ a` caracte´riser le DAG que nous construisons et son couˆt. Pour
cela, nous avons analyse´ analytiquement et par simulation le temps de construction
du DAG qui correspond au temps de stabilisation de l’algorithme de coloriage. Nous
avons e´galement mesure´ par simulation l’influence de la taille du domaine des couleurs
Ω sur ce temps de stabilisation et sur la taille du DAG re´sultant. Comme nous allons
le voir, il en ressort qu’un compromis est a` faire pour de´terminer le parame`tre Ω : plus
la valeur de |Ω| est grande, plus le temps de convergence de N1 est faible mais plus la
hauteur du DAG est importante. Une hauteur de DAG importante augmente le temps
de stabilisation des algorithmes qui se basent sur ces DAG.
Analyse the´orique du temps de convergence.
Le temps de convergence de l’algorithme de coloriage N1 correspond au nombre
d’e´tapes ne´cessaires avant que chaque nœud ait une couleur unique dans son voisinage.
Pour mener cette e´tude the´orique, nous nous sommes inspire´s du protocole NAP [21].
Nous mode´lisons l’algorithme de coloriage par des lance´s successifs de boules dans des
urnes. L’ensemble des couleurs est repre´sente´ par M urnes dans lesquelles L boules
repre´sentant les nœuds sont distribue´es.
L’algorithme de coloriage peut eˆtre mode´lise´ de la fac¸on suivante en termes d’urnes et
de boules :
Algorithm 2 COLORIAGE(L, M )
⊲ Entre´es : M urnes et L boules
⊲ Pre´-condition : M ≥ L
if (L 6= 0) then
Lance ale´atoirement L boules dans les M urnes ;
Met de coˆte´ toutes les urnes contenant exactement une boule avec leur boule ;
Soit c ≤M le nombre d’urnes isole´es ;
Appelle COLORIAGE(L− c, M − c) ;
end
On remarque qu’une telle analyse ne conside`re que des graphes complets. Dans un
re´seau sans fil qui n’est pas ne´cessairement un graphe complet, deux nœuds voisins (A
et B) n’e´tant pas en conflit mutuel peuvent tout de meˆme tirer une nouvelle couleur
simultane´ment s’ils sont chacun en conflit avec un autre de leur voisin non visible par
A ou B, ce qui n’est pas conside´re´ dans cette analyse. Ainsi, l’e´tude suivante nous
fournit une borne infe´rieure sur le temps de stabilisation de l’algorithme. Cet aspect est
plus de´taille´ dans [55].
Dans chaque voisinage, le but est alors de n’avoir qu’une seule boule (un nœud) as-
socie´e a` une seule urne donne´e (une couleur). Soit la variable ale´atoire N repre´sentant
le nombre d’ite´rations ne´cessaires pour obtenir une telle configuration. Le temps de
convergence moyen de l’algorithme est l’espe´rance de N : E[N ]. Pour de´terminer
46 CHAPITRE 3. ALGORITHME DE CLUSTERING
E[N ], nous conside´rons une chaıˆne de Markov a` temps discret X = {Xn, n ∈ N}
sur l’espace I = 0, 1, ..., L. Xn = i repre´sente le fait qu’apre`s n transitions, exacte-
ment i boules et urnes ont e´te´ mises de coˆte´.
Nous notonsP(L,M) = (pi,j(L,M))(i,j)∈I2 la matrice de probabilite´ de transition de
la chaıˆne de Markov X . L’espe´rance E[N ] peut eˆtre de´duite du calcul des pi,j(L,M).
pi,j(L,M) repre´sente la probabilite´ d’avoir exactement j urnes de coˆte´ au temps n+1
sachant que i urnes e´taient de coˆte´ au temps n. pi,j(L,M) peut aussi eˆtre vu comme
la probabilite´ d’obtenir exactement j − i urnes avec exactement une boule en lanc¸ant
L− i boules dans M − i urnes. Nous obtenons donc, pour tout i ≤ j :
pi,j(L,M) = pi,j = p0,j−i(L− i,M − i). (3.1)
X est acyclique et l’e´tatL est un e´tat absorbant. Cela signifie que pour tout i ∈ I−{L}
et tout j ∈ I, pi,j(L,M) = 0 si i > j et pL,L(L,M) = 1.
Graˆce a` la relation 3.1, nous pouvons ne calculer que les valeurs des p0,j−i(L−i,M−i)
pour i ≤ j pour obtenir toutes les valeurs de la matrice P(L,M).
p0,j(L,M) est la probabilite´ d’obtenir exactement j urnes avec exactement une boule
lors du lancer de L boules dans M urnes. Le cas j = L conduit au proble`me des
anniversaires, d’ou` :
M !
p0,L(L,M) =
(M − L)!ML
Pour j < L, nous proce´dons de la sorte. L boules sont lance´es dans M urnes. On note
K0(L,M) le nombre d’urnes vides et K1(L,M) le nombre d’urnes contenant exacte-
ment une boule. Soit aL,M (k, j) la distribution jointe des deux variables ale´atoires K0
et K1 :
aL,M (k, j) = P[K0(L,M) = k, K1(L,M) = j]
Les p0,j(L,M) peuvent alors s’e´crire :
∑M
p0,j(L,M) = P[K1(L,M) = j] = aL,M (k, j)
k=0
Ainsi, afin de calculer la matrice de transition P(L,M), il ne nous reste qu’a`
de´terminer les aL,M (k, j). Pour cela, nous raisonnons par re´currence en conditionnant
le re´sultat du dernier lancer : pour obtenir k urnes vides et j urnes avec exactement une
boule en lanc¸ant L boules dans M urnes il faut qu a` la fin du lancer de la L − 1ieme, ’
balle :
1. soit avoir k + 1 urnes vides et j − 1 urnes avec exactement une boule et lancer
la dernie`re boule dans une urne vide ;
2. soit avoir k urnes vides et j + 1 urnes avec exactement une boule et lancer la
dernie`re boule dans une urne qui contenait exactement une boule ;
3. soit avoir k urnes vides et j urnes avec exactement une boule et lancer la dernie`re
boule dans une urne qui contenait au moins deux boules.
3.8. ANALYSE DE L’AUTO-STABILISATION 47
Pour L ≥ 2, on obtient :
k + 1 j + 1 M − (j + k)
aL,M (k, j) = aL−1,M (k+1, j−1)1{j≥1}+ aL−1,M (k, j+1)+ aL−1,M (k, j)
M M M
ou` 1{c} = 1 si la condition c est remplie et 0 sinon.
Les aL,M (k, j) peuvent eˆtre calcule´s par re´cursion en conside´rant que si L = 1 :
a1,M (k, j) = 1{k=M−1, j=1}
On remarque aussi que aL,M (k, j) = 0 si j > L, si k = M ou si j+k > M . De meˆme,
si j = L, on a aL,M (k, L) = 0 pour k 6= M − L et aL,M (M − L,L) = p0,L(L,M).
Une fois la matrice de probabilite´s de transition obtenue, on peut de´terminer la dis-
tribution de N (P [N = n] pour n = 0, . . . ,∞) et sa valeur moyenne E [N ]. Les cal-
culs sont les meˆmes que ceux mene´s dans l’e´tude du protocole NAP. Ils de´rivent des
re´sultats classiques des chaıˆnes de Markov. Nous les utilisons directement ici.
Nous de´finissonsQ la sous-matrice obtenue a` partir deP(L,M), en retirant la dernie`re
ligne et la dernie`re colonne qui correspondent a` l’e´tat absorbant L.
Soit α le vecteur ligne contenant la distribution initiale des probabilite´s des e´tats tran-
sitoires de X . α est tel que α = (P [X0 = i])i=0,...,L−1. La chaıˆne de Markov X
commence en l’e´tat 0 avec la probabilite´ 1, d’ou` α = (1, 0, . . . , 0).
De par les re´sultats classiques des chaıˆnes de Markov, on obtient :
[N = n] = αQn−1P (I −Q)1, pour n ≥ 1,
∑∞
P [N > n] = αQk−1(I −Q)1 = αQn1, pour n ≥ 0,
k=n+1
∑∞
−1
E [N ] = P [N > n] = α (I −Q) 1
n=0
ou` I est la matrice identite´ et 1 le vecteur colonne unite´, tous deux de dimension L.
On note V = (Vi)0≤i≤L−1 le vecteur d’espe´rance conditionnelle de´fini par Vi =
| O − −1E [N X0 = i]. n a V = (I Q) 1. D’ou` E [N ] = αV = V0. Le vecteur V est
solution du syste`me line´aire (I−Q)V = 1. Cela peut s’e´crire e´galement V = 1+QV .
Ainsi, comme la matrice P(L,M) est acyclique, on obtient, pour i = L− 2 . . . , 0 :
L
1 ∑−1
V = 1 + p V i − i,j j1 pi,i j=i+1
Comme VL−1,L−1 = 1/(1 − pL−1,L−1), on peut obtenir V0 re´cursivement, et ainsi,
obtenir le temps de convergence moyen E [N ].
48 CHAPITRE 3. ALGORITHME DE CLUSTERING
Simulations.
Afin de valider nos re´sultats the´oriques et de mesurer l’impact de la taille du domaine
des couleurs Ω sur le temps de convergence et sur la hauteur du DAG, nous avons mene´
des simulations utilisant plusieurs valeurs de |Ω|. Nous avons simule´ l’Algorithme N1
tili t | | | | 2en u san Ω = (maxp∈V Γ(p) ) , cette valeur e´tant celle conside´re´e par certains
algorithmes auto-stabilisants base´s sur le coloriage [38]. Nous avons e´galement e´tudie´
l’Algorithme N1 en utilisant |Ω| = 2 × (maxp∈V |Γ(p)|). De plus, comme dans les
re´seaux sans fil, les nœuds n’ont aucune connaissance globale du re´seau et donc, aucun
moyen a priori de connaıˆtre le plus fort degre´ du graphe, nous avons e´galement mene´
des simulations en utilisant une taille de domaine de couleur propre a` chaque nœud,
t ll q ∀ ∈ | | | | 2e e ue : p V, Ωp = ( Γ(p) ) .
Nous avons alors conside´re´ le temps de convergence et la taille du DAG induit.
Dans un premier temps, nous avons compare´ les re´sultats the´oriques et de simulation
afin de valider chaque approche. La table 3.10 montre les temps de convergence de
l’algorithme de coloriage a` distance 1 sur une topologie grille ou` chaque nœud interne
a respectivement 4 ou 8 voisins. On remarque que les re´sultats s’accordent.
4 voisins 8 voisins
2 ∗Max Max2 2 ∗Max Max2
The´orie Simulation The´orie Simulation The´orie Simulation The´orie Simulation
2.14 2.14 1.56 1.61 1.56 1.67 1.15 1.21
TAB. 3.10 – Temps de stabilisation the´orique et obtenu par simulation avec |Ω| =
(max |N |)2p∈V p ) et |Ω| = 2× (maxp∈V |Np|) dans une grille a` 4 et 8 voisins.
La figure 3.14 montre l’influence de la taille du domaine sur le temps de convergence
et la hauteur du DAG dans le cas d’un coloriage a` distance 1. Les re´sultats montrent
clairement que plus la valeur de |Ω| est grande, plus le temps de convergence de N1 est
faible mais plus la hauteur du DAG est importante. Il y a donc un compromis a` faire
pour de´terminer le parame`tre Ω.
3.8.4 Utilisation des couleurs pour le clustering
Dans cette section, nous re´-e´crivons l’algorithme de clustering avec les re`gles d’auto-
stabilisation. Chaque nœud u maintient deux variables partage´es : ρ(u) et H(u) ou`
ρ(u) est la densite´ du nœud u et H(u) son cluster-head.
Afin d’utiliser le DAG des couleurs dans l’algorithme de clustering,
nous rede´finissons l’ope´rateur d’ordre binaire ≺ de´fini dans la sec-
tion 3 2 de la fac¸on suivante : pour (u, v) ∈ V 2. , u ≺ v si et
seulement si {ρ(u) < ρ(v)} ou {ρ(u) = ρ(v) ∧Age(u) < Age(v)} ou
{ρ(u) = ρ(v) ∧Age(u) = Age(v) ∧ Colorv < Coloru}. Soit max≺ la fonction
de maximum associe´e a` l’ope´rateur d’ordre binaire ≺. Quand un nœud u calcule le
3.8. ANALYSE DE L’AUTO-STABILISATION 49
3 2
2.8
1.95
2.6
2.4
1.9
2.2
2 1.85
1.8
1.8 |Omega| = 2 * Degre Max
1.6 |Omega| = Degre Noeud au carre
|Omega| = 2 * Degre Max |Omega|= Degre Max au carre
1.4 |O|mOemgeag| a=|  D= eDgereg rneo Meuadx  aauu  ccaarrrree 1.75
1.2
1 1.7
500 600 700 800 900 1000 1100 500 600 700 800 900 1000 1100
Intensite du processus lambda Intensite du processus lambda
(a) Temps de stabilisation (b) Hauteur du DAG
FIG. 3.14 – Influence de Ω.
re´sultat de ≺ ou de max≺, il utilise les valeurs cache de son voisinage en supposant
)Coloru = Coloru et )ρ(u) = ρ(u).
Nous de´finisson{s maintenant la fonction clusterHead d’e´lection de cluster-head :
u si ∀v ∈ Γ(u), v ≺ u,
clusterHead = H(max≺{v ∈ Γ(u)}) sinon.
L’algorithme s’exe´cute comme suit :
R1 : VRAI → ρ(u) := densite
R2 : VRAI → H(u) := clusterHead
Lemme 4 Partant de n’importe quelle configuration initiale, chaque nœud u a une
valeur de densite´ correcte ρ(u) en un temps borne´ constant.
Preuve 2 Apre`s un temps constant, chaque nœud u a une vue correcte de son 2-
voisinage. Puis, apre`s l’exe´cution de la re`gle R1, la densite´ ρ(u) du nœud u est cor-
recte. 
Lemme 5 Partant de n’importe quelle configuration initiale, chaque nœud u a une
valeur correcte pour H(u) en un temps borne´ constant.
Preuve 3 Supposons que tout nœud a une valeur correcte de sa densite´ (vrai apre`s
un temps constant d’apre`s le Lemme 4). Apre`s que la variable partage´e ρ(u) ait e´te´
communique´e sans collision a` tout nœud de Γ(u) (cela arrive apre`s un temps constant),
chaque nœud a une valeur cache correcte pour la densite´ de chacun de ses voisins.
Nous conside´rons maintenant le DAG induit par la relation ≺ (note´ DAG≺ par la
suite). En un temps constant, les racines de DAG≺ ont une valeur correcte de l’identite´
de leur cluster-head (puisqu’il s’agit de leur propre identifiant). Supposons que tout
nœud a` distance infe´rieure ou e´gale a` n des racines de DAG≺ a une valeur correcte de
l’identite´ de leur cluster-head. Sur exe´cution de la re`gle R2 sur les nœuds a` distance
Temps de stabilisation
Hauteur du DAG induit
50 CHAPITRE 3. ALGORITHME DE CLUSTERING
n+1 des racines de DAG≺, ces nœuds obtiennent alors une valeur correcte de l’identite´
de leur cluster-head (puisque le cluster-head est de´termine´ de fac¸on de´terministe (i)
par la densite´ et la topologie locale – qui est fixe – et (ii) par l’identite´ des cluster-heads
des nœuds a` distance infe´rieure ou e´gale a` n des racines de DAG≺). Par induction, le
temps ne´cessaire a` la stabilisation de l’algorithme est proportionnel a` la hauteur du
DAG≺.
Nous prouvons maintenant que la hauteur du DAG≺ est borne´e par une constante. Les
couleurs des nœuds sont borne´es par une constante |Ω|. Le nombre d’areˆtes dans le
1 voisinage d un nœud est borne´e par ∆2- ’ , le nombre de 1-voisins est borne´ par ∆,
d ou` le nombre de valeurs possibles pour la densite´ est au plus de ∆3’ , . Le nombre de
couples (densite´ couleur) possibles pour un nœud est |Ω|∆3, , lui-meˆme borne´ par une
constante. Ainsi, la hauteur du DAG≺ est lui-aussi borne´ par une constante.
L’algorithme stabilise en un temps proportionnel a` la hauteur du DAG≺, celle-ci e´tant
constante. Donc le temps de stabilisation est lui aussi borne´ par une constante. 
3.8.5 Validation des proprie´te´s auto-stabilisantes
Comme mentionne´ dans la section 3.8.1, nous supposons l’existence d’une constante
τ > 0 telle que chaque nœud est en mesure de diffuser localement une trame et d’en
recevoir une de chacun de ses voisins en un temps borne´, appele´ une e´tape de temps.
Apre`s une e´tape, chaque nœud connaıˆt ses 1-voisins. Apre`s deux e´tapes, il connaıˆt ses
2-voisins et peut calculer sa valeur de densite´ et apre`s trois e´tapes, il connaıˆt son pe`re.
Le nombre d’e´tapes ne´cessaires a` un nœud pour connaıˆtre l’identite´ de son cluster-head
de´pend directement de la distance qui l’en se´pare et est borne´ par la hauteur de l’arbre
auquel il appartient.
Les simulations mene´es ici nous ont permis d’e´valuer l’importance de l’introduction
des couleurs. Le mode`le de simulation est toujours celui de´crit dans le chapitre 1.1.
Les nœuds sont de´ploye´s suivant un Processus de Points de Poisson avec diffe´rentes
valeurs de λ et de R.
L’allocation des couleurs se fait suivant l’Algorithme N1. Chaque nœud se choisit
ale´atoirement une couleur entre 0 et |Ω| = ∆2 (avec ∆ = maxv∈V δ(u)). Il com-
pare alors sa couleur a` celle de ses voisins. Si deux voisins ont la meˆme couleur, le
nœud dont la couleur est la plus petite se choisit une autre couleur et ainsi de suite jus-
qu’a` ce qu’il n’existe aucune paire de nœuds voisins portant la meˆme couleur. A` partir
de la`, les clusters sont construits suivant l’algorithme 1 en utilisant les couleurs comme
crite`re de de´cision finale.
Les caracte´ristiques des clusters obtenus sont donne´es dans la table 3.11 pour λ = 1000
et diffe´rentes valeurs deR. Bien que donne´s pourλ = 1000, les re´sultats sont similaires
quelle que soit la valeur de λ.
On remarque que quel que soit R (et donc le degre´ δ des nœuds), l’excentricite´
moyenne des cluster-heads et la hauteur des arbres varient peu. Cela confirme notre
hypothe`se stipulant que la transmission de l’identite´ du chef de cluster se fait en un
3.8. ANALYSE DE L’AUTO-STABILISATION 51
temps constant. On notera e´galement que dans un tel cas ou` les densite´s et identifiants
des nœuds sont uniforme´ment distribue´s, l’utilisation des couleurs n’apporte pas grand
chose. Cela est duˆ au fait que dans une telle distribution, les nœuds utilisent uniquement
les densite´s pour de´terminer leur pe`re puisqu’elles sont rarement e´gales.
R = 0.05 (δ = 7.85) R = 0.08 (δ = 20.11) R = 0.1 (δ = 31.42)
Couleurs avec sans avec sans avec sans
Nb clusters 61.0 61.4 19.2 19.5 11.7 11.7
e˜(H(u)/C(u)) 2.6 2.6 3.1 3.1 3.2 3.2
Hauteur arbre-cluster 2.7 2.7 3.3 3.3 3.5 3.5
TAB. 3.11 – Caracte´ristiques des clusters pour une topologie ge´ome´trique ale´atoire
avec λ = 1000.
Conside´rons maintenant un sce´nario ou` les nœuds sont distribue´s dans une grille avec
des identifiants allant croissant de la gauche vers la droite et du bas vers le haut. Dans
ce cas, tous les nœuds inte´rieurs de la grille ont la meˆme valeur de densite´ et le meˆme
degre´. Le seul moyen de choisir leur pe`re est d’utiliser les identifiants. Comme ceux-
ci sont mal re´partis, tous les nœuds vont finalement s’attacher au meˆme cluster-head,
comme le montre le tableau 3.12. Dans un pareil cas, on remarquera que l’introduction
des couleurs est utile car elle permet de re´duire de fac¸on drastique le nombre d’e´tapes
ne´cessaires avant la stabilisation (puisqu’elle re´duit fortement la hauteur des arbres de
clustering) et de construire des clusters plus adapte´s. La figure 3.15 montre un exemple
de clusters obtenus pourR = 0.05. Les cluster-heads apparaissent en bleu, une couleur
par cluster. Sur la figure 3.15(a), les couleurs ne sont pas utilise´es et seulement un
cluster est cre´e´. Sur la figure 3.15(b), les couleurs sont conside´re´es et plusieurs clusters
homoge`nes sont cre´e´s.
Grille 32× 32 Grille 18× 18 Grille 15× 15
Couleurs avec sans avec sans avec sans
Nb clusters 52.8 1.0 29.3 1.0 18.5 1.0
e˜(H(u)/C(u)) 3.4 29.1 4.1 19.1 3.6 6.5
Hauteur arbres-cluster 3.7 83.4 4.7 100.5 4.5 32.1
TAB. 3.12 – Caracte´ristiques des clusters forme´s sur une grille a` 8 voisins.
Dans cette partie, nous avons introduit un me´canisme supple´mentaire dans la construc-
tion des clusters qui permet a` notre algorithme de se stabiliser en un temps rapide
et borne´ et ce, quelle que soit la topologie sous-jacente. Ce caracte`re local d’auto-
stabilisation apporte une stabilite´ a` notre algorithme et une robustesse face aux pannes
et attaques. En effet, lorsqu’un tel phe´nome`ne survient, l’auto-stabilisation permet au
re´seau de ne pas eˆtre impacte´ dans son ensemble par la cassure de liens. Les nœuds
sont capables d’isoler la faute et de la re´parer.
52 CHAPITRE 3. ALGORITHME DE CLUSTERING
(a) sans utiliser les couleurs (b) en conside´rant les couleurs
FIG. 3.15 – Exemple de constructions obtenues pour des grilles a` 8 voisins.
3.9 Conclusion
Dans ce chapitre, nous avons introduit une nouvelle me´trique qui permet d’organiser
un re´seau sans fil multi-sauts en clusters. Nous avons ensuite analyse´ cette me´trique
analytiquement et par simulation, ainsi que la structure de clusters qu’elle permet de
construire. L’algorithme de clustering et le calcul de cette me´trique sont locaux, dis-
tribue´s et ne ne´cessitent la connaissance que du voisinage a` deux sauts pour chaque
nœud. Ils sont donc peu couˆteux et permettent une maintenance locale donc rapide.
L’algorithme de clustering ne repose sur aucun parame`tre fixe´ a priori et a e´te´ prouve´
auto-stabilisant en un temps borne´ et constant. La structure de clusters forme´e pre´sente
d’inte´ressantes caracte´ristiques. Compare´e a` d’autres algorithmes de la litte´rature, elle
s’ave`re plus robuste face a` la mobilite´ des nœuds et s’adapte mieux a` la topologie sous-
jacente.
Tout re´seau doit permettre aux entite´s de communiquer et ne´cessite pour cela un pro-
tocole de routage/localisation et un processus de diffusion de messages. Graˆce aux
caracte´ristiques de notre structure de clusters que nous avons de´gage´es au travers de
nos e´tudes et analyses, nous avons pu proposer deux utilisations de la structure qui
tirent avantage de ces proprie´te´s : un processus de diffusion (chapitre 4) et un proces-
sus de localisation et de routage (chapitre 5) pour permettre aux entite´s du re´seau de
communiquer.
3.10. PUBLICATIONS 53
3.10 Publications
1. Colloques et confe´rences internationaux avec comite´ de lecture :
(a) Self-stabilization in self-organized Multihop Wireless Networks. Nathalie
Mitton, E´ ric Fleury, Isabelle Gue´rin-Lassous and Se´bastien Tixeuil. Work-
shop on Wireless Ad Hoc Networking (WWAN’05), Juin 2005, Columbus,
Ohio, USA.
(b) Self-organization in large scale ad hoc networks. Nathalie Mitton, Anthony
Busson and E´ ric Fleury. Mediterranean Ad Hoc Networking Workshop
(MED-HOC-NET’04), Juin 2004, Bodrum, Turquie.
2. Colloques et confe´rences nationaux :
(a) Auto-stabilisation dans les re´seaux ad hoc. Nathalie Mitton, E´ ric Fleury,
Isabelle Gue´rin-Lassous et Se´bastien Tixeuil. ALGOTEL’05, Mai 2005,
Presqu’ıˆle de Giens, France.
(b) Auto-organisation dans les re´seaux ad-hoc a` grandes e´chelles. Nathalie
Mitton, Anthony Busson et E´ ric Fleury. ALGOTEL’04, Mai 2004, Batz-
sur-mer, France.
(c) Auto-organisation dans les re´seaux ad-hoc a` grandes e´chelles. Natha-
lie Mitton et E´ ric Fleury. Journe´es Graphes Re´seaux et Mode´lisation,
GRM’03, De´cembre 2003, Paris, France.
3. Rapports de recherche :
(a) On Fast Randomized Colorings in Sensor Networks. Nathalie Mitton, E´ ric
Fleury, Isabelle Gue´rin-Lassous and Bruno Se´ricola and Se´bastien Tixeuil.
LRI-1416. Juin 2005.
(b) Self-stabilization in self-organized Multihop Wireless Networks. Nathalie
Mitton, E´ ric Fleury, Isabelle Gue´rin-Lassous and Se´bastien Tixeuil. RR-
5426. De´cembre 2004.
(c) Analysis of the Self - organization in Multi-hops wireless networks. Natha-
lie Mitton, Anthony Busson and E´ ric Fleury. RR-5328. Octobre 2004.
(d) Self-organization in large scale ad hoc networks. Nathalie Mitton and E´ ric
Fleury. RR-5042. De´cembre 2003.
4. Se´minaires, pre´sentations, expose´s :
(a) Auto-organisation dans les re´seaux ad hoc grandes e´chelles. Nathalie Mit-
ton, E´ ric Fleury. Se´minaire ACI Pair a` Pair - Arcachon - France - 6-7 Mai
2004.
54 CHAPITRE 3. ALGORITHME DE CLUSTERING
3.11 Annexes
3.11.1 Analyse de la densite´ moyenne
Nous donnons ici la preuve du lemme 1 qui donne la valeur moyenne de la 1-densite´
d’un nœud :
Lemme 1 La 1-densite´ moyenne d(e tout nœud)u est :√ ( − {− })o 1 3 3 1 exp λpiR2ρ˜(u) = E [ρ(0)] = 1 + pi − λR2 −
2 4 pi
Preuve 4 Soit (Yi)i=1,..,Φ(B′ ), chacun des points de Φ se trouvant dans B′0. Par0
de´finition de la densite´, on a :  
1 Φ∑(B′0) Φ(B′ ∩B′o [ρ(0)] = 1 + o 0 Y )iE E 
2 Φ(B′ )
i=1 0
′ l b l d i d i l { } ′Bu est a ou e centre´e en u e rayon R, pr ve´e u s ng eton u : Bu =
B(u,R)\ {u} Φ(B′ ∩B′. 0 Y ) correspond au nombre de voisins communs aux nœuds 0i
et Yi. En faisant ainsi la somme des voisins communs a` 0 et Yi pour tous les Yi, on ob-
tient le nombre de liens entre les voisins de 0. Cependant, chaque lien est ainsi compte´
deux fois (un lien entre Yi et Yj est compte´ quand on conside`re Yi voisin commun de
Yj et 0 et quand on conside`re Yj voisin commun de 0 et Yi). C’est pourquoi on se doit
de diviser cette somme par 2.
Nous supposons que ρ(0) = 1 si le nœud 0 n a aucun voisin (Φ(B′’ 0) = 0). Nous
di i l l d d d d ′con t onnons par a va eur u egre´ u nœu 0 : δ(0) = Φ(B0). Nous obtenons
alors :
∑+∞
o [ρ(0)] = o [ρ |δ = 0] o(δ = 0) + oE E 0 0 P 0 E [ρ0|δ0 = k] oP (δ0 = k)
k=1
∑  ∑ ∣∣ ′+∞ Φ(B 0)1 Φ(B′ ′0 ∩B Y )
= 1 + o  iE ∣Φ(B′0) = k o ′P (Φ(B 0) = k)
2 Φ(B′0)
k=1 i=1
∑+∞∑k1 1 [ ∣∣ ]
= 1 + o Φ(B′ ∩B′ )∣Φ(B′ ) = k × oE 0 Y 0 P (Φ(B′0) = k)
2 k i
k=1 i=1
(3.2)
Les nœuds (Yi)[i=1,..,k e´tant in
l p o ′ ∩ ′ ∣∣
de´pendants ]et uniforme´ment distribue´s dans B′0,
es e´rance Φ(B B )∣Φ(B′’ E 0 Y 0) = k est la meˆme pour tout i, i = 1, .., ki
3.11. ANNEXES 55
(et donc pour tout voisin Yi de 0). On note ν(S) la mesure de Lebesgue de la
re´gion du plan S dans IR2 Connaissant ν(B′ ∩ B′ ) et sachant que Φ(B′. ) = k,
a(lors le nombre de) 0 Yi 0nœuds dans B′ ′0 ∩ B Y suit une loi binomiale de parame`trei
ν(B′ ∩B′ )
k − 1, 0 Yiν(B ) .′0
′ ′
L b y d p i d i − ν(B 0∩B Y )e nom re mo en e o nts ev ent : (k 1) iν(B ) .′0
D’ou`, pour tout i = 1, .., k :
[ ∣∣∣ ] (k − 1) [ ∣∣∣ ]o Φ(B′ ∩B′E 0 Y ) Φ(B′0) = k = o ′ ′ ′E ν(B 0 ∩Bi 2 Y ) Φ(B 0) = kpiR i
− (3.3)(k 1)
= o ′ ′E [ν(B 0 ∩B2 Y )]piR i
Cette e´galite´ 3 3 vient du fait que la surface ν(B′ ∩ B′. 0 Y ) ne de´pend pas du nombrei
de Yi, puisque les nœuds Yi sont inde´pendants.
Si on pose que le nœud Yi est a` une distance r du nœud 0, l’ai√re de l’intersection
B′ ′ ′ ′ 2 r 20 ∩ B Y devient ν(B 0 ∩ B Y ) = A(r) = 2R arccos 2R − r R − r
2
4 , commei i
illustre´ sur la figure 3.4.
Puisque les Y sont uniforme´ment distribue´s dans B′i 0, la valeur moyenne de l’aire
intersection est :
o [ν(B′ ∩B′E 0 Y )] =i ∫oE [A(r)]2pi ∫ R A(r)
=
0 ( 20 piR√ )
r dr dθ
3 3
= R2 pi −
4
Soit p la probabilite´ que deux voisins de 0 soient eux-meˆmes voisins. p est la valeur
moyenne de l’aire d’intersection divise´e par la surface totale ou` peuvent se trouver les
voisins de 0 (piR2). On a :
∫ ( √ ) √
∈ ∩ 2
1 u 2− − u − 3 3p = P (Y2 B0 BY ) = 2 arccos u 1 udu = 11 pi u=0 2 4 4pi
≈ 0.5865
56 CHAPITRE 3. ALGORITHME DE CLUSTERING
Ce re´sultat combine´ a` celui de l’e´quation 3.2 nous donne :
∑∑ ( √ )+∞ k
o 1 1 k − 1 3 3
E [ρ(0)] =1 + pi − o (Φ(B′P 0) = k)
2 k
∑k=1 i=1 (
pi ) 4
+∞ − √1 k 1 3 3
=1 + pi − oP (Φ(B′0) = k)
2
k=( pi 41 √ ) (∑ )+∞ ∑+∞1 − 3 3=1 + pi × k o (Φ(B′P 0) = k)− o ′P (Φ(B 0) = k)
2pi ( 4√ ) k=1
1 − 3 3 ( − ( − { }))
k=1
=1 + pi λpiR2 1 exp λpiR2
2pi 4
(3.4)
L’e´galite´ 3.4 de´coule du the´ore`me de Slyvniack dont l’une des conse´quences est que
l b d ′e nom re e voisins Φ(B0) de 0, sous la probabilite´ de Palm, suit une loi de Poisson
discre`te de parame`tre λpiR2. 
3.11.2 Calcul analytique du nombre de clusters
Nous donnons ici les calculs de´taille´s de la borne du nombre de clusters donne´ dans le
the´ore`me 1. Nous bornons la probabilite´ qu’un nœud soit chef.
Conjecture 1 Une borne supe´rieure pour la probabilite´ qu’un nœud soit chef est :
( ) ( ∑+∞ ( ) )n
o 1 λpiR
2
PΦ ρ(0) > max ρ(Yk) ≤ 1 + exp {−λpiR2}
k=1,..,Φ(B0) n n!
n=1
Preuve 5 Calculer la probabilite´ pour un nœud d’eˆtre chef revient a` calculer la pro-
babilite´ pour un nœud d’avoir la plus forte densite´ dans son voisinage.
Nous conside´rons le point 0. Soient B0 = B(0, R) la boule de rayon R centre´e en 0
′
et B0 la boule de rayon R centre´e en 0 prive´e du singleton {0}. Soit (Yi)i=1,..,Φ(B′ ),0
chacun des points de Φ se trouvant dans B′0.
La densite´ des points de B0 est e´qui-distribue´e puisque les positions de ces points sont
uniforme´ment et in(de´pendamment distribue´es dans B0. D’ou` :∣ )
o ∣∣ ′ ≤ 1P ρ(Yi) > max ρ(Yk) Φ(B0) = n
k=1,..,n;k 6=i n
Si l i i i ( ′e po nt 0 n’a aucun vo s n Φ(B0) = 0), 0 est un cluster-head.
3.11. ANNEXES 57
Nous(avons : )
o
P ρ(0) > max ρ(Yk)
( ′k=1,..,Φ(B )0 ∣∣ )∣ ( ) ( )o ′ ′ ′=P ρ(0) > max ρ(Yk) Φ(B0) > 0 oP Φ(B0) > 0 + oP Φ(B0) = 0
′
k=1,..,Φ(B )
0
On note : ( ∣∣ )∣ ( )p = o ′ ′0 P ρ(0) > max ρ(Yk) Φ(B0) > 0 × oP Φ(B0) > 0
′
k=1,..,Φ(B )
0
Si nous su(pposons que les densite´s sont e´qui-distribue´es, nous a)vons :∣∣∣ ( )p < o ′ ′0 P ρ(Y1) > max(ρ(0), max ρ(Yk)) Φ(B0) > 0 × oP Φ(B0) > 0
k=2,..,Φ(B′ )
0
Il s’agit d’une conjecture, en effet nous n’avons pas re´ussi a` de´montrer ce re´sultat.
Cependant d’apre`s nos simulations, quelle que soit la densite´ des nœuds, la quantite´
p0 est deux a` trois fois plus petite que le terme de droite de cette ine´galite´.
De plus, comme l’e´ve`nement
E1 = {ρ(Y1) > max(ρ(0), max ρ(Yk))}
k=2,..,Φ(B′ )
0
est inclus dans l’e´ve`nement
E2 = {ρ(Y1) > max ρ(Yk))}
k=2,..,Φ(B′ )
0
nous pouvons majorer la probabilite´ que E1 se produise par la probabilite´ que E2 se
re´alise. Nous obtenons :
( ) ( )
p0 ≤ o o
′ o o ′
P [(E1]× P Φ(B0) > 0 ≤ P [E2]× P∣∣ )
Φ(B0) > 0( )
o ′ ′p0 ≤ P ρ(Y1) > max ρ(Yk)∣Φ(B0) > 0 × oP Φ(B ) > 0
′
k=2,..,Φ(B )
∑ ( 0 ∣ )
0
+∞
o ∣ ′= oP ρ(Y1) > max ρ(Yk)∣Φ(B0) = n × P (Φ(B′0) = n)
n∑=1+∞ ( )
′
k=2,..,Φ(B )
0
1 λpiR2
n
≤ exp {−λpiR2}
n n!
n=1
58 CHAPITRE 3. ALGORITHME DE CLUSTERING
De plus, d’apre`s le the´ore`me de Slivnyak [76], le nombre de points sous la distribution
de Palm dans un espace Bore´lien de IR2 qui ne contient pas le point 0, suit une loi de
Poisson discre`te. Nous en de´duisons :
( ) ∑+∞ ( )2 n
o 1 λpiR
P ρ(0) > max ρ(Yk) ≤ exp {−λpiR2}+ exp {−λpiR2}
k=1,..,Φ(B0) n n!
n=1

Comme, d’apre`s le lemme 3, le nombre de clusters est tel que
[Nb de clusters dans C] = λν(C) oE PΦ (0 est chef ), on obtient une borne supe´rieure
pour le nombre de clusters forme´s par notre algorithme dans une surface C :
∑+∞ ( )1 λpiR2 n
E [Nb de clusters dans C] ≤ λν(C) exp {−λpiR2}+ exp {−λpiR2}
n n!
n=1
3.11.3 Temps de transmission borne´
Dans cette partie, nous justifions l’hypothe`se suivante : ”il existe une constante τ > 0
telle que chaque nœud est en mesure de diffuser localement une trame et d’en recevoir
une de chacun de ses voisins en un temps borne´ ∆(τ)” faite dans la section 3.8.5 pour
prouver le caracte`re d’auto-stabilisation de notre algorithme.
Dans [83], les auteurs fournissent une analyse des performances du protocole IEEE
802.11 pour la couche MAC des re´seaux sans fil. En conside´rant un graphe a` n stations,
toutes a` porte´e de transmission les unes des autres (c.a`.d. que le graphe de communica-
tion est complet), les auteurs mode´lisent l’activation de la pe´riode de contention par les
nœuds avant l’e´mission d’une trame. La dure´e de cette pe´riode de´pend des collisions
qui ont pu se produire pour cette trame auparavant. On trouve en particulier dans ce
papier la probabilite´ Psuc qu’il y ait une transmission re´ussie parmi les n stations en un
slot de temps donne´. Une transmission est conside´re´e comme re´ussie si exactement une
station e´met pendant cette pe´riode de temps. Si pc est la probabilite´ qu’il y ait au moins
un paquet transmis sur le me´dium parmi les n stations (pc est aussi donne´ dans [83]),
nous avons :
P = (n− 1)((1 − p )(n−2)/(n−1)suc c + pc − 1)
Nous montrons maintenant que le temps moyen au bout duquel tous les voisins d’un
nœud ont e´mis avec succe`s, est borne´ par une constante. Soit X la variable ale´atoire
de´signant le nombre de slots de temps ne´cessaire pour que n stations arrivent a` e´mettre
avec succe`s. Dans le meilleur cas, chaque station parle a` tour de roˆle. Ceci donne :
[X < n] = 0 et [X = n] = PnP P suc.
P [X = k, k > n] est la probabilite´ qu’a` la fin des (k−1) premiers slots, (n−1) stations
ont e´mis avec succe`s et que la nieme station re´ussit a` transmettre sa trame durant le slot
k. Nous avons :
3.11. ANNEXES 59
( − )( )k 1 n
[X = k, k > n] = (1 − P )(k−n+1)PnP − − suck n+ 1 n 1 suc
Les n − 1 premie`res stations ont e´mis pendant les k − 1 premiers slots. On conside`re
donc la probabilite´ de choisir k − (n− 1) slots parmi les k − 1 premiers slots pendant
lesquels aucune transmission n’a eu lieu ou une collision est apparue, multiplie´ par le
nombre de possibilite´s de choisir la nieme station qui e´met durant le kieme slot.
On en de´duit le nombre moyen de slots ne´cessaire E [X ] pour que chacune des n sta-
tions parvienne a` e´mettre avec succe`s.
∑∞
E [X ] = kP [X = k]
k=0 ∑∞
= nP [X = n] + kP [X = k]
( k∑=n+1 ( )( ) )∞
= Pnsuc ×
k − 1 n
n+ k (1− P )(k−n+1)
k − n+ 1 n− suc1
k=n+1
Ceci peut eˆtre de´rive´ en : ( )
n 1
E [X ] = Psuc (n+ n(n+ 1)( − (n+ 1) + nP )Pn sucsuc )
1
= nPnsuc 1 + (n+ 1)( − (n+ 1) + nPsuc)Pnsuc
Ainsi, comme Psuc de´pend uniquement de n et que nous supposons n borne´ par une
constante, E [X ] est aussi constant. D’ou` notre hypothe`se stipulant ”une constante τ >
0 telle que chaque nœud est en mesure de diffuser localement une trame et d’en recevoir
une de chacun de ses voisins en un temps borne´ ∆(τ)”.
60 CHAPITRE 3. ALGORITHME DE CLUSTERING
Chapitre 4
Diffusion
4.1 Introduction
Comme nous avons pu le constater, auto-organiser un re´seau sans fil tel un re´seau
ad hoc ou de capteurs, pre´sente de nombreux avantages. Cependant, de tels re´seaux
ne´cessitent e´galement un me´canisme efficace de diffusion d’information. La diffusion
(ou broadcast) consiste a` transmettre un message depuis un nœud source vers l’en-
semble des entite´s du re´seau. Une telle ope´ration est employe´e par la grande majorite´
des protocoles de routage (pour la de´couverte des routes entre les entite´s du re´seau).
Cette ope´ration s’ave`re aussi utile a` une station de base dans un re´seau de capteurs lors
de la diffusion d’une requeˆte ou de mise a` jour logicielle sur tous les capteurs. Cette
ope´ration, indispensable donc a` tout re´seau sans fil, a fait l’objet de nombreux travaux
avec, comme but premier, la re´duction du nombre de nœuds retransmettant le message
lors de sa diffusion a` l’ensemble du re´seau.
Les bonnes proprie´te´s d’un protocole de diffusion efficace sont les suivantes :
– extensibilite´ : il supporte le passage a` l’e´chelle ;
– accessibilite´ : une grande majorite´ des nœuds du re´seau joignables par la source
(appartenant a` la meˆme composante connexe) rec¸oit le message (plus de 90%) ;
– e´conome : l’e´nergie et la bande passante consomme´es sont minimise´es (le nombre
de messages retransmis et de re´ceptions redondantes est re´duit).
E´ tant donne´ qu’un re´seau sans fil ne´cessite a` la fois une auto-organisation et un pro-
tocole de diffusion, nous proposons d’utiliser la structure d’arbres forme´e par l’algo-
rithme 1, non seulement pour organiser le re´seau en clusters, mais e´galement pour
e´tablir une base propice a` une diffusion efficace, tirant avantage de certaines de ses
caracte´ristiques. Ainsi, une seule structure est cre´e´e pour deux ope´rations : l’organi-
sation et la diffusion. Notre algorithme de diffusion n’autorise que les nœuds internes
des arbres a` retransmettre le message. Comme nous l’avons constate´ dans le chapitre 3,
une grande proportion des nœuds sont des feuilles (environ 75%). Par conse´quent, une
diffusion base´e sur un tel ensemble n’autorise que peu de nœuds a` e´mettre. L’ensemble
61
62 CHAPITRE 4. DIFFUSION
des arbres de clustering forme une foreˆt couvrante, donc un ensemble ou` tout nœud
est soit un nœud interne, soit directement voisin d’un nœud interne. Ne´anmoins, cet
ensemble n’est pas connecte´ puisque les arbres sont inde´pendants. Pour que la diffu-
sion touche toutes les entite´s du re´seau, il faut tout d’abord connecter ces arbres en
e´tablissant des passerelles entre eux. Lors de la diffusion, seuls les nœuds internes et
ceux constituant les passerelles seront autorise´s a` retransmettre le message. Notre algo-
rithme permet deux types de diffusion : une diffusion ge´ne´rale d’un message a` tous les
nœuds du re´seau mais e´galement une diffusion d’un message limite´e a` l’inte´rieur d’un
cluster. Pour ce dernier cas de figure, comme la hauteur des arbres est petite et proche
de l’optimal (excentricite´ du chef de cluster) et que les clusters sont proches de cellules
de Voronoı¨ (chapitre 3), un nœud recevra rapidement une information provenant de son
chef.
Dans ce chapitre, nous de´crivons dans un premier temps notre algorithme de diffu-
sion reposant sur la structure d’arbres ainsi que les algorithmes de se´lection des passe-
relles. Nous donnons ensuite une analyse the´orique d’une diffusion dans tout le re´seau,
montrant que le nombre de re´ceptions par nœud peut s’exprimer comme le produit
des degre´s des relais par la probabilite´ pour un nœud d’eˆtre un relais. Les simulations
viennent illustrer notre analyse the´orique, comparer sur divers aspects plusieurs proto-
coles existant et en e´valuer la robustesse. E´ tonnamment, il apparaıˆt que les protocoles
les plus fiables ne sont pas ceux produisant le plus de relais mais ceux dont les relais
ont le plus fort degre´. Les comparaisons entre ces diffe´rents algorithmes montrent aussi
que notre heuristique de diffusion pre´sente le meilleur compromis entre la consomma-
tion d’e´nergie (nombre d’e´missions et re´ceptions) et la robustesse. Au cours de ces
simulations, nous avons pu remarquer que l’heuristique de diffusion base´e sur les MPR
(multi-points relais) de OLSR (voir section 4.2) pre´sentait tre`s peu de robustesse face
a` la mobilite´ des nœuds. Afin de mieux comprendre le comportement des MPR, nous
avons analyse´ cette heuristique plus en de´tail.
La section 4.2 pre´sente quelques-unes des solutions de diffusion existant pour les
re´seaux sans fil. La section 4.3 donne l’analyse the´orique de la diffusion, utilisant la
ge´ome´trie stochastique et la distribution de Palm. La section 4.4 pre´sente la fac¸on dont
nous utilisons la structure d’arbres sous-jacente afin de re´aliser une diffusion efficace.
Nos comparaisons et e´valuations des diffe´rents algorithmes sont mene´es au travers des
simulations de la section 4.5. La section 4.6 pre´sente l’analyse de la se´lection des MPR
dans OLSR. Enfin, quelques remarques concluront ce chapitre (section 4.7).
4.2 Les algorithmes de diffusion pour les re´seaux ad
hoc dans la litte´rature
Afin de pouvoir supporter une extension du re´seau, un protocole de diffusion dans
les re´seaux sans fil se doit de limiter l’utilisation de la bande passante et la de´pense
en e´nergie ; il doit donc minimiser le nombre de messages ge´ne´re´s tout en assurant
qu’un maximum de nœuds connecte´s a` la source rec¸oivent le message (plus de 90%).
Beaucoup de solutions ont e´te´ propose´es avec des hypothe`ses plus ou moins similaires
4.2. E´TAT DE L’ART 63
a` notre mode`le. Dans cette section, nous ne mentionnerons que ceux supposant les
meˆmes hypothe`ses que nous, c’est a` dire qui supposent un mode`le a` antennes omni-
directionnelles, sans controˆle de puissance. De plus, en supposant une couche MAC
ide´ale (qui ne ge´ne`re aucune collision), on conside`re la diffusion efficace si tous les
nœuds connecte´s a` la source rec¸oivent le message. Un e´tat de l’art plus complet concer-
nant des solutions probabilistes, utilisant des antennes directionnelles ou conside´rant
une couche MAC non ide´ale est donne´ dans [18].
La me´thode de diffusion la plus triviale pour diffuser un message est l’inondation
aveugle ou blind flooding : lorsqu’un nœud rec¸oit le message diffuse´ pour la premie`re
fois, il le re´-e´met pour ses voisins. Ce me´canisme impose une charge e´norme au
re´seau, engendrant un grand nombre de messages et de collisions, de´pensant beaucoup
d’e´nergie et de bande passante. C’est pourquoi un tel me´canisme ne peut eˆtre envisage´
pour un re´seau dense ou e´tendu. Ceci donna motive la mise au point de protocoles de
diffusion plus intelligents qui minimisent le nombre de re-transmissions ne´cessaires
en n’autorisant qu’un sous-ensemble de nœuds a` transmettre. Pour cela, on cherche a`
trouver un ensemble ”dominant”. En effet, afin que tous les nœuds du re´seau rec¸oivent
le message, chacun des nœuds doit eˆtre soit un dominant, soit voisin d’un dominant. La
difficulte´ est alors de trouver un tel ensemble dominant connexe de taille minimum qui
minimise e´galement le nombre de re´ceptions redondantes d’un message retransmis par
cet ensemble. Ce proble`me est montre´ NP-difficile [34]. I. Stojmenovic et J. Wu [75]
ont propose´ une classification des protocoles de diffusion en fonction du type d’en-
semble dominant qu’ils utilisent : cluster-based ou base´ sur la formation de clusters,
ensemble dominant de´pendant de la source et ensemble dominant inde´pendant de la
source.
Les solutions cluster-based [28, 36] sont les plus anciennes. Ces protocoles sont plus
de´taille´s dans le Chapitre 2. L’ide´e est que chaque nœud ayant le plus petit identifiant
(protocole Linked Cluster Architecture - LCA) ou le plus fort degre´ (High Connec-
tivity Clustering - HCC) dans son 1-voisinage se de´clare teˆte de cluster. Ses voisins
s’attachent a` lui. Si un nœud s’attache a` plus d’un cluster-head, il devient une passe-
relle. L’ensemble dominant connexe re´sultant comprend les cluster-heads et les passe-
relles. Par la suite, des optimisations ont e´te´ propose´es afin de minimiser la mainte-
nance pour e´viter des re´actions en chaıˆne e´tendues a` tout le re´seau lors de mouvements
de nœuds [24] ou afin de limiter le nombre de passerelles et donc la taille de l’ensemble
dominant [81].
Dans les propositions base´es sur des ensembles dominants de´pendant de la source [49,
65], les e´metteurs se´lectionnent parmi leurs voisins les nœuds qui relaieront le message.
L’ensemble des relais ainsi choisis par un nœud u est aussi petit que possible et tel
que, chaque nœud a` 2 sauts de u est voisin d’au moins un de ces relais. Pour e´tablir
cette se´lection, u ne´cessite une connaissance de son 2-voisinage uniquement. Lors de la
diffusion, u fera suivre le message diffuse´ qu’il rec¸oit de v, seulement s’il le rec¸oit pour
la premie`re fois et a e´te´ choisi comme relais de v. Les diffe´rents algorithmes diffe`rent
ensuite sur la se´lection des relais, le plus connu e´tant celui base´ sur les Multi-Points
Relais (MPR) de OLSR [65]. Dans OLSR, les MPR sont e´galement utilise´s pour e´tablir
les tables de routage. La structure de diffusion a donc un usage double. Nous de´taillons
plus la se´lection des MPR dans la section 4.6.
64 CHAPITRE 4. DIFFUSION
Les protocoles de diffusion utilisant des ensembles dominants inde´pendants de la
source se´lectionnent cet ensemble inde´pendamment du nœud initiateur de la diffusion.
C’est le cas de notre algorithme. Les nœuds de´cident d’eux-meˆmes s’ils sont ou non
dans cet ensemble, contrairement aux solutions base´es sur des ensembles dominants
de´pendant de la source, ou la de´cision est prise par un autre nœud. Beaucoup de solu-
tions de ce type ont e´te´ propose´es. Dans chacune d’elles, les nœuds ne ne´cessitent que
la connaissance de leur 2-voisinage pour prendre leur de´cision. Un protocole simple
et efficace est le NES (Neighbor Elimination-Based Scheme) de Wu et Li [80], qui se
base sur l’e´limination de voisins. Dans ce sche´ma, un nœud u est dit interme´diaire
si au moins deux de ses voisins v et w ne sont pas eux-meˆmes voisins (u est l’in-
terme´diaire entre v et w). A` partir de la`, deux re`gles de se´lection sont applique´es sur les
interme´diaires afin de re´duire leur nombre. Les nœuds restants deviennent les membres
de l’ensemble dominant et donc les relais lors d’une diffusion. Les re`gles de se´lection
se basent sur une valeur de priorite´. Dans la version originale du NES, cette valeur est
l’identifiant des nœuds. Puis, plusieurs variantes ont e´te´ propose´es utilisant pour cette
valeur le degre´ du nœud ou l’e´nergie restante [26, 74]. Les auteurs de [74] proposent
un autre type d’algorithme base´ sur l’e´limination des voisins que l’on peut re´sumer
par ”Wait and See”. Sur re´ception d’un message de diffusion, un nœud attend pendant
un temps ale´atoire. Durant cette pe´riode, il observe si un de ces voisins retransmet le
message et dans ce cas, quels sont ses voisins recevant ainsi l’information. Si a` la fin de
la pe´riode d’attente, il reste parmi ses voisins des nœuds n’ayant pas rec¸u le message,
il l’e´met. Les auteurs de [19] ont ensuite propose´ une ame´lioration a` cet algorithme
en conside´rant le RNG - Relative Neighborhood Graph (graphe de voisinage relatif)
plutoˆt que le graphe re´el. Ces derniers sche´mas base´s sur l’e´limination de voisins (Wait
& See et Wait & See base´ sur RNG) obtiennent d’excellentes performances en terme
de nombre d’e´missions et de re´ceptions mais induisent une latence importante dans le
processus de diffusion du fait de la pe´riode d’attente ale´atoire de chaque nœud.
4.3 Analyse the´orique d’une diffusion dans un re´seau
sans fil
Comme nous avons pu le constater dans la section 4.2, la plupart des protocoles de
diffusion visent a` re´duire le nombre de nœuds qui relaient le message, l’objectif princi-
pal e´tant de minimiser l’e´nergie globale consomme´e pour diffuser le message. Comme
les nœuds consomment de l’e´nergie non seulement pour transmettre mais aussi pour
recevoir un message, un protocole de diffusion efficace en terme d’e´conomie d’e´nergie
doit chercher a` minimiser E, avec E = Ctx × nbtx + Cry × nbry ou` Ctx (resp. Cry)
est le couˆt e´nerge´tique d’une transmission (resp. re´ception) d’un paquet et nbtx (resp.
nbry) est le nombre de fois ou` le message est e´mis (resp. le nombre de re´ceptions).
Or, les nœuds des re´seaux ad hoc utilisant la technologie 802.11 [31], tout comme les
capteurs [63], ne´cessitent approximativement autant d’e´nergie pour recevoir que pour
e´mettre (Cry ≈ Ctx) et donc, ni les re´ceptions ni les transmissions ne peuvent eˆtre
ne´glige´es lors du bilan e´nerge´tique.
4.3. ANALYSE THE´ORIQUE 65
Dans cette analyse, nous nous sommes inte´resse´s au nombre moyen de fois ou` un
nœud donne´ rec¸oit un meˆme message lors d’une diffusion. Comme dans les ana-
lyses the´oriques pre´ce´dentes, nous utilisons les proprie´te´s des processus ponctuels
et les meˆmes notations, a` savoir : Φ(S) repre´sente le nombre de points du proces-
sus Φ distribue´s sur la surface S, B(x,R) est la boule de rayon R centre´e en x et
′
Bx = B(x,R) \ {x}.
Nous notons r le nombre moyen de re´ceptions d’un meˆme message par un nœud (qu’il
soit un relais ou non). Nous donnons deux re´sultats pour r dans les Propositions 1 et 2,
que nous utiliserons par la suite afin de comparer les diffe´rents algorithmes de diffusion
e´tudie´s. Les re´sultats de r donne´s par ces deux propositions sont semblables mais la
Proposition 1 conside`re le mode`le particulier que nous utilisons dans les simulations,
de´crit dans le Chapitre 1.1 alors que les re´sultats de la proposition 2 sont e´galement
applicables a` une classe plus large de graphes ale´atoires. Dans les deux cas, nous ne
donnons ici que l’ide´e ge´ne´rale de la preuve, les preuves et calculs de´taille´s se trouvant
en Annexes 4.9.
Pour la Proposition 1, nous conside´rons un processus ponctuel stationnaire Φ d’inten-
site´ λ > 0. Deux points (x, y) de Φ sont connecte´s (et donc voisins) si et seulement si
la distance Euclidienne les se´parant est infe´rieure ou e´gale a` R (d(x, y) ≤ R), R e´tant
le rayon de transmission radio des nœuds (mode`le de graphe ge´ome´trique ale´atoire).
Proposition 1 E´tant donne´ un processus ponctuel stationnaire Φ d’intensite´ λ (λ >
0), soit ΦRelay d’intensite´ λRelay un amincissement de Φ. Les points de ΦRelay
repre´sentent les relais. Nous supposons que ΦRelay est toujours un processus ponc-
tuel stationnaire. Le nombre moyen de re´ceptions d’un meˆme message par nœud r est :
λ [ ]Relay ′
r = oE Φ(B )
[ ] λ ΦRelay 0
′
ou` oEΦ ΦRelay(B0) est l’espe´rance sous Palm par rapport au processus Φ (et donc
l l ) d b d l d ′a va eur moyenne u nom re e re ais ans B0.
La preuve de cette proposition est donne´e en annexes 4.9. Le nombre de re´ceptions
d’un meˆme message rec¸u par un nœud de´pend du nombre de relais dans son voisinage.
Le re´sultat s’interpre`te de la fac¸on suivante. Le nombre moyen de re´ceptions par nœud
est le produit du degre´ moyen d’un relais par la probabilite´ pour un nœud donne´ d’eˆtre
un relais (ou de fac¸on e´quivalente par le ratio du nombre de relais sur le nombre total
de nœuds).
Nous conside´rons maintenant des mode`les de graphes ale´atoires plus ge´ne´raux. Nous
supposons que les degre´s des nœuds et le nombre de re´ceptions par nœud sont e´qui-
distribue´es. A noter que nous ne supposons pas ces quantite´s inde´pendamment dis-
tribue´es, ce qui fait que cette hypothe`se n’est pas restrictive. De plus, cette condition
est ve´rifie´e par la plupart des graphes ale´atoires. Par exemple, un graphe ale´atoire de
type Erdo¨s et Renyi [29] qui consiste en n sommets entre lesquels des areˆtes sont
66 CHAPITRE 4. DIFFUSION
place´es avec une probabilite´ uniforme p, inde´pendamment des autres areˆtes, ve´rifie nos
hypothe`ses.
Proposition 2 E´tant donne´ un graphe ale´atoire G(V,E) et un ensemble de relais
Relay ⊂ V ou` les degre´s des nœuds et des relais ainsi que le nombre de re´ceptions
par nœud sont e´qui-distribue´s.[Le no∣mbre moyen∣∣ ]
de re´ceptions par nœud r s’e´crit :
r = E δ(v1) v1 ∈ Relay P(v1 ∈ Relay) (4.1)
La preuve de cette proposition est donne´e en annexes 4.9. L’ide´e est de voir que le
nombre de re´ceptions d’un meˆme message rec¸ues par un nœud correspond au nombre
moyen de relais qu’il a dans son voisinage. On peut de´duire le re´sultat ci-dessus, pour
un graphe ge´ne´ral (proposition 2). Il est le meˆme que pour un graphe ge´ome´trique
ale´atoire (proposition 1) : le nombre moyen de re´ceptions par nœud est le produit du
degre´ des relais par la probabilite´ d’eˆtre un relais. Dans l’e´galite´ 4.1, v1 est un nœud
choisi ale´atoirement parmi l’ensemble des sommets V . Le choix de v1 n’a aucun im-
pact sur les re´sultats puisque la probabilite´ pour un nœud d’eˆtre un relais lors de la
diffusion est e´qui-distribue´e et est la meˆme pour v1 que pour tout autre nœud du graphe.
Dans cette analyse, nous avons montre´ que le nombre moyen de re´ceptions par nœud
est le produit du degre´ moyen des relais par la proportion des relais. Si n est le nombre
de nœuds dans le re´seau et proptx la proportion des relais (nbtx = n×proptx), l’e´nergie
globale consomme´e s’e´crit :
× × ( )E = nCry proptx p+ δRelay
ou` p de´pend du type de technologie utilise´e par les nœuds radio (p ≈ 1 pour les cap-
teurs [63], p ≈ 4 pour les nœuds utilisant la technologie 802.11 [31]). Il en ressort
clairement que pour diminuer E, il faut jouer sur les parame`tres δRelay et proptx.
4.4 Notre contribution a` la diffusion
Dans cette section, nous introduisons dans un premier temps un algorithme permet-
tant l’e´lection de nœuds passerelles entre nos clusters. Puis, dans un second temps,
nous donnons l’algorithme permettant d’appliquer deux types de diffusion sur notre
organisation en arbres : un algorithme de diffusion globale (dans tout le re´seau) et un
algorithme de diffusion dans un cluster.
4.4.1 Se´lection des passerelles
On appelle nœud frontie`re un nœud comptant parmi ses voisins au moins un
repre´sentant d’un ou plusieurs clusters autres que le sien.
Une passerelle Gateway(C(u), C(v)) = 〈x, y〉 entre deux clusters voisins C(u) et C(v)
est une paire de nœuds frontie`res 〈x, y〉 telle que x ∈ C(u), y ∈ C(v) et x ∈ Γ1(y).
4.4. NOTRE CONTRIBUTION A` LA DIFFUSION 67
c b h e
j
l
d
g
i
a k
f m
FIG. 4.1 – Exemple d’arbres de clustering forme´s par la me´trique de densite´.
Dans une telle paire, on appelle le nœud x le nœud passerelle x = GW (C(u), C(v))
et le nœud y le nœud miroir de la passerelle y = GWm(C(u), C(v)). Ces passe-
relles sont oriente´es dans le sens ou` il existe une passerelle permettant a` C(u) de
joindre C(v) ( Gateway(C(u), C(v))) et une autre qui permet a` C(v) de joindre C(u)
(Gateway(C(v), C(u))), ces deux passerelles pouvant eˆtre diffe´rentes.
Notre algorithme de se´lection des passerelles se de´roule en deux e´tapes. Dans un pre-
mier temps, chaque nœud frontie`re, choisit localement son miroir dans les clusters
voisins. Un nœud frontie`re et son miroir forment alors une paire de nœuds candidate
au titre de passerelle. Dans un second temps, l’algorithme se´lectionne parmi ces paires
candidates, la paire la plus ade´quate au roˆle de passerelle. Comme les nœuds de la
passerelle seront invite´s a` re-transmettre un message diffuse´ dans tout le re´seau, l’algo-
rithme de se´lection favorise l’e´lection des nœuds internes afin de minimiser le nombre
d’e´metteurs. En effet, les nœuds internes appartiennent de´ja` a` l’ensemble des nœuds
relais. Les se´lectionner en tant que passerelle n’ajoute aucun e´metteur et donc aucun
message superflu.
Cependant, il est clair que si une passerelle est le seul moyen de raccorder un ensemble
du re´seau a` la source du message diffuse´, cette passerelle devient un point sensible.
Afin d’ajouter de la robustesse au protocole envers une cassure de liens au niveau des
passerelles, chaque nœud passerelle e´lit parmi ses voisins une passerelle de secours
(ou de back-up). Cette dernie`re re´-e´mettra le message diffuse´ si et seulement si elle
n’entend pas la passerelle principale. Nous reprenons ici la philosophie Wait & See vue
dans la section 4.2. Dans la suite, nous de´taillons la se´lection des trois types de nœuds :
miroir, passerelle et passerelle de secours.
Se´lection des miroirs.
Comme mentionne´ dans le chapitre 3.8, tout nœud u sait en un temps borne´ s’il existe
parmi ses voisins un nœud v qui n’appartient pas au meˆme cluster que lui (C(u) 6=
C(v)) et donc s’il est un nœud frontie`re. Chaque nœud frontie`re u doit se´lectionner
son miroir parmi les nœuds de son voisinage appartenant a` un cluster diffe´rent du sien.
Pour cela, dans un premier temps, u conside`re parmi ces nœuds ceux qui ne sont pas
des feuilles et qui sont donc des transmetteurs dans tous les cas. u se´lectionne parmi eux
le nœud de plus forte densite´. Si tous les nœuds conside´re´s sont des feuilles, u choisit
68 CHAPITRE 4. DIFFUSION
le nœud de plus faible degre´, de fac¸on a` limiter le nombre de re´ceptions occasionne´es
lors de l’e´mission du message diffuse´ par le miroir.
Si u est un nœud frontie`re du cluster C(v) (C(v) 6= C(u)), on note m(u, C(v)) le nœud
miroir choisi par u dans C(v). Si u est voisin de plusieurs clusters diffe´rents du sien,
il doit e´lire plusieurs miroirs, un dans chacun des clusters voisins. Par exemple, sur la
figure 4.1, le nœud i doit se choisir deux miroirs, m(i, C(f)) dans C(f) et m(i, C(l))
dans C(l).
Algorithm 1 Se´lection du nœud miroir - EXE´CUTE´ SUR CHAQUE NŒUD FRONTIE`RE u,
c.a.d., ∃v ∈ Γ1(u) s.t. C(v) 6= C(u)
Pour chaque cluster voisin C pour lequel u est un nœud frontie`re : C =6 C(u) et
∃v ∈ Γ1(u) ∩ C
Se´lectionne l’ensemble S des nœuds tels que S = C ∩ {v | Γ1(u) | Ch(v) 6= ∅}.
⊲ u conside`re dans un 1er temps l’ensemble des nœuds non feuilles, e´metteurs dans tous les cas.
if (S 6= ∅) then Se´lectionne l ensemble S′’ des nœuds tels que
S′ = {v | v = maxw∈Sρ(w)}.
⊲ u conside`re les candidats ayant la plus forte valeur de densite´ dans le but de favoriser la
stabilite´.
else ⊲ Tous les candidats miroirs de u sont des feuilles.
S = {C ∩ Γ1(u)}.
Se´lectionne l ensemble S′ des nœuds tels que S′’ = {v | v = minw∈Sδ(w)}.
⊲ u conside`re les feuilles de plus faible degre´ afin de minimiser le nombre de re´ceptions
ge´ne´re´es lors de l’ajout de cette feuille dans l’ensemble des relais.
end
if (S′ = {v}) then m(u, C) = v.
⊲ S′ ne contient qu’un nœud : le miroir de u.
else m(u, C) = v tel que Id(v) = minw∈S′Id(w).
⊲ Il existe des ex-aequo. u choisit le nœud de plus faible Id.
end
Se´lection des passerelles.
La seconde e´tape de l’algorithme de se´lection de passerelle e´lit les passerelles reliant
chaque cluster C a` chacun de ses clusters voisins C′, parmi les paires forme´es par un
nœud frontie`re et son miroir dans C′. Cette e´tape ne´cessite que des informations concer-
nant les nœuds frontie`res soient remonte´es a` la racine. Suivant la taxonomie de [81],
cette e´tape est qualifie´e de quasi-locale car chaque entite´ ne´cessite des informations
situe´es a` une distance borne´e (ici distance borne´e par la hauteur de l’arbre, elle-meˆme
borne´e par une constante). La premie`re e´tape de l’algorithme qui permet aux nœuds
frontie`res de se´lectionner leur miroir ne ne´cessite que des informations locales (de voi-
sinage) et est qualifie´e de locale. Le fait que ces e´tapes soient locales ou quasi-locales
sous-entend une maintenance rapide et une robustesse de l’algorithme envers la mobi-
lite´ des nœuds [81].
4.4. NOTRE CONTRIBUTION A` LA DIFFUSION 69
La se´lection des passerelles de notre algorithme est distribue´e puisqu’une se´lection est
ope´re´e a` chaque niveau de l’arbre. Tout comme la se´lection des miroirs, elle cherche
a` favoriser l’e´lection des nœuds internes en tant que passerelles de fac¸on a` limiter les
re´ceptions redondantes lors d’une diffusion d’un message. Les nœuds frontie`res en-
voient leur Id a` leur pe`re en leur indiquant si eux-meˆmes et leur miroirs sont ou non
des feuilles. Chaque pe`re choisit parmi tous ses fils frontie`res le meilleur candidat dont
il envoie les informations a` son propre pe`re et ainsi de suite, jusqu’a` atteindre le cluster-
head. La se´lection est donc semi-distribue´e puisque chaque nœud interne e´limine des
candidats et n’en renvoie qu’un seul a` son pe`re. De cette fac¸on, seuls des paquets de pe-
tites tailles sont envoye´s depuis les nœuds frontie`res jusqu’a` la teˆte de cluster. Comme
mentionne´ en section 3.6.2-table 3.5, le degre´ moyen des nœuds internes est faible et
constant quel que soit le nombre de nœuds, ce qui induit un nombre borne´ de messages
a` chaque niveau. De plus, comme la hauteur des arbres est e´galement borne´e par une
constante, le nombre de niveaux est lui aussi faible.
De´finition 2 (Sous-arbre) v appartient au sous-arbre de racine u (note´ sT (u)) si
l’une des trois conditions suivantes est remplie :
– u = v,
– u est le pe`re de v : u = P(v),
– le pe`re de v appartient au sous-arbre de racine u : P(v) ∈ sT (u).
C(x) est un cluster voisin du sous-arbre sT (u) si et seulement si C(x) 6= C(u) et il
existe dans sT (u) un nœud v frontie`re du cluster C(x) : ∃z ∈ C(x) et y ∈ sT (u) tels
que y ∈ Γ1(z).
La passerelle entre deux clusters voisins est alors se´lectionne´e de la fac¸on suivante.
L’algorithme est exe´cute´ par chaque nœud interne, apre`s re´ception des informations
concernant tous les nœuds frontie`res de son sous-arbre. Pour chaque cluster voisin de
son sous-arbre, un nœud interne u conside`re l’ensembleG des nœuds candidats (nœuds
frontie`res) (G = {v ∈ sT (u) | ∃w ∈ Γ1(v) | C(w) 6= C(u)}). Il se´lectionne parmi eux
le sous ensemble G′- ⊂ G des nœuds internes. Si G est seulement compose´ de nœuds
feuilles (et donc G′ = ∅), la se´lection se poursuit parmi les nœuds de G directement.
Le nœud u prend en priorite´ les nœuds dont le miroir est un nœud interne et il choisit
parmi eux le nœud de plus forte densite´ si les candidats sont des nœuds internes ou
de plus faible degre´ sinon. En cas d’e´galite´, le nœud de plus petit identifiant est e´lu.
On remarque qu’entre deux clusters voisins C(u) et C(v), il existe deux passerelles
Gateway(C(u), C(v)) et Gateway(C(v), C(u)) qui sont diffe´rentes dans la plupart des
cas. Du fait de leur orientation et comme un relais ne re-transmet que sur la premie`re
re´ception du message, dans la plupart des cas, seulement une de ces deux passerelles
sera utilise´e lors d’une diffusion. Ce phe´nome`ne sera mis en e´vidence par les simula-
tions de la section 4.5.
Algorithm 2 Se´lection des passerelles - EXE´CUTE´ PAR CHAQUE NŒUD INTERNE u
70 CHAPITRE 4. DIFFUSION
Pour chaque cluster C =6 C(u) pour lequel ∃v ∈ sT (u) nœud frontie`re
Conside`re l’ensemble G des candidats : G = {v ∈ sT (u) | ∃w ∈ Γ1(v) | C(w) = C}.
Se´lectionne l ensemble G′ ⊂ G des nœuds v tel que G′’ = G ∩ {v|Ch(v) 6= ∅}.
⊲ u conside`re en priorite´ les nœuds non feuilles.
if (G′ 6= ∅) then
⊲ u favorise les nœuds internes de plus forte densite´ ayant un nœud non feuille comme miroir.
Se´lectionne l ensemble G” ⊂ G′ tel que G” = G′’ ∩ {v|Ch(m(v,C)) 6= ∅}.
if (G” 6= ∅) then
Se´lectionne l’ensemble Finalist ⊂ G” tel que
Finalist = {v|ρ(v) = maxw∈G”ρ(w)} .
⊲ Passerelle Nœud Interne↔Nœud Interne.
else
Se´lectionne l’ensemble Finalist ⊂ G” tel que
Finalist = {v|ρ(v) = maxw∈G′ρ(w)} .
⊲ Passerelle Nœud Interne↔Feuille.
end
else
⊲ Tous les candidats sont des feuilles. u favorise ceux de plus faible degre´ ayant un nœud interne
comme miroir.
Se´lectionne l’ensemble G” ⊂ G tel que G” = G ∩ {v|Ch(m(v, C)) 6= ∅}.
if (G” 6= ∅) then
Se´lectionne Finalist ⊂ G” tel que Finalist = {v|δ(v) = minw∈G”δ(w)} .
⊲ Passerelle Feuille↔Nœud Interne.
else
Se´lectionne Finalist ⊂ G” tel que Finalist = {v|δ(v) = minw∈G′δ(w)} .
⊲ Passerelle Feuille↔Feuille.
end
end
if (Finalist = {v}) then
Winner = v.
else
Winner = {v|Id(v) = minw∈F inalistId(w)}.
⊲ Conflits. u choisit le nœud de plus petit Id.
end
if (u = H(u)) then
Winner est le nœud passerelle :
Gateway(C(u),C) = 〈Winner, m(Winner,C)〉.
else
Envoie l’identite´ de Winner a` son pe`re P(u).
end
Se´lection de la passerelle de secours.
Cette se´lection est purement locale et n’engendre aucun couˆt supple´mentaire. Elle tire
avantage du caracte`re de diffusion du me´dium radio qui fait que lorsqu’un nœud e´met,
tous les nœuds a` porte´e radio entendent le message, meˆme s’il ne leur est pas destine´.
Quand un nœud frontie`re u envoie une information a` son pe`re durant le processus de
4.4. NOTRE CONTRIBUTION A` LA DIFFUSION 71
se´lection des passerelles (algorithme 2), chacun de ses voisins apprend la condition de u
(feuille, nœud interne, nœud frontie`re, etc.). De cette fac¸on, le nœud passerelle apprend
qui dans son voisinage e´tait e´galement candidat et ainsi peut servir potentiellement de
passerelle de secours. Il se´lectionne ce nœud en choisissant parmi ses voisins un nœud
frontie`re dont le miroir est diffe´rent du sien. Cette passerelle de secours agit de la fac¸on
suivante. Sur re´ception d’un message de diffusion, la passerelle de secours enclenche
un compte a` rebours. Si a` la fin de celui-ci, elle n’a pas entendu la passerelle principale
e´mettre, elle e´met le message. Ce me´canisme n’ajoute aucune re´ception redondante et
ajoute de la robustesse au processus de diffusion.
4.4.2 L’algorithme de diffusion
Dans un re´seau sans fil, un nœud peut avoir usage de trois sortes de broadcast :
– une diffusion de voisinage : envoi d’un message a` tous ses 1-voisins (comme les
paquets HELLO) ;
– une diffusion localise´e : diffusion dans un cluster uniquement ;
– une diffusion globale : diffusion d’un message dans tout le re´seau.
Les passerelles ne seront utilise´es que dans le cas d’une diffusion globale, afin de re-
layer le message diffuse´ d’un cluster a` l’autre. Afin de distinguer ces trois types de
diffusions a` la re´ception d’un message, un nœud ne´cessite une indication dans le pa-
quet rec¸u1. Quand une diffusion est effectue´e dans un cluster C(u), le message est
relaye´ par tous les nœuds internes appartenant a` ce cluster. Quand le message doit eˆtre
propage´ dans tout le re´seau, tous les nœuds internes du re´seau ainsi que les passerelles
re´-e´mettent le message pour leurs voisins. Les passerelles (principales et de secours)
e´tant oriente´es, elles ne re´-e´mettent que sous certaines conditions. Le nœud passe-
relle GW (C(u), C(w)) re-transmet un message seulement s’il arrive de son propre
cluster C(u). Un nœud passerelle miroir GWm(C(u), C(w)) ne re-transmet le mes-
sage que s’il arrive du cluster C(u) pour lequel il est miroir. Ainsi, un nœud passe-
relle miroir GWm(C(u), C(w)) re-transmet un message provenant de C(u) quel que
soit le nœud qui le lui envoie et qui n’est donc pas ne´cessairement le nœud passe-
relle GW (C(u), C(w)). Les passerelles de secours agissent comme de´crit dans la sec-
tion 4.4.1.
Algorithm 3 Algorithme de diffusion
Pour tout nœud u, sur re´ception d’un message M provenant d’un nœud v ∈ Γ1(u)
⊲ A noter que v est le nœud qui a transmis M a` u mais pas force´ment la source de la diffusion.
if (u rec¸oit M pour la premie`re fois) then
if Diffusion ge´ne´rale then
if (Ch(u) 6= ∅) then
Re´-e´met
⊲ u est un nœud interne.
else
if ((C(u) = C(v)) et (u = GW (C(u),C(w))∀w ∈ V )) then
⊲ u est un nœud passerelle et M provient de son propre cluster.
1Les adresses IPv6 utilisent de´ja` ce ”scope” d’indication d’adresse multicast : local, global.
72 CHAPITRE 4. DIFFUSION
Re´-e´met
end
if ((C(u) 6= C(v)) et (u = GWm(C(v),C(u)))) then
⊲M provient d’un cluster pour lequel u est une passerelle miroir.
Re´-e´met
end
end
else
⊲ Il s’agit d’une diffusion dans un cluster.
⊲M n’est re´-e´mis que par les nœuds internes dudit cluster.
if ((C(v) = C(u)) et (Ch(u) 6= ∅)) then Re´-e´met end
end
end
4.5 Analyses et re´sultats de simulations
Dans un premier temps, nous avons simule´ le processus de se´lection des passerelles
afin de l’e´valuer. Puis, nous avons simule´ des diffusions globales dans tout le re´seau et
restreintes a` des clusters uniquement, en utilisant notre algorithme ainsi que d’autres
protocoles existants afin de comparer les performances de chacun des protocoles de
diffusion et de valider les re´sultats analytiques obtenus dans la section 4.3.
4.5.1 E´ lection et utilisation des passerelles
E´ tant donne´s deux clusters voisins C(u) et C(v), quatre types de passerelles sont pos-
sibles :
– Passerelle Feuille↔Feuille : GW (C(u), C(v)) et GWm(C(u), C(v)) sont deux
nœuds feuilles. Ce type de passerelle est le plus couˆteux puisque son utilisation
ajoute deux relais dans le processus de diffusion et cause donc plus de re´ceptions
redondantes.
– Passerelle Feuille↔Nœud interne : GW (C(u), C(v)) est une feuille et
GWm(C(u), C(v)) est un nœud interne. Ce type de passerelle n’ajoute qu’un
seul relais. Comme nous le verrons, c’est le type de passerelle le plus e´lu.
– Passerelle Nœud Interne↔Feuille : GW (C(u), C(v)) est un nœud interne et
GWm(C(u), C(v)) est un nœud feuille.
– Passerelle Nœud Interne↔Nœud Interne : GW (C(u), C(v)) et GWm(C(u), C(v))
sont deux nœuds internes. Ce type de passerelle est le moins couˆteux puisqu’il
n’ajoute aucun e´metteur et donc n’engendre aucune re´ception superflue. Bien que
cela soit le type de passerelle que l’algorithme cherche a` favoriser, il est le moins
courant.
La table 4.1 donne le nombre moyen de passerelles qu’un cluster doit e´lire et maintenir
en moyenne vers ses clusters voisins, ainsi que le nombre de passerelles qui sont effec-
tivement utilise´es lors de la diffusion d’un message dans tout le re´seau. On remarque
4.5. ANALYSES ET RE´SULTATS DE SIMULATIONS 73
500 nœuds 600 nœuds 700 nœuds
#clusters 11.93 11.64 11.36
#passerelles e´lues par cluster 5.86 6.02 6.16
#passerelles utilise´es par cluster 1.76 1.74 1.73
800 nœuds 900 nœuds 1000 nœuds
#clusters 11.30 11.14 10.72
#passerelles e´lues par cluster 6.20 6.22 6.26
#passerelles utilise´es par cluster 1.76 1.68 1.66
TAB. 4.1 – Nombre de passerelles e´lues et utilise´es par cluster lors d’une diffusion
ge´ne´rale initie´e par une source choisie ale´atoirement.
que le nombre de passerelles a` e´lire est raisonnable et quasiment constant malgre´ l’aug-
mentation de l’intensite´ des nœuds. Ceci de´montre une bonne caracte´ristique pour l’ex-
tensibilite´ de notre heuristique. Ne´anmoins, cette proprie´te´ e´tait pre´visible puisque,
comme constate´ dans le chapitre 3.6.1, le nombre de clusters est constant a` partir d’une
certaine intensite´ du processus sous-jacent et que les clusters forme´s correspondent
grossie`rement a` des cellules de Voronoı¨ centre´es sur les cluster-heads. Comme, dans
un diagramme de Voronoı¨, une cellule a 6 cellules voisines en moyenne, il en est de
meˆme pour nos clusters et donc pour le nombre de passerelles qu’ils doivent e´lire.
La figure 4.2(a) donne la proportion de chaque type de passerelles e´lues. On remar-
quera que les deux types de passerelles qu’on retrouve le moins sont celles de type
Feuille↔Nœud Interne et Nœud Interne↔Nœud Interne. Cela s’explique par le fait
que, par construction, la majeure partie des nœuds frontie`res sont des feuilles et donc,
la majeure partie des miroirs e´galement. Comme l’algorithme de se´lection conside`re
en priorite´ les nœuds internes pour le nœud passerelle, aussitoˆt qu’un nœud non feuille
est candidat, il est se´lectionne´. Comme il y a une majorite´ de feuilles sur les frontie`res,
ce nœud interne a une forte probabilite´ d’avoir une feuille comme miroir. Ceci explique
la forte proportion des passerelles Nœud Interne↔Feuille et Feuille↔Feuille. Plus le
re´seau est dense, plus on a de chances de trouver des nœuds internes aux frontie`res.
C’est pourquoi la proportion de passerelles de type Nœud Interne↔Feuille augmente
avec le nombre de nœuds alors que la proportion de passerelles Feuille↔Feuille
de´croıˆt.
Quand une diffusion ge´ne´rale est effectue´e, toutes les passerelles ne sont pas
ne´cessairement utilise´es. Si deux clusters voisins C(u) et C(v) sont relie´s par deux pas-
serelles Gateway(C(u), C(v)) et Gateway(C(v), C(u)), dans la plupart des cas, seule-
ment une des deux sera utilise´e. Comme le montre la table 4.1, le nombre de passerelles
utilise´es est quasiment constant et reste faible, toujours compris entre 1 et 2. Cela si-
gnifie que de fac¸on ge´ne´rale, ou le message diffuse´ pe´ne`tre un cluster et y meurt (dans
ce cas, il n’utilise qu’une seule passerelle), ou il le traverse et dans ce cas utilise deux
passerelles (une pour entrer et une pour en sortir). Ce phe´nome`ne s’explique par le fait
que nous conside´rons une couche MAC ide´ale et que le message se propage a` la meˆme
vitesse dans toutes les directions. Un message ne va donc pas ”contourner” un cluster
74 CHAPITRE 4. DIFFUSION
avant de l’inonder.
La figure 4.2(b) illustre la proportion de chaque type de passerelle utilise´e lors d’une
diffusion globale. La majorite´ des passerelles utilise´es sont celles n’ajoutant qu’un seul
relais dans le processus de diffusions. Cela est vrai meˆme pour des petits nombres de
nœuds alors que les passerelles Feuille↔Feuille e´taient majoritairement e´lues. Cela
montre une nouvelle caracte´ristique d’extensibilite´ de notre algorithme de diffusion : il
favorise l’utilisation des nœuds internes. Ainsi, comme le nombre moyen de passerelles
utilise´es est faible et que chacune d’elles n’ajoute qu’un relais dans le processus de
diffusion, le couˆt introduit par ces passerelles est faible.
0.45 0.6
0.55
0.4 Feuille<->Feuille
Noeud Interne<->Feuille
Feuille<->Noeud Interne 0.5 Feuille<->Feuille
Noeud Interne<->Noeud Interne Noeud Interne<->Feuille
0.35 Feuille<->Noeud Interne0.45 Noeud Interne<->Noeud Interne
0.3 0.4
0.35
0.25
0.3
0.2 0.25
0.15 0.2
0.15
0.1
0.1
0.05 0.05
500 550 600 650 700 750 800 850 900 950 1000 500 550 600 650 700 750 800 850 900 950 1000
Intensite du processus lambda Intensite du processus lambda
(a) Passerelles se´lectionne´es (b) Passerelles utilise´es
FIG. 4.2 – Proportion de chaque type de passerelles se´lectionne´es et utilise´es par
cluster.(+ : Feuille↔Feuille ; × : Nœud Interne↔Feuille ; ∗ : Feuille↔Nœud Interne ;
2 : Nœud Interne↔Nœud Interne)
4.5.2 Performances de la diffusion
De fac¸on a` e´valuer notre algorithme, nous avons choisi de le comparer a` des proto-
coles de diffusion existants les plus repre´sentatifs (cf. section 4.2) : blind flooding,
HCC [36] (sche´mas cluster-based), Multi-Point Relais (MPR) [65] (ensemble domi-
nant de´pendant de la source), le NES de Wu et Li [80] (ensemble dominant inde´pendant
de la source) et le sche´ma ”Wait & See” de I. Stojmenovic, M. Seddigh et J. Zunic [74]
(ensemble dominant base´ sur des valeurs ale´atoires). Comme mentionne´ lors des ana-
lyses the´oriques de la section 4.3, nous cherchons a` comparer ces algorithmes en terme
d’e´conomie d’e´nergie (nombre de messages envoye´s et rec¸us par nœud) et de bande
passante (nombre de messages envoye´s au total), en cherchant a` calculer l’impact du
degre´ des nœuds relais sur ces performances. C’est pourquoi nous avons releve´ la pro-
portion des nœuds qui re´-e´mettent le message diffuse´, le degre´ de ces nœuds relais ainsi
que l’impact de ces valeurs sur le nombre de copies redondantes d’un meˆme message
rec¸ues par nœud.
Dans la meˆme optique, nous avons simule´ deux variantes du protocole NES de Wu et
Li : la version originale [80] ou` la valeur de priorite´ utilise´e par les nœuds est l’identi-
Proportion de chaque type de passerelles elues
Proportion de chaque type de passerelles utilisees
4.5. ANALYSES ET RE´SULTATS DE SIMULATIONS 75
fiant des nœuds, et une version ou` la valeur de priorite´ est le degre´ des nœuds (plus l’Id
pour re´soudre les conflits) [26].
Nous avons e´galement mesure´ la latence2, excepte´ pour le protocole NES-”Wait &
See” ou` la latence de´pend de la taille de la feneˆtre dans laquelle les nœuds tirent un
temps d’attente ale´atoire.
A priori, un grand nombre de nœuds e´metteurs et de re´ceptions multiples ajoute de
la redondance au protocole et le rend the´oriquement plus re´sistant face a` la mobilite´
des nœuds et aux cassures de lien. C’est pourquoi, nous nous sommes inte´resse´s a`
l’impact du nombre de re´ceptions redondantes et du degre´ des relais sur la robustesse
des diffe´rents protocoles de diffusion.
Diffusion d’un message dans tout le re´seau (diffusion ge´ne´rale)
Nous analysons ici une diffusion d’un message dans tout le re´seau, initie´e par une
source choisie ale´atoirement parmi les nœuds du re´seau.
36 1
34 Blind Flooding
HCC 0.9
MPR
32 NES-’Wu et Li’
NES-’Wu et Li, degre’ 0.8
NES-’Wait&See’
30 Arbres de densite Blind Flooding
HCC
0.7 MPR
28 NES-’Wu et Li’
NES-’Wu et Li, degre’
26 0.6 NES-’Wait&See’Arbres de densite
24 0.5
22
0.4
20
0.3
18
16 0.2
14 0.1
500 550 600 650 700 750 800 850 900 950 1000 500 550 600 650 700 750 800 850 900 950 1000
Intensite du processus lambda Intensite du processus lambda
(a) Degre´ des e´metteurs (b) Proportion d’e´metteurs
FIG. 4.3 – Degre´ (a) et proportion (b) des e´metteurs en fonction des diffe´rents algo-
rithmes de diffusion et du nombre de nœuds.(+ : Blind Flooding ; × : HCC ; ∗ : MPR ;
2 : NES - Wu Li ; NES - Degre´ - Wu Li ; ⊖ NES - Wait & See ; • Arbres de densite´)
La figure 4.3 montre le degre´ dans le graphe des nœuds relais ainsi que leur proportion
dans le re´seau pour les diffe´rents algorithmes de diffusion conside´re´s.
La figure 4.3(a) montre le degre´ des relais. Comme dans le Blind Flooding, tous les
nœuds relaient le message, le degre´ moyen des relais correspond exactement au degre´
moyen des nœuds dans le graphe. Nous pouvons voir que notre algorithme maximise
le degre´ moyen des relais. En effet, notre algorithme e´lit les relais sur leur valeur de
densite´ qui est quasiment proportionnelle a` leur degre´. La version originale du NES
de Wu et Li et le NES-”Wait & See” e´lisent des relais de meˆme degre´, infe´rieur au
degre´ moyen. Ceci est duˆ au fait que plus un nœud a de voisins, plus il a de chances
2Temps au bout duquel tous les nœuds du re´seau ont rec¸u le message de diffusion.
Degre des relais
Proportion d’emetteurs
76 CHAPITRE 4. DIFFUSION
soit d’entendre l’un d’eux e´mettre avant la fin de son temps d’attente (dans le cas du
protocole ”Wait & See”) soit d’avoir e´te´ ”e´limine´” par les re`gles de se´lection de l’algo-
rithme de Wu et Li. On remarque e´galement que les courbes repre´sentant les degre´s des
MPR et des relais dans le Blind Flooding sont confondues. Ceci montre que les relais
utilise´s lors d’une diffusion avec les MPR sont choisis inde´pendamment de leur degre´.
Les protocoles HCC et le NES-degre´ Wu de Li choisissent des relais de fort degre´ par
construction, ce qui se retrouve dans les re´sultats.
La figure 4.3(b) montre la proportion de relais dans le re´seau. Comme dans le blind
flooding, tous les nœuds re-transmettent le message, cette proportion est e´gale a` 1. On
observe que le protocole ”Wait & See” est l’heuristique ne´cessitant le moins de relais,
ce qui implique que cette heuristique de´pense moins d’e´nergie en e´mission. Notre heu-
ristique obtient des re´sultats proches. On remarquera e´galement que les deux variantes
du protocole NES de Wu et Li ge´ne`rent approximativement le meˆme nombre de relais.
Cependant, comme vu lors des analyses the´oriques, le nombre de re´ceptions par nœud
ne peut eˆtre directement de´duit des re´sultats du degre´ des relais ou directement de la
proportion d’e´metteurs puisqu’il est en fait le produit des deux. Comme certaines des
heuristiques produisant le moins de relais sont e´galement celles dont les relais ont les
plus forts degre´s, nous ne pouvons en de´duire laquelle minimise le plus le nombre de
re´ceptions. Nous pouvons juste supposer que la variante du protocole NES utilisant
l’identifiant des nœuds induira moins de re´ceptions que la variante utilisant le degre´
des nœuds puisque pour un nombre e´quivalent de re´-e´metteurs, le degre´ de ses relais
est plus faible. La figure 4.4 montre le nombre de re´ceptions par nœud d’un message
diffuse´ dans tout le re´seau.
35
Blind Flooding
HCC
MPR
NES-’Wu et Li’
30 NES-’Wu et Li, degre’
NES-’Wait&See’
Arbres de densite
25
20
15
10
5
500 550 600 650 700 750 800 850 900 950 1000
Intensite du processus lambda
FIG. 4.4 – Nombre de re´ceptions par nœud en fonction du nombre de nœuds et des
diffe´rents algorithmes de diffusion.(+ : Blind Flooding ; × : HCC ; ∗ : MPR ; 2 : NES
- Wu Li ; NES - Degre´ Wu Li ; ⊖ NES - Wait & See ; • Densite´)
Ainsi, lorqu’un message est diffuse´ a` tous les nœuds du re´seau, l’algorithme NES-
”Wait & See” est celui induisant le moins de re´ceptions redondantes sur les nœuds,
de´pensant ainsi moins d’e´nergie et de ressources. On remarque que notre algorithme
obtient des re´sultats tre`s proches puisqu’il ne ge´ne`re qu’une re´ception de plus en
moyenne par nœud que ”Wait & See”. De plus, le ”Wait & See” e´tant base´ sur des
valeurs ale´atoires, la latence qu’il introduit est ine´vitablement supe´rieure a` celle intro-
Nombre de receptions par noeud
4.5. ANALYSES ET RE´SULTATS DE SIMULATIONS 77
duite par notre protocole. On remarque e´galement que la version originale du NES de
Wu et Li cause moins de re´ceptions que sa variante base´e sur le degre´ des nœuds.
Latence : Puisque dans l’algorithme de se´lection des MPR, les relais sont choisis de
fac¸on a` ce que le 2-voisinage d’un nœud soit atteint en 2 sauts, le k-voisinage de la
source est atteint en k sauts. Sous l’hypothe`se d’une couche MAC ide´ale, les MPR
donnent des re´sultats optimaux en terme de latence (ici e´quivalente aux nombres de
sauts). C’est pourquoi nous avons compare´ la latence produite par notre heuristique
a` celle produite par les MPR afin de mesurer l’e´cart entre notre solution et l’optimal.
Nous conside´rons une unite´ de temps comme une e´tape de transmission (c.a`.d. 1 saut).
Les re´sultats sont pre´sente´s dans la table 4.2. Meˆme si notre algorithme n’est pas op-
timal en terme de latence, il ne s’en e´loigne gue`re (2 sauts au plus). La figure 4.5
repre´sente la propagation temporelle d’une diffusion ge´ne´rale d’un message, initie´e
au temps 0 par une source centrale (en vert sur les sche´mas). Les cluster-heads ap-
paraissent en bleu. La couleur des autres nœuds de´pend du temps au bout duquel ils
rec¸oivent le message. Plus la couleur est claire, plus le temps est long.
(a) Propagation avec MPR (b) Propagation avec les arbres de
densite´
FIG. 4.5 – Temps de propagation d’un message diffuse´ dans tout le re´seau par une
source centrale en utilisant les MPR (a) et notre me´trique (b).
500 nœuds 700 nœuds 800 nœuds 900 nœuds 1000 nœuds
MOY MAX MOY MAX MOY MAX MOY MAX MOY MAX
MPR 5.13 8.97 4.88 8.40 4.88 8.40 4.81 8.23 4.78 8.07
Densite´ 6.31 11.05 6.22 10.78 6.24 10.95 6.15 10.66 6.19 10.74
TAB. 4.2 – Temps max et moyen pour recevoir le message. Les valeurs ”MAX” donnent
le temps au bout duquel tous les nœuds du re´seau ont rec¸u le message. Les valeurs
”MOY” donnent le temps moyen au bout duquel un nœud rec¸oit le message.
78 CHAPITRE 4. DIFFUSION
Diffusion dans un cluster.
On suppose maintenant qu’une diffusion est initie´e dans chaque cluster, par chaque
cluster-head. Nous avons donc autant de diffusions simultane´es que de clusters. Un
nœud applique le protocole de diffusion (quel qu’il soit) en ne conside´rant que les
nœuds appartenant au meˆme cluster que lui.
1 35
Blind Flooding
Blind Flooding MPR
MPR NES-’Wu&Li’
0.9 NES-’Wu&Li’ NES-’Wu&Li-degre’
NES-’Wu&Li-degre’ 30 NES-’Wait&See’NES-’Wait&See’ Arbres de densite
Arbres de densite
0.8
25
0.7
0.6 20
0.5
15
0.4
10
0.3
0.2 5
500 550 600 650 700 750 800 850 900 950 1000 500 550 600 650 700 750 800 850 900 950 1000
Intensite du processus lambda Intensite du processus lambda
(a) Proportion d’e´metteurs (b) Nombre de re´ceptions
FIG. 4.6 – Proportion de e´metteurs (a) et Nombre moyen de re´ceptions par nœud (b)
pour une diffusion dans un cluster en fonction de l’intensite´ du processus et du proto-
cole utilise´.(+ : Blind Flooding ; × : MPR ; ∗ : NES - Wu Li ; 2 : NES - Degre´ Wu Li ;
NES - Wait & See ; ⊖ Densite´ ).
On remarque sur la figure 4.6, que pour ce type de diffusion, notre algorithme est
celui qui minimise le plus le nombre de relais et de re´ceptions, obtenant meˆme des
performances e´gales ou supe´rieures a` celles du protocole NES ”Wait & See”.
Ces re´sultats confirment e´galement les re´sultats analytiques montrant que le nombre de
re´ceptions ne peut eˆtre de´duit directement de la proportion d’e´metteurs. Par exemple,
notre algorithme utilise moins de relais avec de plus forts degre´s que le ”Wait & See”
pour finalement induire autant de re´ceptions par nœud.
La table 4.3 et la figure 4.7 repre´sentent les re´sultats concernant la latence induite dans
de telle diffusion par notre heuristique. Comme pour une diffusion ge´ne´rale, la latence
obtenue est tre`s proche de l’optimale, s’en e´loignant seulement d’une demie unite´ de
temps pour le temps moyen. Cela montre e´galement que, meˆme si les routes dans les
arbres, du cluster-head vers les autres nœuds du cluster ne sont pas toujours les plus
courtes, elles en sont tre`s proches.
Remarque 3 A` l’exception de notre algorithme, base´ sur la densite´, une diffusion dans
un cluster est e´quivalente a` une diffusion dans un environnement fini pour les autres
algorithmes de diffusion, contrairement a` une diffusion ge´ne´rale qui correspond a` une
diffusion dans un environnement non borne´. On remarquera que tous les protocoles
sont plus robustes dans des environnements infinis.
Proportion de noeuds emetteurs
Nombre de receptions par noeud
4.5. ANALYSES ET RE´SULTATS DE SIMULATIONS 79
500 nœuds 700 nœuds 800 nœuds 900 nœuds 1000 nœuds
MOY MAX MOY MAX MOY MAX MOY MAX MOY MAX
MPR 1.76 4.71 1.78 4.85 1.81 4.83 1.81 4.80 1.82 5.00
Densite´ 1.80 5.08 1.83 5.38 1.87 5.29 1.87 5.50 1.88 5.30
TAB. 4.3 – Temps max et moyen pour recevoir le message dans un cluster. Les valeurs
”MAX” donnent le temps au bout duquel tous les nœuds du re´seau ont rec¸u le message.
Les valeurs ”MOY” donnent le temps moyen au bout duquel un nœud rec¸oit le message.
(a) Clusters (b) Propagation avec MPR (c) Propagation avec les arbres
de densite´
FIG. 4.7 – Temps de propagation d’un message diffuse´ dans chacun des clusters
repre´sente´s sur (a), en utilisant les MPR (b) et notre me´trique (c).
4.5.3 Robustesse de la diffusion
Apre`s avoir conside´re´ tous ces re´sultats, nous nous sommes interroge´s sur la robus-
tesse de ces protocoles (toujours en conside´rant la couche re´seau uniquement) envers
la cassure de liens. En effet, jusqu’a` maintenant, nous n’avons compare´ les diffe´rents
protocoles qu’en terme d’e´nergie e´pargne´e en limitant les re´ceptions redondantes et le
nombre de re´-e´metteurs. Cependant, la redondance apporte de la robustesse au proces-
sus de diffusion. Il est donc le´gitime de se demander si une limitation de la redondance
dans un environnement aux liens radios sensibles est bien une bonne approche ou si
la redondance en terme de nombre de re´ceptions a re´ellement un impact sur la robus-
tesse ? Nous nous sommes aussi interroge´s sur l’impact du degre´ des relais sur cette
robustesse : pour une redondance de messages e´quivalente, est-il pre´fe´rable d’avoir
peu de relais avec un fort degre´ ou un plus grand nombre de relais avec un plus petit
degre´ ?
Afin d’e´valuer cet aspect de la diffusion et de re´pondre a` ces diverses interrogations,
nous avons applique´ une probabilite´ de cassure sur les liens et mesure´ la proportion
de nœuds qui rec¸oivent encore le message diffuse´. Les simulations que nous avons
faites supposent que le message se propage avant qu’aucune information de routage ne
soit recalcule´e par les nœuds comme par exemple l’ensemble des MPR (pour l’heuris-
tique des MPR), l’ensemble des voisins a` e´liminer (pour les sche´mas NES) ou le pe`re
dans l’arbre de clustering (pour l’algorithme base´ sur la densite´). Comme dans le blind
80 CHAPITRE 4. DIFFUSION
flooding, tous les nœuds retransmettent le message, si des nœuds ne rec¸oivent pas le
message, cela implique que le re´seau n’est plus connexe.
La figure 4.8 donne la proportion des nœuds touche´s par la diffusion quand on applique
une probabilite´ de cassure sur les liens pour les deux types de diffusion (ge´ne´rale et
dans un cluster) et λ = 1000. Globalement, le comportement des diffe´rentes heuris-
tiques est le meˆme pour les deux types de diffusion, excepte´ pour notre algorithme. Par
exemple, le NES-”Wait & See” qui e´tait le meilleur protocole en terme de re´ceptions
et d’e´metteurs est le protocole le moins robuste, quel que soit le type de diffusion.
La figure 4.8(a) pre´sente les re´sultats pour une diffusion dans un cluster. E´ tonnamment,
il ne semble pas que le nombre de re´ceptions redondantes et la robustesse du protocole
soient lie´s. Par exemple, l’algorithme base´ sur les arbres de densite´ est l’un de ceux
induisant le moins de re´ceptions redondantes et pourtant l’un des plus robustes.
Il semble que les protocoles dont les relais ont un fort degre´ tendent a` eˆtre plus ro-
bustes. En effet, des protocoles avec des relais a` fort degre´ (NES-degre´ et Densite´) sont
tre`s robustes alors que ceux avec des relais a` plus faible degre´ comme les MPR ou
le NES-”Wait & See” pre´sentent les pires comportements. Le NES-Wu&Li est moins
robuste que sa variante NES-degre´ (qui augmente le degre´ des relais). La redondance
en terme de nombre de re´ceptions multiples est donc tre`s couˆteuse en terme d’e´nergie
consomme´e et de bande passante utilise´e, sans pour autant apporter plus de robustesse
au processus de diffusion.
Notre heuristique pre´sente une bonne robustesse envers les cassures de liens lors d’une
diffusion dans un cluster. Comme elle minimise e´galement a` la fois le nombre de re-
lais et le nombre de re´ceptions par nœud, elle constitue le meilleur compromis couˆt-
robustesse-latence.
1 1
0.9 0.9
0.8 0.8
0.7 0.7
0.6 0.6
0.5 0.5
0.4 0.4
0.3 Blind Flooding 0.3 Blind Flooding
MPR MPR
NES-’Wu&Li’ NES-’Wu&Li’
0.2 NES-’Wu&Li-degre’ 0.2 NES-’Wu&Li-degre’
NES-’Wait&See’ NES-’Wait&See’
Arbre de densite Arbres de densite
0.1 0.1
0 0
0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1
Probabilite de cassure de liens Probabilite de cassure de liens
(a) Cassure de liens - diffusion dans un cluster (b) Cassure de liens - diffusion globale
FIG. 4.8 – Proportion de nœuds recevant toujours le message de diffusion apre`s appli-
cation d’une probabilite´ de cassure sur les liens lors d’une diffusion dans un cluster (a)
ou dans tout le re´seau (b).
Cependant, comme le montre la figure 4.8(b), notre algorithme est bien moins robuste
lorsqu’il s’agit d’une diffusion globale. Il reste plus robuste que le NES-”Wait & See”
Proportion de noeuds recevant le message
Proportion de noeuds recevant le message
4.5. ANALYSES ET RE´SULTATS DE SIMULATIONS 81
mais bien moins que le protocole NES de Wu et Li. Ce re´sultat, couple´ au fait que
notre heuristique est tre`s robuste lorsque le message est propage´ dans un cluster seule-
ment, montre que les liens sensibles dans une diffusion ge´ne´rale sont les passerelles.
En effet, si un cluster A ne peut eˆtre atteint que par le cluster B et que les nœuds de la
passerelle de B vers A tombent, l’ensemble du cluster A est alors isole´ de la diffusion.
Afin d’ajouter de la robustesse a` ce niveau, il est donc souhaitable d’e´lire plusieurs
passerelles entre deux clusters voisins. E´ lire plus d’une passerelle n’ajoute aucun couˆt
lors de la phase d’e´lection (aucun message supple´mentaire n’est utile) mais l’utilisation
de passerelles supple´mentaires engendre plus d’e´metteurs et de re´ceptions redondantes
lors de la propagation d’un message. Il y a donc un compromis a` faire entre le nombre
de passerelles a` e´lire et le couˆt de leur utilisation. De fac¸on a` estimer ce compromis,
nous avons simule´ une diffusion d’un message dans le re´seau en augmentant le nombre
de passerelles utilise´es. Les re´sultats sont donne´s par la figure 4.9. L’ajout de passe-
relles apporte vite de la robustesse au protocole, ce qui confirme le fait qu’il s’agissait
bien des liens sensibles. Comme le montre la figure 4.9(a), e´lire trois passerelles entre
chaque paire de clusters voisins permet d’obtenir la meˆme robustesse que pour le pro-
tocole NES de Wu et Li, sans pour autant produire plus de re´ceptions et d’e´metteurs
que ces heuristiques (figures 4.9(b) et 4.9(c)).
1 1
Blind Flooding
0.9 MPR0.9 NES-’Wu et Li’
NES-’Wait&See’
0.8 Arbres de densite-1 passerelle0.8 Arbres de densite-2 passerellesArbres de densite-3 passerelles
Arbres de densite-4 passerelles
0.7
0.7
0.6
0.6
0.5
0.5
0.4 Blind Flooding
MPR
NES-’Wu&Li’ 0.4
0.3 NES-’Wait&See’
Arbres de densite-1 passerelle
arbres de densite-2 passerelles 0.3
0.2 Arbres de densite-3 passerellesArbres de densite-4 passerelles
0.2
0.1
0 0.1
0 0.2 0.4 0.6 0.8 1 500 550 600 650 700 750 800 850 900 950 1000
Probabilite de cassure de liens Intensite du processus lambda
(a) Robustesse (b) Proportion d’e´metteurs
14
Blind Flooding
MPR
NES-’Wu et Li’
NES-’Wait&See’
12 Arbres de densite-1 passerelleArbres de densite-2 passerelles
Arbres de densite-3 passerelles
Arbres de densite-4 passerelles
10
+ Blind Flooding
8 × MPR
∗ NES - Wu Li
6 2 NES - Wait & See
Densite´ - 1 passerelle
4 ⊖ Densite´ 2 passerelles
500 550 600 650 700 750 800 850 900 950 1000 • Densite´ 3 passerelles
Intensite du processus lambda △ Densite´ 4 passerelles
(c) Re´ceptions par nœud (d) Le´gende
FIG. 4.9 – Robustesse envers les cassures de liens (a), Proportion d’e´metteurs (b) et
nombre de re´ceptions par nœud (c).
Proportion de noeuds recevant le message
Nombre de receptions par noeud
Proportion d’emetteurs
82 CHAPITRE 4. DIFFUSION
4.6 Analyse de la se´lection des MPR dans OLSR
Comme nous l’avons de´ja` vu, OLSR est un protocole de routage pro-actif pour les
re´seaux ad hoc, re´cemment standardise´ a` l’IETF. Il utilise le concept des Multi-Points
Relais (MPR) pour minimiser le trafic de controˆle et calculer les plus courts chemins
entre toute paire de nœuds. Chaque nœud du re´seau choisit ses MPR dans son voisinage
a` un saut. Lorsqu’un nœud u rec¸oit un message M d’un voisin v, il ne le re-transmet
que si c’est la premie`re fois qu’il rec¸oit M et si v a de´signe´ u comme e´tant un de ses
MPR. La se´lection des MPR consiste pour un nœud u a` choisir un ensemble minimal
de nœuds parmi ses voisins de telle fac¸on que l’ensemble des 2-voisins de u soit ainsi
couvert (c.a`.d. que chaque 2-voisin de u rec¸oit une transmission d’au moins un MPR
de u). De cette fac¸on, meˆme si u ne conside`re que les MPR dans son voisinage, il peut
joindre tous ses 2-voisins en 2 sauts, et par extension son k-voisinage en k sauts.
Ce protocole est tre`s ce´le`bre et pourtant, il est loin d’obtenir les meilleurs re´sultats.
Nous nous sommes alors penche´s sur la se´lection des MPR afin de l’analyser plus en
de´tail et de comprendre pourquoi.
4.6.1 La se´lection des MPR
Comme la se´lection optimale d’un ensemble minimum de MPR est un proble`me NP-
complet [40], nous donnons ici l’heuristique gloutonne de se´lection des MPR qui est
celle actuellement utilise´e dans l’imple´mentation d’OLSR.
Pour un nœud v ∈ Γ(u) nous notons d+, u (v) le nombre de nœuds que u peut atteindre
en deux sauts via v :
d+u (v) = |Γ2(u) ∩ Γ(v)|
Pour un nœud v ∈ Γ (u) soit d−2 , u (v) le nombre de nœuds dans le voisinage de u qui
permettent de connecter u et v en deux sauts :
d−u (v) = |Γ(u) ∩ Γ(v)|
Le nœud u se´lectionne dansΓ(u) un ensemble de nœuds couvrant inte´gralementΓ2(u).
Cet ensemble est l’ensemble des MPR de u. Nous le notons MPR(u). Chaque nœud a
donc son propre ensemble de MPR qui est diffe´rent d’un nœud a` l’autre. Par de´finition,
MPR(u) est tel que : ⋃
u ∪ Γ2(u) ⊂ Γ(v)
v∈MPR(u)
Conside´rant un nœud u, nous appelons ”nœud isole´” pour u, tout nœud v ∈ Γ2(u) pour
lequel il n’existe qu’un chemin a` deux sauts de u a` v. En d’autres termes, un nœud v
est dit isole´ pour u si d−u (v) = 1.
L’algorithme de se´lection des MPR est exe´cute´ sur chaque nœud et suppose que chaque
nœud connaıˆt ses voisins a` 1 et 2 sauts. Il se de´compose en deux e´tapes. Nous notons
4.6. ANALYSE DE LA SE´LECTION DES MPR DANS OLSR 83
MPR1 l’ensemble des nœuds MPR se´lectionne´s lors de la premie`re e´tape de l’algo-
rithme. Les MPR1 permettent de couvrir les nœuds isole´s. L’algorithme de se´lection
des MPR est le suivant.
Algorithm 4 Algorithme glouton de se´lection des MPR - Exe´cute´ sur chaque nœud.
Γ′(u) = Γ(u) et Γ′2(u) = Γ2(u).
⊲ Premie`re e´tape
Pour tout nœud v ∈ Γ(u)
if (∃w ∈ Γ(v) ∩ Γ (u) | d−2 u (w) = 1) then
Se´lectionne v comme MPR(u).
⊲ Se´lectionne comme MPR(u), les nœuds de Γ(u) couvrant les nœuds ”isole´s”.
Retire v de Γ′(u) et retire Γ(v) ∩ Γ (u) de Γ′2 2(u).
end
⊲ Seconde e´tape
while (Γ′2(u) 6= ∅)
Pour tout nœud v ∈ Γ′(u)
if (d+(v) = max d+u w∈Γ′(u) u (w)) then
Se´lectionne v comme MPR(u).
⊲ Se´lectionne comme MPR(u) le nœud v permettant de rattacher le plus de nœuds de
Γ2(u) a` u en deux sauts.
Retire v de Γ′(u) et retire Γ(v) ∩ Γ (u) de Γ′2 2(u).
end
Afin de mieux comprendre cet algorithme, exe´cutons-le sur le nœud u en vert sur
l’exemple de la figure 4.10. Les nœuds isole´s apparaissent en rouge, hachure´s hori-
zontalement. Par exemple, le nœud t est un nœud isole´ pour u car le nœud h est le
seul de ses voisins dans Γ(u). Le nœud h sera donc e´lu lors de la premie`re e´tape de
l’algorithme : h ∈MPR1. De la meˆme fac¸on, u e´lira les nœuds bleus, hachure´s verti-
calement h, i, c, g comme MPR1. Les nœuds k, j, t, s, r, q, o,m, l de Γ2(u) sont ainsi
couverts. Le nœud u passe alors a` la seconde e´tape de l’algorithme et ne conside`re dans
Γ2(u) que les nœuds non encore couverts (p et n) et dans Γ1 les nœuds non MPR1
(b, f , e et d). Il ne garde donc qu’une vue re´duite de la topologie comme illustre´ sur
la figure 4.10(b). Il se´lectionne alors son voisin de plus fort degre´ dans ce graphe.
Comme le nœud e couvre n et p alors que f et d ne couvrent chacun qu’un nœud
de Γ2(u) (resp. p et n), c’est e qui est e´lu. A partir de la`, tous les nœuds de Γ2(u)
sont couverts par les nœuds se´lectionne´s comme MPR, l’algorithme s’arreˆte. On a :
MPR(u) = {c, e, i, h, g}.
Plusieurs algorithmes [8, 41, 53] ont e´te´ propose´s afin d’ame´liorer cet algorithme
et re´duire le nombre de MPR se´lectionne´s. Cependant, aucun d’eux ne re´duit
conside´rablement le nombre de MPR. Comme on peut le constater, la premie`re e´tape
de l’algorithme glouton ne peut eˆtre supprime´e, quel que soit l’algorithme de se´lection,
puisqu’elle seule permet de couvrir tous les nœuds isole´s. De plus, si on veut minimi-
ser le nombre de MPR, cette e´tape doit eˆtre exe´cute´e en premier lieu. C’est pourquoi,
toutes les variantes de cet algorithme ne portent en fait que sur la deuxie`me e´tape, ce
qui laisse in fine une faible marge de manœuvre, comme nous allons le montrer.
84 CHAPITRE 4. DIFFUSION
  
  
  
 l  b
  
  
  
  
 k 
  
  
 m 
b   
  
 j               c
  
   i         
      n
n u d
  
t         u
   d
     
   h
     
o
      e e
s    g  
      f f
p
  
 q 
  
   p
 r    
  
  
(a) Topologie globale - Les nœuds isole´s de u ap- (b) Topologie conside´re´e par u a` la fin
paraissent en rouge et hachure´s horizontalement, les de la premie`re e´tape
MPR1 de u apparaissent en bleu et hachure´s verti-
calement.
FIG. 4.10 – Illustration de l’algorithme de se´lection des MPR.
4.6.2 Analyse
Nous nous sommes inte´resse´s aux proprie´te´s d’un ensemble MPR se´lectionne´ par un
nœud donne´. C’est pourquoi, dans notre analyse, nous ne conside´rons pas l’ensemble
du re´seau mais un point particulier, ainsi que son voisinage a` 1 et 2 sauts. En effet,
l’algorithme de se´lection de MPR est distribue´ et exe´cute´ inde´pendamment par chaque
nœud a` partir de sa connaissance de son voisinage a` 1 et 2 sauts.
Soit B(x,R) la boule de rayonR centre´e en x. Nous distribuons un processus ponctuel
de Poisson d’intensite´ λ > 0 dans B(0, 2R) et ajoutons un point 0 au centre de la
boule. Le voisinage de 0 est donc, par de´finition, l’ensemble des points du processus
se trouvant dans B(0, R)\0. C’est pour ce point 0 que nous e´tudions l’algorithme de
se´lection des MPR.
Re´sultats ge´ne´raux.
Avant de donner les re´sultats concernant l’e´tude des MPR, nous donnons des re´sultats
plus ge´ne´raux qui nous serviront pour les calculs suivants.
Soit A(r) l’aire de l’intersection de deux boules de rayon R dont les centres sont dis-
tants de r (figure 4.11(a)) :
( √r ) r2
A(r) = 2R2 arccos − r R2 −
2R 4
et A1(u, r, R) l’aire de l’union de deux disques de rayons respectifs R et u et dont les
centres sont distants de r (figure 4.11(b)) :
s
 
R2 − u2 + r2 2 u2 − R2 − r2 R2 − u2 − r2
A1(u, r,R) = rR 1− −R
2 arccos − u2 arccos
2Rr 2Rr 2ur
4.6. ANALYSE DE LA SE´LECTION DES MPR DANS OLSR 85
                         
                         
 
                         
                         
                         
                         
                         
R u RR                          
                         
                         
                         
                         
                         
                         
                         
                         
r r
(a) A(r) est l’aire en bleu : aire (b) A1(u, r, R) est l’aire hachure´e :
de l’intersection de deux boules de union des aires de deux disques de rayons
rayon R. R et u.
FIG. 4.11 – Illustration des aires A(r) et A1(u, r, R).
Nous sommes alors en mesure d e´valuer les valeurs moyennes de d+ d−’ 0 , 0 , |Γ(0)| et
|Γ2(0)| pour une distribution poissonnienne.
Proposition 4 Soit u ∈ Γ(0) un point uniforme´ment distribue´ dans B(0, R).
La valeur moyenne de d+0 (u) est donne´e par :
[ ] ∫ √λ 2pi ∫ R+ 2 − 2 3 3E d0 (u) = (piR A(r))rdrdθ = λRpiR2 0 0 4
Pour obtenir la valeur moyenne de d+0 (u), l’ide´e est de compter le nombre moyen de
points se trouvant dans l’aire de l’intersection de B(u,R) (1-voisinage de u) et de
B(0, 2R)\B(0, R) (2-voisinage de 0) et de sommer pour tout point u ∈ Γ(0).
Soit v ∈ Γ2(0) un point uniforme´ment distribue´ dans B(0, 2R)\B(0, R). La valeur
moyenne de d−0 (v) est donne´e par :
[ ] ∫ √2R
− 2 2 3
E d0 (v) = λ A(r)rdr = λR3R2 R 4
Pour obtenir la valeur moyenne de d−0 (v), on compte le nombre de points se trou-
vant dans l’intersection de B(v,R) (1-voisins de v) et de B(0, R) (1-voisins de 0)
et on somme pour tout point v ∈ Γ2(0). On remarquera que v peut se trouver dans
B(0, 2R)\B(0, R) sans pour autant eˆtre un 2-voisin de 0 dans le cas ou` 0 et v n’ont
aucun voisin commun (si Γ(v) ∩ Γ(0) = ∅). Ainsi, pour obtenir le nombre moyen de
2-voisins de 0, nous devons conditionner le nombre de points v dans B(R, 2R) par la
probabilite´ que v soit un 2-voisin de 0, c.a`.d par la probabili
Nous obtenons : [ ] [ ]
te´ que {Γ(v) ∩ Γ(0) 6= ∅}.
−
− E d0 (v)
E d0 (v)|v ∈ Γ2(0) = (d−P 0 (v) > 0)
86 CHAPITRE 4. DIFFUSION
ou` ( ) ∫2 2R
d−P 0 (v) > 0 = 1− exp{−λA(r)}rdr3R2 R
La taille moyenne du voisinage de 0 est donne´e par :
δ˜(0) = [|Γ(0)|] = λpiR2E
Le nombre moyen de voisins a` deux sauts de 0 (|Γ2(0)|) correspond au nombre de
points v du processus se trouvant dans B(0, 2R)\B(0, R), conditionne´ par la proba-
bilite´ qu’il existe un voisin commun a` chaque v et 0
| | ( )
. On obtient :
2
E [ Γ2(0) ] = 3λpiR P( d−0 (v) >∫0 )
2 2R
= 3λpiR2 1− exp{−λA(r)}rdr
3R2 R
Analyse de la premie`re e´tape de l’algorithme de se´lection des MPR.
Nous nous inte´ressons maintenant plus particulie`rement a` la premie`re e´tape de l’al-
gorithme de se´lection. Dans un premier temps, nous de´terminons le nombre moyen
de points isole´s pour le point 0. Comme nous l’avons vu, l’unique voisin d’un point
isole´ appartenant aussi a` Γ(0) est obligatoirement un MPR1. Cependant, le nombre
de points isole´s ne nous donne pas directement le nombre de MPR1 mais une borne
supe´rieure car un meˆmeMPR1 peut couvrir plusieurs points isole´s. Par exemple, sur la
figure 4.10(a), nous avons quatre MPR1 mais sept nœuds isole´s. Le MPR1 i permet
de couvrir deux nœuds isole´s : les nœuds j et k.
Par de´finition les nœuds isole´s sont les nœuds v ∈ Γ (0)(u) tels que d−, 2 0 (v) = 1.
Proposition 5 Soit v un point uniforme´ment distribue´ dans B(0, 2R)\B(0, R) et D
l ensemble des points isole´s v (tels que d−’ 0 (v) = 1). On obtient :
( ) ∫2 2R
d−P 0 (v) = 1 = λA(r)exp{−λA(r)}rdr3R2 R
Tout comme dans la proposition 4, nous ne conside´rons que les nœuds v tels que v ∈
Γ2(0) : ( ) (P
P d−0 (v) = 1|v ∈ Γ2(0) = (d−0 (v) = 1)
)
−
P d0 (v) > 0
Nous pouvons alors de´duire de cette∫probabilite´ le nombre moyen de points isole´s :2R
E [|D|] = 2piλ2 A(r)exp{−λA(r)}rdr
R
qui constitue une borne supe´rieure pour le nombre de MPR1 :
E [|MPR1|] ≤ E [|D|]
4.6. ANALYSE DE LA SE´LECTION DES MPR DANS OLSR 87
Dans la proposition suivante, nous donnons une borne infe´rieure du nombre moyen de
MPR1 :
Proposition 6 Soit u un point uniforme´ment distribue´ dans B(0, R).
Z Z
2   R R+r   
P (u ∈MPR1) ≥ d
+
P 0 (u) > 0 f(x, r,R) exp {−λ 2πR
2−A1(R, x,R) }rdxdr
R2 0 R
ou` f(x, r, R) est la fonction densite´ de probabilite´ :
[ ]
∂
− λ A1(x, r, R)− 2pix ( )f(x, r, R) = ∂x− {− − } exp {−λ A1(x, r, R)− pix2 }1 exp λ (A (R, r,R) piR21 )
De cette probabilite´, nous pouvons de´duire une borne infe´rieure pour le nombre moyen
de MPR1 :
Z Z
  R R+r
+   
E [|MPR1|] ≥ 2λπP d0 (u) > 0 f(x, r,R) exp {−λ 2πR
2−A1(R, x,R) }rdxdr
0 R
Preuve 6 Pour e´tablir la borne infe´rieure de la probabilite´ qu’un point de Γ(0) soit un
MPR1, nous nous basons sur une condition suffisante. Une condition suffisante pour
que u ∈ MPR1 est que le point w de Γ(u) le plus e´loigne´ de 0 est un point isole´
(d−0 (w) = 1).
Connaissant r, la distance entre 0 et u, on est capable de calculer la distribution de la
distance entre 0 et w (le point du voisinage de u qui est le plus e´loigne´ de 0). Sachant
alors la distance x entre 0 et w, on calcule la probabilite´ qu’il n’existe qu’un seul
point (le point u) dans l’intersection des voisinages de 0 et w. Cette dernie`re condition
garantit que w est un point isole´ et que u ∈ MPR1. On inte`gre alors cette dernie`re
probabilite´ par les distributions de r et de x pour obtenir le re´sultat final. Cette borne
est tre`s fine puisque, dans la plupart des cas, les points isole´s sont les nœuds les plus
e´loigne´s de 0. 
Nous nous sommes aussi inte´resse´s a` la distribution spatiale des MPR1. Nous avons
pour cela calcule´ un encadrement de la probabilite´ qu’un point u ∈ Γ(0) a` distance
r de 0 soit un MPR1 en fonction de sa distance a` 0. Pour cela, nous conside´rons un
point u ∈ Γ(0) a` distance r (0 < r ≤ R) de 0. Nous fixons ces deux points (u et
0) et distribuons les points du processus de Poisson dans B(0, 2R) inde´pendamment
de ces deux points. Nous cherchons alors quelle est la probabilite´ que ce nœud soit
un MPR1(0). Dans la proposition suivante, nous proposons un encadrement de cette
probabilite´.
88 CHAPITRE 4. DIFFUSION
Proposition 7 Soit u un point a` distance r (0 < r ≤ R) de 0.
Z R+r
  
(u ∈MPR ) ≥ 1− exp {−λ(πR2 − A(r))} f(v, r,R) exp {−λ(2πR2P 1 − A1(R, v, R))}dv
R
( )2
A(R+ r)
P (u ∈MPR1) ≤ 1− 1− exp {−λ }
2
Preuve 7 La borne infe´rieure est obtenue de la meˆme fac¸on que la borne infe´rieure
du nombre de MPR1 donne´e dans la proposition 6, mais la distance entre 0 et u est
cette fois fixe´e. La borne supe´rieure est obtenue a` partir de l’ide´e suivante. S’il existe
des points v dans les deux demi-intersections de cercle illustre´s sur la figure 4.12, la
plupart des voisins de u appartenant a` Γ(u) ∩ Γ2(0) sont couverts par ces points v
(en plus de u) et ne sont donc pas isole´s. Concernant les points non couverts par les
points v, nous pouvons montrer facilement que la meˆme borne reste valable. Cela nous
donne une probabilite´ que u ne soit pas un MPR1, de laquelle nous pouvons de´duire
la probabilite´ que u soit un MPR1. 
Upper semi−intersection
0 u
Lower semi−intersection
r R
FIG. 4.12 – Les deux demi-intersections utilise´es dans la preuve de la proposition 7.
4.6.3 Re´sultats nume´riques et simulations
Afin d’estimer de fac¸on nume´rique les re´sultats obtenus pre´ce´demment, nous avons
simule´ l’algorithme de se´lection des MPR. Nous utilisons le meˆme mode`le que celui
e´tudie´ lors de l’analyse the´orique, a` savoir que les nœuds sont re´partis sur une boule
B(0, 2) (R = 1) avec un processus ponctuel de Poisson d’intensite´ λ > 0. Nous
ajoutons le point 0 au centre de la boule et e´tudions le nombre de MPR se´lectionne´s par
ce point a` chaque e´tape de l’algorithme. La figure 4.13 repre´sente des e´chantillons du
mode`le pour diffe´rentes valeurs de λ. Le point 0 pour lequel nous e´tudions l’algorithme
est le point noir central. Les points a` l’inte´rieur de cercle sont les points de Γ(0), les
4.6. ANALYSE DE LA SE´LECTION DES MPR DANS OLSR 89
(a) λπ = 6 (b) λπ = 45
FIG. 4.13 – Se´lection des MPR pour λpi = 6 et λpi = 45.
plus gros e´tant les MPR1. Les points a` l’exte´rieur du cercle sont les voisins a` deux
sauts de 0, les points bleus e´tant ceux couverts par les MPR1.
On remarquera que dans les deux cas, la quasi totalite´ du 2-voisinage de 0 est couvert
par les MPR1. L’ajout d’un seul point MPR suffirait a` couvrir l’inte´gralite´ de Γ2(0).
Nous avons vu qu’il existe en moyenne un grand nombre de points isole´s, donnant
naissance a` un grand nombre de MPR1. Ces MPR1 semblent eˆtre re´gulie`rement
distribue´s pre`s de la frontie`re de B(0, R), ce qui confirme les re´sultats obtenus dans la
proposition 7 et explique pourquoi ils couvrent une grande partie de Γ2(0).
 20
analytic lower bound 1
analytic upper bound
18 number of MPR selected at the step 1 total number of MPR
 16 0,8
 14
0,6
 12
 10
0,4
 8
 6
0,2
 4
 2 0
0,2 0,3 0,4 0,5 0,6 0,7 0,8 0,9
 20  40  60  80  100  120
mean number of neighbors distance from the origin
(a) Nombre moyen de MPR et MPR1 obtenus (b) Bornes infe´rieure et supe´rieure de la
par simulation et bornes analytiques du nombre de probabilite´ pour un voisin de 0 d’eˆtre un
MPR1. MPR1(0) en fonction de la distance au
point 0.
FIG. 4.14 – Comparaison des re´sultats analytiques et de simulation.
La figure 4.14(a) montre le nombre moyen de MPR et MPR1 obtenus par simulation
ainsi que les bornes analytiques du nombre de MPR1. On observera qu’approxima-
tivement 75% des MPR sont e´lus lors de la premie`re e´tape de l’algorithme (et sont
number of MPR
90 CHAPITRE 4. DIFFUSION
des MPR1), ce qui confirme le fait que les MPR1 couvrent la quasi-totalite´ du 2-
voisinage. Comme mentionne´ auparavant, la borne infe´rieure est une borne tre`s fine du
nombre de MPR1 moyen.
L’encadrement de la probabilite´ qu’un voisin de 0 soit e´lu comme MPR1(0) (donne´
dans la proposition 7), nous permet de montrer que lesMPR1 sont re´partis a` proximite´
de la frontie`re de la porte´e radio R de 0. La figure 4.14(b) montre ces bornes pour une
distance r entre les nœuds 0 et ses voisins variant de 0.2 a` 0.999 pour λ = 15. On
remarque que ces re´sultats de´pendent de λ : plus λ augmente, plus la distance entre 0
et ses MPR1 augmente aussi (puisque 0 a plus de chances d’avoir des voisins proches
de la frontie`re).
4.6.4 Conse´quences
Comme nous l’avons vu dans les sections pre´ce´dentes, le but recherche´ en introduisant
les MPR est de minimiser le nombre de relais lors de la diffusion du trafic de controˆle.
Le nombre de MPR doit donc eˆtre aussi petit que possible. Bien que plusieurs travaux
aient cherche´ a` optimiser l’algorithme glouton de se´lection des MPR, seule la seconde
e´tape de l’algorithme peut eˆtre ame´liore´e puisque la premie`re est indispensable pour
couvrir l’ensemble du 2-voisinage d’un nœud. Or, comme nous avons pu le constater
au cours de nos analyses et simulations, cette premie`re e´tape me`ne a` la se´lection de
plus de 75% des MPR. Cela signifie que les ame´liorations pouvant eˆtre apporte´es ne
portent que sur 25% des MPR, ce qui explique que les variantes de l’algorithme de
se´lection ne produisent aucune ame´lioration significative.
Malheureusement, cette caracte´ristique peut e´galement eˆtre une source de proble`me de
robustesse. En effet, si 75% des MPR de u couvrent au moins un nœud isole´, la perte
d’un de ces nœuds engendre une forte probabilite´ qu’au moins un voisin v a` 2 sauts de
u ne rec¸oive plus un message envoye´ u. Il se peut bein suˆr que v rec¸oive le message
de u via un autre chemin mais ce dernier serait plus optimal comme le clame OLSR.
De plus, si v est tel que v ∈ MPR(u) et v ∈/ MPR(w), il peut recevoir un message
pour la premie`re fois par w plutoˆt que u mais ne le re-transmettra pas puisqu’il n’est
pas un MPR de w. Cela peut conduire a` l’isolation de certaines parties du re´seau lors
d’une diffusion, comme l’illustre la figure 4.15. Les nuages repre´sentent deux parties
connexes du re´seau, connecte´es par les nœuds b et c. Comme le nœud e est un nœud
isole´ pour a, a e´lit c en tant que MPR. Il ne choisit pas b puisque le nœud d couvert
par b l’est e´galement par c. Supposons que le lien entre c et a tombe et que la diffusion
se propage avant que a n’ait pu recalculer ses MPR. Bien que le re´seau soit encore
connecte´, la partie droite du re´seau ne sera pas touche´e par la diffusion car b n’e´tant
pas MPR de a, il ne re-transmettra pas le message. Ce phe´nome`ne peut expliquer les
mauvais re´sultats obtenus par les MPR lors de l’e´tude de la robustesse des protocoles
de diffusion en section 4.5. De plus, les liens entre un nœud et ses MPR ont de fortes
probabilite´s de casser dans un environnement mobile puisque, comme nous avons pu le
constater, les MPR sont situe´s a` proximite´ de la frontie`re de la porte´e de transmission
des nœuds. Ils sont donc plus enclins a` basculer en dehors de la zone de transmission
et ainsi a` casser le lien radio.
4.7. CONCLUSION ET PERSPECTIVES 91
b
d
a
c e
(a)
FIG. 4.15 – Exemple.
4.7 Conclusion et perspectives
Dans ce chapitre, nous avons tire´ avantage de certaines caracte´ristiques des clusters
forme´s par notre heuristique pour proposer une utilisation supple´mentaire de la struc-
ture. En effet, la structure d’arbres sous-jacente des clusters permet l’application d’un
protocole de diffusion aussi bien dans un cluster que sur l’ensemble du re´seau, ceci
avec un couˆt faible et borne´ et une maintenance quasi-locale. Nous avons analyse´ de
fac¸on the´orique le nombre de re´ceptions par nœud lors d’une diffusion. Puis, nous
avons pu constater que notre algorithme de diffusion proposait le meilleur compromis
couˆt en e´nergie - latence - robustesse parmi les protocoles de diffusion existant dans la
litte´rature.
Dans le futur, il serait inte´ressant d’e´tudier ce protocole dans un environnement plus
mobile. Dans notre approche, nous conside´rons une couche MAC ide´ale afin de pouvoir
comparer les protocoles de niveau 3 sans s’occuper des proble`mes qui peuvent surve-
nir aux niveaux infe´rieurs et influer sur les performances de chacun de ces protocoles.
Cependant, comme nous l’avons mentionne´, plus le nombre de messages e´change´s
est important, plus fortes sont les collisions survenant aux niveaux infe´rieurs. Il sem-
blerait donc inte´ressant d’e´tudier un protocole de diffusion qui ne soit pas cloisonne´
a` la couche re´seau mais qui prenne en conside´ration les caracte´ristiques de plusieurs
couches en meˆme temps, plutoˆt que de chercher a` optimiser un protocole a` un niveau
particulier.
92 CHAPITRE 4. DIFFUSION
4.8 Publications
1. Journaux et revues avec comite´ de lecture :
(a) Efficient Broadcasting in Self-Organizing Sensor Networks. Nathalie Mit-
ton, Anthony Busson et E´ ric Fleury. International Journal of Distributed
Sensor Networks (IJDSN), Volume 1, Janvier 2006.
2. Colloques et confe´rences internationaux avec comite´ de lecture :
(a) Efficient Broadcasting in Self-Organizing Multi-Hop Wireless Network.
Nathalie Mitton, E´ ric Fleury. Conference on AD-HOC Networks & Wire-
less (Ad Hoc Now’05), 6-8 Octobre 2005, Cancu`n, Mexique. Se´lectionne´
parmi les meilleurs papiers pour une soumission a` une issue spe´ciale du
journal JDA.
(b) An analysis of the MPR selection in OLSR and consequences. Anthony
Busson, Nathalie Mitton and E´ ric Fleury. Mediterranean Ad Hoc Net-
working Workshop (MED-HOC-NET’05), Juin 2005, Ile de Porquerolles,
France.
(c) Broadcast Analysis in Multi-hop Wireless Networks. Nathalie Mitton, An-
thony Busson and E´ ric Fleury. Invited Paper at Spatial Stochastic Modeling
of Wireless Networks (SpasWIN’05), Avril 2005, Riva de Garda, Italie.
(d) An analysis of the MPR selection in OLSR. Anthony Busson, Nathalie Mit-
ton and E´ ric Fleury. Spatial Stochastic Modeling of Wireless Networks
(SpasWIN’05), Avril 2005, Riva de Garda, Italie.
3. Colloques et confe´rences nationaux :
(a) Une analyse de la se´lection des MPR dans OLSR. Anthony Busson, Natha-
lie Mitton et E´ ric Fleury. ALGOTEL’05, Mai 2005, Presqu’ıˆle de Giens,
France.
4. Rapports de recherche :
(a) Broadcast in Self-organizing Wireless Multi-hop Network. Nathalie Mitton,
Anthony Busson and E´ ric Fleury. RR-5487. Fe´vrier 2005.
(b) An analysis of the MPR selection in OLSR. Anthony Busson, Nathalie Mit-
ton and E´ ric Fleury. RR-5468. Janvier 2005.
5. Journaux en cours de soumission :
(a) Efficient Broadcasting and Self-Stabilization in Self-Organizing Multi-hop
Wireless Networks. Nathalie Mitton, E´ ric Fleury, Isabelle Gue´rin-Lassous
and Bruno Se´ricola and Se´bastien Tixeuil. ”Best Papers of Adhoc Now
2005” special issue of the Journal of Discrete Algorithms (JDA).
6. Se´minaires, pre´sentations, expose´s :
(a) Diffusion efficace dans les re´seaux sans fil multi-sauts. Nathalie Mitton,
E´ ric Fleury. Journe´es RESCOM - Villeneuve d’Ascq - France - 6-7 Mars
2005.
(b) An analysis of the MPR selection in OLSR. Anthony Busson, Nathalie Mit-
ton, Eric Fleury. Se´minaire ACI FRAGILE - Aussois - France - 23-24 Mars
2005.
4.9. ANNEXES 93
4.9 Annexes
Nous pre´sentons ici les preuves des propositions 1 et 2 donnant le nombre de re´ceptions
par nœud lors de la diffusion d’un message.
Preuve de la proposition 1 E´ tant donne´ un processus ponctuel stationnaire Φ d’in-
tensite´ λ (λ > 0), soit ΦRelay d’intensite´ λRelay un amincissement de Φ. Les points de
ΦRelay repre´sentent les relais. Nous supposons que ΦRelay est toujours un processus
ponctuel stationnaire. On cherche a` montrer que le nombre moyen de re´ceptions d’un
meˆme message par nœud r est : [ ]
o ′r = E Φ(B )
[ ] ΦRelay 0
′
ou` oEΦ ΦRelay(B0) est l’espe´rance sous Palm par rapport au processus Φ (et donc la
l y ) d b d l i d ′va eur mo enne u nom re e re a s ans B0.
Pour un point donne´, c.a`.d. le point 0 sous les probabilite´s de Palm, le nombre moyen
de re´ceptions correspond au nombre moyen de points de ΦRelay dans le voisinage de 0
(a` distance infe´rieure ou e´gale a` R).
A` partir de la formule de Mecke [76], on peut de´duire que le nombre total de re´ceptions
Z rec¸ues par l’ensembl[e∫des nœuds d’une surfa]ce S est :[ ]
′ o ′Z = E ΦRelay(Bx)Φ(dx) = λEΦ ΦRelay(B0)
S
Par stationnarite´ [d∫es deux processus pon]ctuels [Φ∫et ΦRelay , nous avon]s :
′ ′
E ΦRelay(Bx)Φ(dx) = E Φ(Bx)ΦRelay(dx)
S S
La partie gauche de l’e´quation est le nombre total de re´ceptions rec¸ues par les nœuds de
la surface S, sachant que les nœuds en bordure peuvent recevoir le message depuis des
nœuds en dehors de S. La partie droite de l’e´quation est le nombre de re´ceptions rec¸ues
par l’ensemble des nœuds du processus Φ mais ge´ne´re´es uniquement par les relais se
trouvant dans S. En appliquant la formule de Mecke de part et d’autre de l’e´quation,
on obtient :
[ ] [ ]
o ′ o ′λEΦ ΦRelay(B0) = λREΦ Φ(B )Relay 0
d’ou` :
[ ] [ ] λ [ ]
r = o
′ ′ Relay ′
EΦ Φ (B ) =
o o o
Relay 0 EΦ Φ(B ) P (0 ∈ Φ ) = E Φ(B )Relay 0 Φ Relay λ ΦRelay 0
94 CHAPITRE 4. DIFFUSION
Preuve de la proposition 2 E´ tant donne´ un graphe ale´atoireG(V,E) et un ensemble
de relais Relay ⊂ V ou` les degre´s des nœuds et des relais ainsi que le nombre de
re´ceptions par nœud sont e´qui-distribue´s. On cherche a` montrer que le nombre moyen
de re´ceptions par nœud r s’e´cr[it : ∣∣∣ ]r = E δ(v1) v1 ∈ Relay P(v1 ∈ Relay) (4.2)
Soient N une variable ale´atoire repre´sentant le nombre de sommets dans G (N = |V |)
et Z le nombre total de re´ceptions induites sur les nœuds du re´seau par la diffusion.
Pour tout u ∈ V , nous de´finissons δR(u) comme le nombre de relais dans le voisinage
de u.
Comme seuls les relais e´mettent le message, les liens e´tant bidirectionnels, le nombre
de re´ceptions du message perc¸ues par un nœud (qu’il soit lui-meˆme relais ou non)
correspond au nombre de relais dans son voisinage. Nous avons donc :
r = E[δR(u)], ∀u ∈ V
ou` E[δR(u)] est l’espe´rance de la variable δR(u) et correspond a` sa valeur moyenne.
Les liens e´tant bi-directionnels, Z peu∑t s’e´crire de deux fac¸ons :
Z = δR(u) (4.3)
u∈V
ou ∑ ∑
Z = δ(v) = δ(v)1lv∈Relay (4.4)
v∈Relay v∈G
ou` 1lv∈Relay = 1 if v ∈ Relay et 1lv∈Relay = 0 sinon.
A` partir de la pre[mie`r]e formulation[de∑+∞ ∑
Z (e´quation 4.3), on a
k
Z δ (u ) ∣∣∣
]
i=1 R i
E = E N = k P(N = k)
N k
k∑=1+∞∑k 1 [ ∣∣ ]
= E δR(ui)∣N = k P(N = k)
k
k∑=1 i=1+∞ k [ ∣∣ ]
= E δR(u1)∣N = k P(N = k)
k
k∑=1+∞ [ ∣∣∣ ]= E δR(u1) N = k P(N = k)
k=1
= E [δR(u)]
Couple´ a` la de´finition de r donne´ en e´quation[4.2,]on a :
Z
r = E
N
4.9. ANNEXES 95
[ ]
Cette dernie`re e´galite´ nous permet de calculer la valeur moyenne de ZN :
Z
E N en
utilisant cette fois la deuxie`me formulation de Z (e´quation 4.4). Nous conditionnons
cette quantite´ par les diff[e´ren]tes valeurs de N :
Z
r = E [N∑ ]
v∈V δ(v)1lv∈Relay= E
∑ [+∞ ∑
N
k
i=1 δ(vi)1lvi∈Relay ∣∣∣
]
= E N = k P(N = k)
k
k∑=1+∞∑k 1
= E [δ(vi)1lv ∈Relay]P(N = k)
k i
k∑=1 i=+∞ [1
= E δ(v1)1lv ∈Relay∣∣∣ ]N = k P(N = k)1
k=1
= E [[δ(v1)1l∣∣ v ]1∈Relay∣ ]= E δ(v1) v1 ∈ Relay P(v1 ∈ Relay)
ou` v1 est un nœud choisi arbitrairement parmi les sommets de G.
96 CHAPITRE 4. DIFFUSION
Chapitre 5
Localisation et routage
5.1 Introduction
Nous avons propose´ un algorithme de clustering pour organiser le re´seau (chapitre 3)
afin de pouvoir utiliser le re´seau sans fil multi-sauts sur de larges e´chelles. Nous avons
vu comment une telle structure de clusters peut eˆtre utilise´e pour effectuer une dif-
fusion efficace, aussi bien dans tout le re´seau que dans un cluster. Dans ce chapitre,
nous expliquons comment nous comptons utiliser notre organisation de clusters pour
le routage et permettre a` toute paire de nœuds de communiquer. Dans tout type de
re´seau, pour router un message vers un nœud destination v, un nœud u doit avoir une
information sur la position de v. Dans les re´seaux filaires, l’information de routage
est encapsule´e dans l’adresse du nœud, celle-ci e´tant de´pendante de la topologie du
re´seau. Par exemple, une adresse IP identifie un nœud et en meˆme temps permet de le
situer puisque le pre´fixe du re´seau est inclus dans l’adresse IP. Dans les re´seaux sans fil,
l’identifiant permanent du nœud ne peut inclure sa position du fait de sa mobilite´ et est
donc inde´pendant de la topologie sous-jacente. Les protocoles de routage utilise´s dans
les re´seaux filaires ne peuvent eˆtre applique´s. Une approche possible est d’utiliser un
routage indirect. Une ope´ration de routage est qualifie´e de indirecte si elle s’effectue
en deux e´tapes : (i) le look-up qui permet de situer le nœud cible, puis, (ii) le routage
qui permet a` la source de communiquer directement avec le nœud cible´. La figure 5.1
illustre un routage indirect. Le nœud u veut communiquer avec le nœud v mais il doit
d’abord le localiser. Pour cela, il effectue l’ope´ration de look-up : il demande a` une
troisie`me entite´ (ici, le nœud w) ou` se trouve v. Cette entite´ est un point de rendez-
vous : v enregistre re´gulie`rement sa position aupre`s de w qui garde une trace de la
position de v. Une fois que w a re´pondu a` u, u est en mesure de contacter directement
v Ce principe de routage est par exemple utilise´ dans les re´seaux de te´le´phonie GSM1.
ou dans le protocole Mobile IP2, ou` la position de la destination est pre´alablement de-
mande´e respectivement aux HLR (Home Location Register) ou aux Home Agent avant
1http ://www.gsm.org
2http ://www.ietf.org/rfc/rfc2002.txt
97
98 CHAPITRE 5. LOCALISATION ET ROUTAGE
d’e´tablir directement la communication entre le demandeur et la destination. Cepen-
dant, un tel principe ne peut eˆtre mis en œuvre dans un re´seau sans fil de type ad hoc
car tous les nœuds sont susceptibles de bouger, y compris les Home Agents potentiels.
w
2. V is at (X,Y)
1:  Where is v? v
3. Route towards v
u
FIG. 5.1 – Routage indirect : le nœud u veut communiquer avec le nœud v mais ne
connaıˆt pas sa position. Il demande donc dans un premier temps a` une troisie`me entite´
(ici, le nœud w) ou` se trouve v. w sait ou` se trouve v car v enregistre re´gulie`rement sa
position aupre`s de w qui peut re´pondre a` u. u est alors en mesure de contacter v.
Nous nous proposons d’appliquer un sche´ma de routage indirect pour router dans des
re´seaux sans fil multi-sauts a` large e´chelle. Nous de´sirons une solution qui permette le
passage a` l’e´chelle du re´seau et qui doit donc maintenir le moins d’information pos-
sible sur les nœuds. Nous voulons e´galement e´viter les situations ou` la distance entre
la source (le nœud u sur la figure 5.1) et le point de rendez-vous (le nœud w) est plus
importante que la distance entre la source (le nœud u) et la destination (le nœud v).
En effet, si la requeˆte de localisation doit traverser deux fois le re´seau avant qu’une
communication entre deux nœuds qui peuvent eˆtre proches s’e´tablisse, nous occupons
inutilement la bande passante et introduisons une forte latence, ce qui empeˆche le pro-
tocole d’eˆtre extensible.
Un moyen d’appliquer un routage indirect est d’utiliser une Table de Hachage Dis-
tribue´e (DHT - Distributed hash table). L’imple´mentation des DHT dans les re´seaux
sans fil a donne´ naissance a` de nouvelles proble´matiques [64]. De plus, un tel adres-
sage offre une approche prometteuse pour permettre le passage a` l’e´chelle [30]. Les
DHT fournissent une association ge´ne´rale entre une clef et toute sorte d’information
(comme l’identite´ d’un nœud ou une position). Elles utilisent un espace d’adressage
virtuel V . Des partitions de cette espace virtuel sont alloue´es aux nœuds du re´seau.
L’ide´e est d’utiliser une fonction depuis un espace re´el vers un espace virtuel V . Cette
fonction, dite de hash, permet aux nœuds d’identifier certains points de rendez-vous
aupre`s desquels ils enregistrent leur position. Cette fonction de hash est connue de tous
les nœuds du re´seau et peut ensuite eˆtre utilise´e par un nœud source pour retrouver ces
meˆmes points de rendez-vous et leur demander la position du nœud qu’ils recherchent.
Une information connue de tous (comme le nom de notre destinataire) est hashe´e en
une clef (hash(v) = clev) de l’espace d’adressage virtuel V . Les informations as-
socie´es a` cette clef (comme la position des nœuds) sont ensuite stocke´es sur le (ou les)
nœud(s) responsable(s) de la partition de l’espace virtuel auquel la clef appartient. Par
exemple, sur la figure 5.1, nous avons hash(v) = Position nœud v ∈ I ⊂ V et
le nœud w est responsable de l’intervalle I . En connaissant I , les nœuds v et u sont
5.1. INTRODUCTION 99
capables de trouver w soit pour s’enregistrer (pour le nœud v) soit pour lui demander
ou` se trouve v (pour le nœud u). On remarque que les nœuds u et v n’ont pas besoin de
connaıˆtre la vraie identite´ dew, mais juste son adresse virtuelle dans V . Cette ope´ration
retournant le(s) nœud(s) responsable(s) d’une certaine clef dans les syste`mes utilisant
des DHT, est appele´e look-up. Plus de de´tails au sujet des ope´rations de look-up sont
donne´s dans [10].
Dans la litte´rature, les DHT sont utilise´es a` deux niveaux : au niveau de la couche appli-
cation et au niveau de la couche re´seau. Les DHT sont utilise´es au niveau applicatif en
particulier dans les syste`mes pair-a`-pair. La clef ”hache´e” dans ces syste`mes de partage
de fichiers est l’identifiant d’un fichier (cle = hash(fichier)). L’information associe´e
a` la clef et maintenue par le nœud responsable de cette clef est l’identite´ des nœuds
du re´seau qui de´tiennent ce fichier. Les adresses virtuelles des nœuds (ou partitions de
V dont ils sont responsables) forment un re´seau overlay (c.a`.d un re´seau virtuel base´
sur le re´seau physique qui maintient des liens logiques entre les nœuds) sur lequel les
requeˆtes sont route´es. Ce qui diffe´rencie majoritairement les diffe´rentes propositions
de re´seaux pair-a`-pair dans la litte´rature est la ge´ome´trie de ce re´seau overlay. En effet,
la forme de ce re´seau va de l’anneau (Chord [73]) au graphe de De Bruijn (D2B [33])
en passant par des arbres (Tapestry [84], Kademlia [54]), des espaces d-dimensionnels
(CAN [68]), des structures en forme de papillon [52] ou encore des structures hybrides
arbres-anneaux (Pastry [70]).
Lorsqu’elles sont utilise´es au niveau de la couche re´seau, les DHT distribuent les in-
formations de position des nœuds a` travers le re´seau et sont utilise´es pour identifier
un nœud pouvant fournir des informations permettant de joindre le nœud destination.
C’est de cette fac¸on que nous nous proposons d’utiliser les DHT. Quand un nœud u
doit envoyer une information a` v, il doit d’abord le localiser et pour cela, demander a`
un nœud w, responsable de la clef k = hash(v). Parmi les DHT applique´es au niveau
re´seau, le routage utilise´ dans les diffe´rentes propositions est de deux sortes : un rou-
tage inde´pendant de la DHT (le routage n’utilise pas l’espace virtuel V) et un routage
de´pendant de la DHT (le routage utilise l’espace virtuel V).
Lorsque le routage est inde´pendant de la DHT, les nœuds disposent ge´ne´ralement de
leur coordonne´es ge´ographiques absolues (obtenues par exemple avec un GPS) ou re-
latives (comme dans [17]). C’est cette information qu’ils associent a` la clef. En ef-
fectuant hash(destination), un nœud u obtient des coordonne´es ge´ographiques d’une
”zone rendez-vous” A. u peut alors appliquer un routage ge´ographique classique afin
d’envoyer sa requeˆte vers un nœud v se trouvant dans la zone A et qui de´tient les
coordonne´es ge´ographiques de la destination cherche´e par u. De la`, u effectue de nou-
veau un routage ge´ographique mais cette fois, directement vers la destination. Ce type
de routage inde´pendant de la DHT est utilise´ par exemple dans [6, 57, 58], dans les
projets ”Terminodes” [15, 16] et ”Grid” [48]. Dans notre cas, les nœuds ne disposent
d’aucune information concernant leur position ge´ographique et nous aimerions e´viter
l’utilisation d’un GPS. De ce fait, nous ne pouvons utiliser ce type de routage indirect.
Dans le cas ou` le routage est de´pendant de la DHT, l’espace virtuelV qui lui est associe´,
est utilise´ non seulement pour identifier les points de rendez-vous mais e´galement pour
router vers ces points et vers la destination finale. Dans ce cas, l’adresse virtuelle d’un
100 CHAPITRE 5. LOCALISATION ET ROUTAGE
nœud de´pend de sa position. La cohe´rence du protocole de routage repose alors sur
la cohe´rence de la distribution des partitions de l’espace virtuel V sur les nœuds du
re´seau. Le routage est effectue´ sur la structure logique et ne tient plus compte du
re´seau physique sous-jacent. Dans de tels scenarii, un nœud u cherchant le nœud w
re´cupe`re l’adresse virtuelle du point de rendez-vous v avec la fonction de hachage
hash(w) = Idvirtuel(v). Les requeˆtes de look-up sont route´es dans V jusqu’a` v qui
retourne l’adresse virtuelle de w. De la`, u joint w en utilisant son adresse virtuelle et en
routant dans V . Ge´ne´ralement, le routage dans l’espace virtuel est un routage glouton :
”Transmet a` ton voisin dans V dont l’adresse virtuelle est la plus proche de l’adresse
virtuelle de la destination”. C’est ce qu’on trouve par exemple dans Tribe [78, 79] ou
L+ [22] sur lequel se base SAFARI [69]. La principale difficulte´ ici est de re´partir les
partitions de l’espace virtuel V de fac¸on a` ce que les routes obtenues en routant dans V
ne soient pas beaucoup plus longues que les routes physiques.
5.2 Localisation et routage sur une structure de clus-
ters
Dans notre proposition, chaque nœud de´tient une information concernant sa position
relative : l’identite´ de son cluster. C’est cette information que les nœuds vont associer
a` la clef de hachage. Comme nous avons une structure d’arbres, nous proposons de
partitionner l’espace virtuel V dans chaque arbre. V e´tant ainsi duplique´ autant de fois
que l’on a de clusters, on retrouve un nœud responsable d’une clef donne´e dans chaque
arbre/cluster. Chaque nœud enregistre alors sa position dans chaque espace virtuel et
donc dans chaque arbre. De cette fac¸on, lorsqu’un nœud v recherche un nœud u dans le
re´seau, il a juste a` chercher dans son propre cluster. Comme l’excentricite´ d’un nœud
dans un cluster est faible (voir chapitre 3.6.2), la distance a` parcourir pour atteindre
le nœud de rendez-vous est e´galement faible. Partitionner ainsi plusieurs fois l’espace
virtuel plutoˆt qu’une seule fois sur tout le re´seau e´vite les situations ou` la distance
entre la source et le point de rendez-vous est supe´rieure a` la distance entre la source et
la destination, puisque la source et le point de rendez-vous appartiennent toujours au
meˆme cluster alors que la destination peut eˆtre n’importe ou` dans le re´seau.
Pour distribuer les partitions de l’espace virtuel V de la DHT de telle fac¸on que, e´tant
donne´e une adresse virtuelle, un nœud u soit en mesure de joindre le nœud en question
sans information supple´mentaire, nous utilisons un sche´ma d’e´tiquetage d’arbre (tree
Interval Labeling Scheme) pour ensuite permettre un routage par intervalle sur notre
structure logique.
Dans les diverses propositions de DHT que nous avons pre´sente´es, les deux phases du
routage indirect (look-up et routage) sont toujours du meˆme type : inde´pendantes de
la DHT et effectue´es dans l’espace physique ou de´pendantes de la DHT et effectue´es
sur l’espace logique. Dans notre approche, les deux e´tapes de routage indirect sont ef-
fectue´es diffe´remment. Le look-up est effectue´ en utilisant un routage par intervalle sur
les adresses virtuelles des points de rendez-vous alors que l’e´tape de routage s’effectue
dans l’espace physique, inde´pendamment de V .
5.2. LOCALISATION ET ROUTAGE 101
Le routage par intervalle s’est ave´re´ tre`s attractif de par sa simplicite´. Il a e´te´ introduit
dans les re´seaux filaires par Santoro et Khatib dans [72] dans le but de re´duire la taille
des tables de routage. L’ide´e est de repre´senter la table de routage de chaque nœud
de manie`re compacte, en agre´geant l’ensemble des adresses destination qui peuvent
eˆtre atteintes en utilisant le meˆme port de sortie, au moyen d’intervalles d’adresses
conse´cutives. Par exemple, si l’on conside`re le graphe repre´sente´ sur la figure 5.2(a), le
nœud 0 doit utiliser le port a pour atteindre les nœuds 4, 5 et 6, le port b pour atteindre
1 et 2 et le port c pour atteindre 3. Plutoˆt que de cre´er une entre´e dans sa table de
routage par nœud destination, il cre´e une entre´e par port de sortie et plutoˆt que de lister
tous les nœuds accessibles via ce port, il stocke seulement l’intervalle contenant les
adresses de ces nœuds : [1, 2] pour le port a, [4, 6] pour le port b et [3] pour le port
c. Le principal avantage de ce type de routage est qu’il ne´cessite peu de me´moire sur
les nœuds puisque la taille de la table de routage d’un nœud u est en O(δ(u)). Le
routage est exe´cute´ de fac¸on distribue´e : a` chaque nœud interme´diaire x, si x n’est pas
le nœud destination y, le message est transfe´re´ sur le port de sortie dont l’e´tiquette est
un ensemble d’intervalles I tel que y ∈ I .
Un Interval Labeling Scheme (ILS) est la fac¸on d’allouer les e´tiquettes des nœuds
(adresses virtuelles) pour pouvoir de´finir les intervalles a` assigner aux areˆtes de chaque
nœud, de fac¸on a` pouvoir effectuer un routage par intervalle efficace avec des routes
aussi courtes que possible. Les auteurs de [77] ont montre´ qu’un arbre non-oriente´
supportait un routage par intervalle avec de plus courts chemins (dans l’arbre) et en
n’utilisant qu’un intervalle par areˆte sortante a` condition de distribuer les e´tiquettes
(ILS) en effectuant un parcours en profondeur de l’arbre.
Dans les re´seaux filaires, dans un arbre, les nœuds doivent stoker un intervalle pour cha-
cune des areˆtes sortantes. La taille de la table de routage d’un nœud u est en O(δ(u)).
Dans un environnement sans fil, l’e´mission d’un message atteint tous les nœuds se trou-
vant a` porte´e radio de l’e´metteur. Les areˆtes du graphes sont en re´alite´ des hyper-areˆtes
(voir figure 5.2). La proble´matique est donc un peu diffe´rente puisque une requeˆte
e´mise sera entendue par tous les voisins de la source, qu’elle leur soit destine´e ou pas.
Comme les nœuds n’ont qu’une hyper-areˆte sortante, ils peuvent ne stocker qu’un seul
intervalle. Nous proposons ici de tirer avantage de la nature diffusante du me´dium ra-
dio. Les nœuds stockent l’intervalle global pour lequel leur sous-arbre est responsable
et non plus un intervalle pour chaque voisin. Par exemple, si on conside`re la figure 5.2,
le nœud 0 ne ge`re plus 3 intervalles mais un seul : [0, 6]. Cela donne une taille de table
de routage en O(1) par nœud. Quand une requeˆte est envoye´e, tous les nœuds a` porte´e
radio la rec¸oivent mais seuls ceux concerne´s y re´pondent.
5.2.1 Re´sume´ et analyse de complexite´
Pour re´sumer, nous proposons d’appliquer un routage indirect sur la structure en arbres
de notre re´seau auto-organise´, en utilisant une DHT qui associe chaque nœud a` sa
position dans le re´seau : son cluster. L’ensemble des adresses virtuelles V de la DHT
est partitionne´ et re´parti sur les nœuds de chaque cluster. Comme le nombre de clusters
102 CHAPITRE 5. LOCALISATION ET ROUTAGE
6
[1,5] a
[6]
6
b a[6] [5] 5 [5]
[6,4] 54 c [4,6] 4
a [0,3]
[1 2] [0,6]
[1,2] a [4,6]
0
1
b [3,0] [3]
1 0b [3] [2] 3a c 2
[2]
[3,1] [4,2]
a a2 3
(a) Routage en environnement filaire. Les nœuds (b) Routage en environnement sans fil. Les
stockent un intervalle par areˆte sortante. nœuds stockent un seul intervalle (un par
hyper-areˆte).
FIG. 5.2 – Areˆtes dans un re´seau filaire (a) Vs hyper-areˆtes dans un re´seau sans fil (b).
est borne´ par une constante et que les clusters sont homoge`nes (chapitre 3), chaque
nœud maintient finalement O(1) informations de position.
Quand un nœud u doit joindre un nœud v, il obtient l’adresse virtuelle d’un point de
rendez-vous en utilisant la fonction de hash : hash(v) = keyv ∈ V . Puis, a` partir
de cette adresse, en appliquant un routage par intervalle sur l’espace virtuel V de son
propre arbre, il re´cupe`re la position C(v) de v. Comme les intervalles des voisins de u
ne sont pas maintenus par u, u stocke uniquement l’intervalle dont son arbre est res-
ponsable. La taille de la table de routage de u est en O(1). Une fois que u connaıˆt C(v),
il peut atteindre C(v) en employant un routage pro-actif entre clusters puis un routage
re´actif pour joindre v une fois que le cluster destination est atteint. Comme le nombre
de clusters est borne´ par une constante, chaque cluster a O(1) routes a` maintenir vers
les autres clusters.
5.3 Notre proposition
5.3.1 Pre´liminaires
Chaque nœud u posse`de deux adresses :
– Une adresse universelle Id(u) ∈ IR (souvent note´e u par la suite). Cette adresse est
unique dans le re´seau et ne change jamais. Elle est le ”vrai” nom de u.
– Une adresse logique i(u) ∈ V . Cette adresse est unique dans un cluster. Elle peut
changer a` chaque re-distribution des partitions de V parmi les nœuds d’un cluster.
Elle identifie le nœud u dans son espace logique.
5.3. NOTRE PROPOSITION 103
Soit I(u) la partition de V assigne´e au nœud u. I(u) est telle que I(u) = [i(u), ...[
ou` i(u) est l’adr
T ⋃esse logique de u dans V . i(u) de´pend donc de I(u). On noteItree(s (u)) = v∈sT (u) I(v) l’intervalle/partition de V pour lequel le sous-arbre
de racine u est responsable. |I| de´signe la taille de l’intervalle I .
5.3.2 Distribution des partitions de l’espace virtuel - ILS
Comme mentionne´ dans la section 5.2, une distribution optimale des intervalles sur un
arbre est obtenue via une nume´rotation des nœuds obtenue par un parcours en profon-
deur ILS (Depth First Search DFS-ILS).
Comme dans tout ILS traditionnel, les partitions de V sont attribue´es a` chaque nœud
u ∈ V de sorte que :
– Les intervalles des nœuds de sT (u) forment un intervalle continu.
– La taille de l’intervalle dont un sous-arbre est responsable est proportionnelle a` la
taille de ce sous-arbre : |Itree(sT (u))| ∝ |sT (u)|. Et donc, pour tout nœud v ∈
sT (u), |Itree(sT (u))| ≥ |Itree(sT (v))|.
V V ⋃– est entie`rement distribue´ parmi les nœuds du cluster : = v∈C(u) I(v).
– Les diffe´rents intervalles s’excluent mutuellement : ∀v ∈ C(u),∀w ∈ C(u),v 6=
w I(v) ∩ I(w) = ∅.
Nous proposons une re´partition des intervalles distribue´e, qui s’effectue en paralle`le sur
chaque branche de chaque arbre. Chaque nœud u ne´cessite des informations pouvant
se trouver jusqu’a` dtree(u,H(u)) sauts de lui ou` dtree(u,H(u)) est le nombre de sauts
dans l’arbre entre u et son cluster-headH(u). La distance dtree(u,H(u)) est borne´e par
la hauteur des arbres qui est elle-meˆme borne´e par une constante (voir chapitre 3.6.2).
Cette distribution peut donc eˆtre qualifie´e de quasi-locale selon la taxonomie e´tablie
en [81], ce qui implique une maintenance rapide du processus.
Notre algorithme s’exe´cute en deux temps : une premie`re phase pendant laquelle les
nœuds remontent des informations depuis les feuilles de l’arbre jusqu’a` sa racine et une
seconde phase ou` les nœuds internes distribuent re´cursivement les intervalles parmi
leurs fils. La distribution des intervalles s’effectue en paralle`le sur chaque branche de
chaque arbre, chaque phase ayant une complexite´ temporelle en O(Tree depth). La
complexite´ temporelle totale de l’algorithme de distribution des intervalles pour un
cluster est donc de 2 × (Tree depth). Comme la hauteur des arbres Tree depth est
borne´e par une constante, la complexite´ temporelle devient O(1).
La figure 5.3 illustre cette distribution d’intervalles pour V = [1, 17[.
E´ tape 1. Comme nous l’avons de´ja` vu dans le chapitre 3.6.2, chaque nœud u est en
mesure de savoir en un temps borne´ qui l’a choisi comme pe`re parmi ses voisins et
donc connaıˆt son nombre de fils. Si un nœud est feuille, la taille de son sous-arbre
est 1. De`s qu’un nœud interne a rec¸u la taille des sous-arbres de chacun de ses fils, il
calcule la taille de son propre sous-arbre qui est la somme de la taille
| T | | { }⋃ T | ∑des sous-arbres dechacun de ses fils plus 1 : s (u) = u v∈Ch(u) s (v) = 1+ v∈Ch(u) |sT (v)|.
Chaque nœud envoie la taille de son sous-arbre a` son pe`re et ainsi de suite jusqu’a`
atteindre le cluster-head. C’est ce qu’illustre la figure 5.3(a).
104 CHAPITRE 5. LOCALISATION ET ROUTAGE
E´ tape 2. Une fois que le cluster-head connaıˆt la taille des sous-arbres de chacun de ses
fils, il partage V e´quitablement entre lui-meˆme et ses fils. Chaque fils u se voit attribuer
une partition de V , Itree(sT (v)), de taille proportionnelle a` la taille de son sous-arbre.
Chaque nœud interne re-distribue alors l’intervalle qu’on lui a alloue´ entre lui et ses
fils, et ainsi de suite, jusqu’a` atteindre les extre´mite´s des branches de l’arbre. Cette
e´tape est illustre´e sur la figure 5.3(b).
Ainsi, une fois les deux e´tapes de l’algorithme accomplies, chaque nœud est respon-
sable d’une partition de V qui est de taille e´gale pour tous les nœuds d’un meˆme cluster.
La figure 5.3(c) illustre le re´sultat d’une distribution des intervalles. Le nœud u se voit
attribuer l’intervalle I(u) et est de´sormais responsable des clefs contenues dans cet
intervalle et il doit stocker les positions des nœuds v tels que hash(v) ∈ I(u). On
remarque qu’il peut exister plusieurs nœuds vi tels que hash(vi) = hash(vj).
Chaque nœud interne u garde e´galement en me´moire l’intervalle alloue´ a` son sous-
arbre Itree(sT (u)), sans pour autant stocker les informations associe´es a` toutes les
clefs de Itree(sT (u)). Cela lui servira lors du routage des requeˆtes, comme nous le
verrons dans la section 5.3.6
Comme nous l’avons mentionne´ dans le chapitre 3.6.2, un nœud interne a en moyenne
peu de fils a` qui distribuer une partie de V . Cette ope´ration ne ge´ne`re donc que peu de
calcul sur chaque nœud.
5.3.3 Enregistrement
Afin d’eˆtre localise´ par la suite, chaque nœud u doit enregistrer sa position (l’identite´
de son cluster) aupre`s de chaque nœud responsable de la clef hash(u) dans son cluster,
mais e´galement dans les autres clusters du re´seau. Pour s’enregistrer dans son propre
cluster, u a juste besoin d’envoyer une requeˆte d’enregistrement ou Registration Re-
quest, comme nous le de´taillerons plus tard dans la section 5.3.6. Pour s’inscrire dans
les autres clusters, u doit tout d’abord joindre un nœud vi dans chaque cluster Ci. Puis,
chaque vi envoie une Registration Request dans son propre cluster Ci au nom de u. Les
nœuds vi peuvent eˆtre trouve´s via un routage pro-actif vers le cluster Ci, comme de´crit
plus tard dans la section 5.3.7.
Les nœuds s’enregistrent toutes les ∆(t) unite´s de temps. Une approche commune´ment
adopte´e dans la litte´rature [1, 35, 56] est que les informations de localisation sont mises
a` jour sur les points de rendez-vous en fonction de la distance de ces points de rendez-
vous a` la source. Plus la distance est courte, plus les mises a` jour sont fre´quentes.
5.3.4 De´parts et arrive´es
Quand un nœud arrive dans un cluster, il n’est responsable d’aucun intervalle pour un
certain temps.
Quand un nœud disparaıˆt, les informations dont il e´tait en charge sont perdues (mais
toujours disponibles dans les autres clusters). Chaque nœud interne u est constamment
5.3. NOTRE PROPOSITION 105
1 [1, 17[   
    2
   
   
4 [3, 5[        [13, 17[
   
   
      
    [6, 13[
      
   
   
          
   
      
   
   
   
      
       1     2                              
   
   
1        [7, 9[     [9, 13[ [15, 17[
          
   
   
      
      
          
   
      
   
      
   
   
      
      
   
      
   
      
   
   
1              [11, 13[
      
      
      
      
      
      
      
(a) E´ tape 1 : chaque nœud envoie la (b) E´ tape 2 : chaque nœud interne par-
taille de son sous-arbre a` son pe`re. Les tage l’intervalle donne´ par son pe`re entre
feuilles (nœuds jaunes hachure´s verti- lui-meˆme et ses fils, proportionnellement
calement) envoient 1. Les nœuds in- a` la taille des sous-arbres de chacun. Les
ternes (nœuds oranges hachure´s horizon- intervalles note´s sur les fle`ches corres-
talement) rassemblent les informations de pondent a` ce qui est alloue´ par un nœud
tous leurs fils et calculent la taille de leur a` ses fils, c.a`.d l’intervalle dont le sous-
propre sous-arbre avant de l’envoyer a` arbre de chacun est en charge.
leur propre pe`re, et ainsi de suite, jusqu’a`
atteindre la racine (le cluster-head), nœud
rouge hachure´ en diagonal.
[1, 3[
   
   
   
   
   
   
      
   
   
   
   
       [13, 15[
   
   
[3, 5[     [5, 7[              
   
      
   
          
      
   
          
      
[7, 9[    [9, 11[       [15, 17[
      
      
      
[11, 13[
(c) Re´sultat : chaque nœud se voit attri-
buer un intervalle de V dont il est respon-
sable.
FIG. 5.3 – Distribution des partitions de l’espace virtuel.
106 CHAPITRE 5. LOCALISATION ET ROUTAGE
au courant des arrive´es et de´parts de ses fils graˆce aux paquets HELLO. S’il constate
des changements trop importants parmi eux, il peut de´cider localement de redistri-
buer l’intervalle Itree(sT (u)) dont son sous arbre est en charge entre lui-meˆme et ses
fils. Plus un nœud interne est proche du chef de cluster, plus les re´-attributions qui
de´couleront de sa de´cision seront importantes, puisqu’elles se re´percutent de pe`re en
fils jusqu’a` atteindre les feuilles. De plus, une nouvelle attribution des intervalles im-
plique un changement d’adresse logique pour les nœuds. Cependant, comme constate´
pre´ce´demment, plus un nœud est proche du chef de cluster, plus son voisinage est
stable.
Lorsque les intervalles sont re-distribue´s, chaque nœud u qui e´tait pre´alablement res-
ponsable de l’intervalle Iold et qui se voit de´sormais attribuer la partition Inew ne
conserve que les informations relatives aux clefs de Iold ∩ Inew . De fac¸on a` ne pas
perdre pour autant les informations associe´es aux clefs de Iold \ Inew , u envoie des
Registration Request au nom de tous les nœuds v dont il n’est plus en charge c.a`.d les
nœuds v tels que hash(v) ∈ Iold \ Inew.
5.3.5 Ajouter de la redondance et de la robustesse
Comme mentionne´ dans la section 5.3.4, quand un nœud u disparaıˆt d’un cluster C(u)
ou quitte le re´seau, les informations dont il e´tait responsable sont perdues dans ce clus-
ter jusqu’au prochain enregistrement des nœuds. De fac¸on a` pallier cet inconve´nient,
un nœud peut enregistrer sa position d fois dans chaque cluster, d e´tant une constante.
Pour cela, l’espace virtuel V doit eˆtre distribue´ d fois dans chaque cluster, chaque nœud
se voyant de´sormais attribuer d partitions inde´pendantes de V et posse´dant alors d
diffe´rentes adresses logiques. Comme d est une constante, la taille me´moire requise
sur les nœuds reste en O(1) puisque, en moyenne, si c est le nombre de clusters, un
nœud devra stocker d ∗ c positions au lieu de c (c et d e´tant deux constantes). Ainsi,
meˆme lorsqu’un nœud meurt, la position d’un nœud dont il e´tait responsable a tou-
jours des chances d’eˆtre trouve´e dans le meˆme cluster. Cependant, cela ge´ne`re plus de
messages puisque les requeˆtes devront de´sormais suivre d routes, une pour chaque oc-
currence de V . Dans le pire cas, le routage des requeˆtes dans l’espace virtuel conduira
a` une diffusion dans un cluster. Mais, comme nous l’avons e´tudie´ dans le chapitre 4,
une telle diffusion peut s’effectuer en suivant les branches des arbres de fac¸on efficace
et peu couˆteuse.
5.3.6 Ope´ration de look-up : Routage dans l’espace virtuel V de la
DHT
Nous de´taillons ici comment les requeˆtes sont route´es dans les arbres sur la base
d’un routage par intervalle. Ceci correspond a` la premie`re e´tape du routage indirect,
l’ope´ration de look-up.
Chaque nœud u a un identifiant unique Id(u). Comme dans tout sche´ma base´ sur une
DHT, chaque nœud connaıˆt une fonction spe´cifique hash qui associe a` chaque adresse
universelle une adresse logique de l’espace virtuel V .
5.3. NOTRE PROPOSITION 107
hash : IR→ V
Id(u)→ hash(u)
Plusieurs nœuds peuvent avoir la meˆme valeur retourne´e par la fonction hash.
Les informations de ces nœuds seront stocke´es sur le meˆme nœud de rendez-vous.
Dans la suite, nous utilisons la clef suivante pour identifier un nœud x : key =
{hash(x), id(x)}.
Une requeˆte est route´e dans l’espace virtuel jusqu’a` atteindre un nœud v responsable
de la clef key contenue dans la requeˆte : v est tel que key ∈ I(v). Une requeˆte peut
eˆtre de trois types :
– u veut enregistrer une position :
u doit enregistrer sa propre position ou, s’il est un nœud frontie`re, il peut vouloir
enregistrer un nœud u′ d’un autre cluster qui lui en a fait la demande. u doit donc
trouver le nœud responsable de sa propre adresse logique hash(u) ou de celle de u′,
hash(u′) : key = {hash(u), u} (resp key′ = {hash(u′), u′. })
Dans ce cas, u utilise une Registration Request (RR) 〈RR, key, C(u), f lag〉 (resp.
〈RR, key′, C(u′), f lag〉).
– u doit localiser x :
Dans ce cas, u cherche le nœud responsable de l’adresse logique de x : hash(x).
Il utilise une Location Request (LR) 〈LR, key = {hash(x), x} , i(u), f lag〉.
L’adresse logique de u, i(u), est ensuite utilise´e pour envoyer la requeˆte de re´ponse
a` u.
– u doit re´pondre a` une requeˆte LR concernant une clef dont il est responsable
(key ∈ I(u)) :
u a rec¸u une requeˆte de type Location Request :
〈LR, key = {hash(x), x} , i(w), f lag〉 envoye´e par le nœud w et contenant
une clef telle que key ∈ I(u). u doit re´pondre a` w.
Dans ce cas, il utilise une requeˆte de type Location Reply (Reply)
〈Reply, key = {i(w),−1} , C(x), f lag〉. On remarque qu’ici la clef key n’a
pas besoin de contenir l’adresse re´elle de w.
Pour chaque type de requeˆte, le champ flag est mis a` 1 par le nœud faisant suivre la
requeˆte si la clef key appartient a` l’intervalle de son sous-arbre, a` 0 sinon. Comme nous
le verrons par la suite, ce champ est utilise´ pour prendre des de´cisions de routage.
On remarque qu’un nœud u connaıˆt de´ja` la position (ou cluster) de ses voisins, de son
chef de cluster et des nœuds dont il est responsable. Ainsi, pour un nœud v tel que
{v ∈ H(u) ∪ Γ1(u)} ou hash(v) ∈ I(u), u n’a pas besoin d’effectuer la proce´dure de
look-up et peut directement envoyer le message a` v, en suivant la proce´dure de routage
dans le re´seau physique, comme de´crite dans le chapitre 5.3.7.
Du fait de la nature diffusante du me´dium radio, un nœud rec¸oit toutes les requeˆtes
e´mises par ses voisins, meˆme celles ne le concernant pas. Les requeˆtes de look-up
suivent uniquement les areˆtes de l’arbre de clustering, donc un nœud ne sera pas
108 CHAPITRE 5. LOCALISATION ET ROUTAGE
concerne´ par une requeˆte de look-up provenant d’un de ses voisins qui ne sera ni son
pe`re ni l’un de ses fils. Les nœuds prennent la de´cision de re´-e´mettre une requeˆte de
look-up en se basant non-seulement sur la cle´ et le champ flag contenus dans la requeˆte
mais e´galement sur l’identite´ de leur voisin qui leur l’a transmise. Le champ flag est
renseigne´ a` chaque re´-e´mission de la requeˆte par un nœud. Le processus de routage
d’une requeˆte est le meˆme quel que soit son type (LR, RR or Reply). Il est de´crit par
l’algorithme 1.
Vu que le routage des requeˆtes de look-up est ope´re´ sur l’espace virtuel V , il ne
ne´cessite pas la connaissance des adresses universelles des nœuds, il n’a besoin que
des adresses logiques.
Sur re´ception d’un message M (RR, LR or Reply) contenant la clef key =
{hash(x), x} provenant du nœud u (u ∈ Γ1(v)), le nœud v arreˆte le processus s’il
est responsable de la clef key (donc si key ∈ I(v)) ou s’il est lui-meˆme le nœud
cherche´ (si key = {hash(v), v}). Ce second cas arrive ne´anmoins rarement vu qu’il
implique que l’initiateur de la requeˆte x soit dans le meˆme cluster que v (C(x) = C(v))
et que v se trouve sur la route suivie par la requeˆte de x vers le nœud responsable de la
clef.
Lorsqu’une requeˆte de type RR 〈RR, key = {hash(u), u} , C(u), f lag〉 atteint sa des-
tination v, v met a` jour la position du nœud u dans sa table. Lorsqu’une requeˆte
de type Reply 〈Reply, key = {i(u),−1} , C(x), f lag〉 arrive a` sa destination u, u
est alors capable d’entamer la seconde e´tape du routage indirect. Enfin, lorsqu’une
requeˆte de type LR 〈LR, key = {hash(x), x} , i(w), f lag〉 atteint sa destination v
(en charge de hash(x)), v re´pond a` l’initiateur de la requeˆte par une requeˆte Reply :
〈Reply, {i(w),−1} , C(x), f lag〉.
Si key 6= {hash(v), v}, le nœud v re´-e´met M dans les trois cas suivants :
– Si u = P(v) et key ∈ Itree(sT (v)) (M a e´te´ transmis a` v par son pe`re et le sous-
arbre de v contient la cle´ de la requeˆte). Voir figure 5.4(a).
– Si u ∈ Ch(v) (M a e´te´ transmis a` v par un de ses fils u), v re´-e´met M si :
– Si key ∈/ Itree(sT (v)) (le sous-arbre de v n’est pas responsable de la clef du
message), le message doit poursuivre son chemin en remontant dans l’arbre vers
la racine. Voir figure 5.4(b).
– Si key ∈ Itree(sT (v)) et key ∈/ Itree(sT (u)) (flag = 0) (le sous-arbre de v
contient la clef mais pas celui de u), v doit re´-e´mettre M afin que le message
redescende sur une autre branche du sous-arbre de v. Voir figure 5.4(c).
La requeˆte est ignore´e dans tous les autres cas, c’est a` dire :
– Si u ∈/ P(v) ∪ Ch(v) (la requeˆte arrive par un lien n’e´tant pas dans l’arbre). Voir
figure 5.5(a).
– Si u ∈ Ch(v) et key ∈ Itree(sT (u)) (flag = 1) (le message parvient a` v par un de
ses fils dont le sous-arbre est responsable de la clef). Graˆce au champ flag mis a` 1,
u sait que le sous-arbre de l’e´metteur est en charge de la clef et donc ne s’en occupe
pas. La requeˆte redescend le sous-arbre de v. Voir figure 5.5(b).
– Si u = P(v) et key ∈/ Itree(sT (v)) (u rec¸oit M depuis son pe`re et son sous-arbre
n’est pas en charge de la clef). u n’est pas concerne´ par la requeˆte, il l’ignore. Un de
ses fre`res s’en chargera. Voir figure 5.5(c).
5.3. NOTRE PROPOSITION 109
a  I(a) = [0, 8[ a  I(a) = [0, 8[
q = <6, a, 1>
q = <1,  e,  0 >
b  I(b) = [1, 3[ d  I(d) = [3, 8[ b  I(b) = [1, 3[ d  I(d) = [3, 8[
c  I(c) = [2, 3[ e  I(e) = [5, 8[ f  I(f) = [4, 5[ c  I(c) = [2, 3[ e  I(e) = [5, 8[ f  I(f) = [4, 5[
g  I(g) = [6, 7[ g  I(g) = [6, 7[
h  I(h) = [7, 8[ h  I(h) = [7, 8[
(a) Cas 1 : le message descend dans l’arbre. a (b) Cas 2 : le message remonte. e cherche le
cherche le nœud responsable de la clef 6. nœud en charge de la clef 1.
a  I(a) = [0, 8[
b  I(b) = [1, 3[ d  I(d) = [3, 8[ q = <4, e,  0>
c  I(c) = [2, 3[ e  I(e) = [5, 8[ f  I(f) = [4, 5[
g  I(g) = [6, 7[
h  I(h) = [7, 8[
(c) Cas 3 : le message remonte dans une
branche pour re-descendre dans une autre. e
cherche le nœud en charge de la clef 4.
FIG. 5.4 – Diffe´rents cas de figures ou` une requeˆte rec¸ue par d est re´-e´mise.
110 CHAPITRE 5. LOCALISATION ET ROUTAGE
a  I(a) = [0, 8[ a  I(a) = [0, 8[
q = <key, b, flag>
q = <7,  e,  1 >
b  I(b) = [1, 3[ d  I(d) = [3, 8[ b  I(b) = [1, 3[ d  I(d) = [3, 8[
c  I(c) = [2, 3[ e  I(e) = [5, 8[ f  I(f) = [4, 5[ c  I(c) = [2, 3[ e  I(e) = [5, 8[ f  I(f) = [4, 5[
g  I(g) = [6, 7[ g  I(g) = [6, 7[
h  I(h) = [7, 8[ h  I(h) = [7, 8[
(a) Cas 1 : le message ne provient pas d’une (b) Cas 2 : e cherche le nœud en charge de
branche de l’arbre. la clef 4. Le message monte et redescend les
branches du sous-arbre de e en e´tant entendu
par d qui ignore la requeˆte.
a  I(a) = [0, 8[
q = <2, a, 1>
b  I(b) = [1, 3[ d  I(d) = [3, 8[
c  I(c) = [2, 3[ e  I(e) = [5, 8[ f  I(f) = [4, 5[
g  I(g) = [6, 7[
h  I(h) = [7, 8[
(c) Cas 3 : a cherche le nœud en charge de
7. Cette cle´ n’est pas dans l’arbre de nœud d.
FIG. 5.5 – Diffe´rents cas de figures ou` un message est entendu par le nœud d et ignore´. Les
fle`ches pointille´es repre´sentent un chemin possible suivi par la requeˆte dans ces cas. Les areˆtes
pointille´es repre´sentent les liens du graphe G non contenus dans l’arbre T .
5.3. NOTRE PROPOSITION 111
Algorithm 1 Routage dans l’espace virtuel
Pour tout nœud u, sur re´ception d’une requeˆte 〈Type, key = {hash(x), x} , X, flag〉,
X de´pendant du type de requeˆte, provenant d’un nœud v ∈ Γ1(u) et initie´e par le
nœud y :
if (key ∈ u ∪ I(u)) then
⊲ u est responsable de la clef. La requeˆte a atteint sa destination.
if (Type = LR) then
Re´pond en envoyant 〈Reply, {X = i(y),−1} , C(x), flag〉. Exit
end
if (Type = RR) then Enregistre la position de x. Exit end
if (Type = Reply) then
Route vers le cluster destination X. Exit
end
end
if (v = P(u)) then
⊲ Le message descend les branches de l’arbre.
if (key ∈ Itree(sT (u))) then
⊲ ∃w ∈ sT (u) tel que key ∈ I(w). cf. figure 5.4(a).
Met le champ flag a` 1.
Re´-e´met.
else
Ignore.
⊲ cf. figure 5.5(b).
end
else
if (v ∈ Ch(u)) then
⊲ La requeˆte remonte les branches de l’arbre depuis un fils de u.
if (key ∈/ Itree(sT (u))) then
Met le champ flag a` 0.
Re´-e´met.
⊲ cf. figure 5.4(b).
else
⊲ ∃w ∈ sT (u) \ {u, v} tel que key ∈ I(w).
if (flag = 0) then
Met le champ flag a` 1.
Re´-e´met.
⊲ key ∈/ Itree(sT (v)) mais puisque key ∈ Itree(sT (u)), u doit transmettre
la requeˆte a` ses autres fils. Celle-ci redescend l’arbre par une autre branche u.
Cf. figure 5.4(c).
else
⊲ La requeˆte transite par v avant de redescendre. Cf. figure 5.5(c).
Ignore.
end
end
else Ignore.
⊲ Cf. figure 5.5(a).
end
end
112 CHAPITRE 5. LOCALISATION ET ROUTAGE
5.3.7 Routage sur le re´seau physique
Dans cette section, nous explicitons la seconde phase du routage indirect : le routage
dans l’espace physique. Comme nous l’avons de´ja` mentionne´, nous proposons une
approche hie´rarchique base´e sur la structure de clusters dans laquelle nous appliquons
un protocole pro-actif entre les clusters (comme par exemple OLSR [25]) et re´actif
a` l’inte´rieur des clusters (comme par exemple DSR [43] ou AODV [62]). Comme le
nombre de clusters est constant quand la densite´ des nœuds augmente, le nombre de
nœuds par cluster augmente aussi (O(n) nœuds par cluster). Comme le nombre de
clusters est constant, il en est de meˆme pour le nombre de routes entre ces clusters et
chaque cluster a O(1) routes a` maintenir vers les autres clusters. Bien que le nombre
de nœuds augmente, l’excentricite´ moyenne des nœuds dans un cluster reste faible et
constante (entre 3 et 4 sauts en moyenne). Ainsi, une route re´active dans un cluster peut
eˆtre trouve´e a` la demande sans trop de latence et avec un faible nombre de sauts.
Un routage pro-actif entre clusters signifie que chaque cluster ou nœud maintient en
permanence la liste des clusters a` traverser pour aller d’un cluster A vers un cluster B.
Il reste maintenant a` de´finir qui, dans un cluster maintient ces routes pro-actives vers les
autres clusters. L’approche la plus commune´ment admise est la suivante. Si tre`s peu de
messages sont route´s vers les autres clusters, seul le chef de cluster ou quelques nœuds
peuvent me´moriser ces routes et les fournir sur demande aux autres nœuds du cluster.
Si au contraire, cela arrive plus fre´quemment, la table de routage entre clusters peut
eˆtre distribue´e a` tous les nœuds en appliquant par exemple l’algorithme de diffusion
efficace dans un cluster introduit en section 4.4.
Supposons que le nœud u cherche a` joindre le nœud v. Si v est le chef de cluster de u
ou un de ses voisins (v ∈ Γ1(u) ∪ {H(u)}), u sait de´ja` comment joindre v et n’a donc
pas besoin de faire appel a` la fonction de look-up. Dans le cas contraire, u doit d’abord
localiser v (connaıˆtre C(v)) avant de pouvoir ensuite lui envoyer un message suivant
le processus de routage illustre´ sur la figure 5.6. Si C(v) = C(u), alors u initialise un
routage de type re´actif dans son cluster pour joindre v. Sinon, graˆce au routage pro-actif
entre clusters, u connaıˆt la liste des clusters a` traverser pour atteindre C(v). Soit C(w)
le premier cluster a` traverser. u initialise un routage re´actif vers un nœud x ∈ C(u) qui
est un nœud frontie`re avec C(w) : x tel que x ∈ C(u) et ∃y ∈ Γ1(x) ∩ C(¯w).
x fait alors suivre le message de u a` l’un de ses voisins y se trouvant dans C(w). y
re´ite`re alors le meˆme processus de routage, et ainsi de suite, jusqu’a` joindre le cluster
de la destination C(v).
Ce processus de routage est donne´ dans l’algorithme 2. Nous notons
Next Hop(cluster1, cluster2) la fonction qui retourne le prochain cluster a`
traverser pour atteindre le cluster2 depuis le cluster1. Cette fonction illustre le
routage pro-actif entre clusters et est connue par tous les nœuds.
5.3. NOTRE PROPOSITION 113
Cluster B
4
Cluster C
Cluster A 2 Y 3 Z T 5X V
1
U
FIG. 5.6 – u souhaite joindre le nœud v. Graˆce a` l’ope´ration de look-up, il sait que
C(v) = C. Il connaıˆt le prochain cluster a` traverser pour atteindre C : le cluster B. Il
joint le nœud x, voisin de B avec un protocole re´actif (fle`che 1). x transmet le message
a` son voisin y du cluster B (fle`che 2). y sait que les clusters B et C sont voisins,
il transmet le message a` un nœud z de son cluster, voisin du cluster C (fle`che 3). z
transmet a` son voisin t dans C (fle`che 4) qui joint finalement v graˆce a` un routage
re´actif dans son cluster (fle`che 5).
Algorithm 2 Routage hie´rarchique
Pour un message M envoye´ par le nœud x ∈ C(x) au nœud y ∈ C(y)
Ccurrent = C(x)
Cnext = C(x)
while (Cnext 6= C(y)) do
Cnext = Next Hop(Ccurrent, C(y))
Envoie M avec un routage re´actif vers le nœud u ∈ Ccurrent tel que ∃v ∈ Γ1(u) ∩
Cnext.
u envoie M a` son voisin v.
Ccurrent = Cnext
end
⊲ Le message a atteint le cluster destination.
Envoie M avec un routage re´actif vers le nœud destination y.
end
Enregistrer la position d’un nœud . Si le nœud u souhaite seulement enregistrer sa
position dans un autre cluster que le sien, il utilise le meˆme sche´ma. Par exemple,
si u souhaite s’enregistrer dans C, il exe´cute l’algorithme 2 (sans avoir a` effectuer
l’ope´ration de look-up vu qu’il connaıˆt de´ja` le nom des clusters existants ainsi que la
liste des clusters a` traverser pour les joindre) jusqu’a` atteindre un nœud dans C, quel
qu’il soit (le nœud t dans notre exemple). t envoie alors une Registration Request :
〈RR, key = {hash(u), u} , A, f lag〉 dans C. On remarque que, comme la requeˆte
passe par le nœud y dans le cluster B, y peut faire de meˆme et enregistrer u dans b
en meˆme temps.
114 CHAPITRE 5. LOCALISATION ET ROUTAGE
5.4 Simulations
Comme nous l’avons de´ja` mentionne´, il n’a e´te´ propose´, a` notre connaissance, qu’un
autre protocole de routage hie´rarchique qui propose une approche re´active a` l’inte´rieur
des clusters et pro-active entre les clusters : le protocole SAFARI [69]. Dans cette
section, nous e´valuons par simulation notre algorithme de localisation/routage sur notre
structure de clusters en la comparant aux performances de SAFARI.
5.4.1 SAFARI
SAFARI propose une organisation hie´rarchique de l niveaux, c.a`.d que les clusters
(appele´s cellules dans SAFARI) sont re´cursivement re-groupe´s en clusters de niveaux
supe´rieurs et ainsi de suite. Les simples nœuds sont conside´re´s comme des clus-
ters/cellules de niveau 0. Le nombre de niveaux s’e´tablit automatiquement en fonction
de la taille et de la densite´ du re´seau.
Le rayon des cellules de SAFARI est de´fini a priori. Le rayon D1 des cellules de ni-
veau 1 (e´quivalentes aux clusters de notre algorithme, e´galement appele´es cellules fon-
damentales) est fixe´ et les rayons Di des niveaux supe´rieurs sont de´finis re´cursivement
a` partir de D1. La hie´rarchie de cellules construite par SAFARI se base sur une
auto-se´lection des nœuds en tant que drums (cluster-heads). Un drum de niveau i est
e´galement un drum de tout niveau infe´rieur j tel que 0 ≤ j ≤ i. Un drum de niveau i
de´cide d’augmenter ou de de´cre´menter son niveau en fonction du nombre de drums de
niveaux i+ 1 et i se trouvant a` une certaine distance de lui. Si un drum de niveau i n’a
aucun drum de niveau i + 1 parmi ses voisins a` moins de Di sauts, il incre´mente son
niveau et s’auto-de´clare drum de niveau i+ 1. Si deux drums de niveau i sont distants
de moins de Di sauts, seul le drum de plus grand identifiant reste drum de niveau i,
l’autre de´cre´mente son niveau et devient drum de niveau i− 1.
Cette hie´rarchie attribue a` chaque nœud un anceˆtre (chef) unique a` chaque niveau. A
partir de cette algorithme de clustering hie´rarchique, chaque nœud se voit attribuer
une adresse/coordonne´e logique (qui sera son adresse dans l’espace de la DHT). La
coordonne´e d’un nœud de niveau i est la concate´nation de la coordonne´e de son drum
de niveau i+ 1 et d’un nombre ge´ne´re´ ale´atoirement.
Soient COORD(di) la coordonne´e d’un drum di de niveau i, PARENT (di) le pe`re
de di (le drum de niveau i+ 1 de di) et Rand un nombre ale´atoire. La coordonne´e de
di est comme suit :
COORD(di) = COORD(PARENT (d0)) pour i = 0
= COORD(PARENT (di)).Rand pour 0 < i
Les drums de niveau 0 (les simples nœuds) sont des feuilles dans cet arbre de coor-
donne´es. Tous les nœuds d’une meˆme cellule fondamentale ont la meˆme coordonne´e
logique.
Chaque drum de niveau i envoie un paquet appele´ beacon toutes les Ti unite´s de
temps, Ti de´pendant du niveau i. Plus le niveau hie´rarchique est e´leve´, plus la pe´riode
5.4. SIMULATIONS 115
d’e´mission des beacons correspondants est grande. Un beacon de niveau i envoye´ par
le drum di est transmis a` tous les nœuds de la cellule de di ainsi qu’a` tous les nœuds
se trouvant dans une cellule de niveau i dont le drum de niveau i + 1 est le pe`re de
di. Par exemple, sur la Figure 5.4.3, les beacons de niveau 1 envoye´s par le drum de
niveau 1 de la cellule F seront envoye´s a` tous les nœuds des cellules F et G, puisque
ces deux cellules appartiennent a` la meˆme cellule de niveau 2. Chaque nœud stocke
tous les beacons qu’ils relaient dans une table appele´e Drum Ad Hoc Routing Table
(DART) en leur associant la date de re´ception et le nœud par lequel il a e´te´ rec¸u.
Les coordonne´es des nœuds forment l’espace d’adressage de la DHT de SAFARI.
La fonction de hachage retourne k diffe´rentes coordonne´es de points de rendez-vous
pour chaque niveau i. Contrairement a` notre heuristique ou` les points de rendez-vous
se trouvent dans le meˆme cluster que le demandeur, les points de rendez-vous dans
SAFARI sont re´partis sur l’ensemble du re´seau. Le look-up se base sur l’ide´e qu’en
ge´ne´ral, les nœuds communiquent plus avec les entite´s proches d’eux. Lorsqu’un nœud
x veut s’enregistrer, il hache son identifiant et obtient k coordonne´es pour chaque ni-
veau i (0 ≤ i ≤ l) par la DHT. x va s’inscrire k fois dans chaque niveau. Pour chacune
de ces coordonne´es c retourne´e par la DHT, il va s’enregistrer aupre`s du nœud qu’il
trouve qui a la coordonne´e la plus proche possible de la coordonne´e c. Pour cela, il
envoie sa requeˆte d’enregistrement au nœud u se trouvant dans sa DART et dont la co-
ordonne´e est la plus proche de la coordonne´e c. u fait de meˆme et transmet la requeˆte
de u au nœud de sa propre DART dont la coordonne´e est la plus proche de c et ainsi de
suite jusqu’a` atteindre un nœud d’une cellule fondamentale (tous les nœuds de la meˆme
cellule fondamentale ont la meˆme coordonne´e) qui n’a aucune entre´e dans sa DART
avec une coordonne´e plus proche de c qu il ne l est lui meˆme Ce nœud 3’ ’ - . devient le
nœud aupre`s duquel le nœud u enregistre sa position. Lorsqu’un nœud x veut re´cupe´rer
la coordonne´e d’un nœud y, il va d’abord chercher dans les cellules de niveau 1 appar-
tenant a` la meˆme cellule de niveau 2 que lui. S’il ne trouve pas, il cherchera au niveau
supe´rieur et ainsi de suite : il cherche dans toutes les cellules de niveau i appartenant a`
la meˆme cellule de niveau i+ 1 que lui, jusqu’a` atteindre l’ensemble du re´seau. Lors-
qu’un nœud x veut re´cupe´rer les coordonne´es d’un nœud y, il hache la coordonne´e de
y et envoie sa requeˆte au nœud u se trouvant dans sa DART et dont la coordonne´e est
la plus proche de la coordonne´e retourne´e par la DHT pour le niveau conside´re´, et ainsi
de suite, jusqu’a` atteindre un nœud r. Si r connaıˆt les coordonne´es de y, il les retourne
a` x qui pourra alors joindre y de la meˆme fac¸on qu’il a joint r. Si r ne de´tient pas la
coordonne´e de y, x re´-ite`re sa requeˆte au niveau supe´rieur. x peut donc envoyer jusqu’a`
l requeˆtes de look-up pour localiser y. Nous verrons par la suite que meˆme au bout de l
fois, le look-up de SAFARI peut e´chouer. Dans nos simulations, k est fixe´ a` 3, comme
le sugge`re les auteurs de SAFARI.
Nous nous sommes inte´resse´s dans un premier temps a` la formation des clusters de
chacun des deux algorithmes, puis, nous avons e´value´ les performances du look-up et
du routage de chacun des protocoles.
3Tous les nœuds d’une cellule fondamentale ayant la meˆme coordonne´e, plusieurs nœuds peuvent poten-
tiellement stocker la position de u mais SAFARI n’explicite pas s’il s’agit du drum ou d’un nœud particulier
de la cellule
116 CHAPITRE 5. LOCALISATION ET ROUTAGE
5.4.2 Comparaison des structures
Comme notre heuristique construit des clusters de rayon compris entre 3 et 4 sauts
(chapitre 3), nous avons fixe´ D1 a` 3 dans SAFARI, de fac¸on a` pouvoir comparer les
cellules fondamentales de SAFARI aux clusters de notre algorithme. C’est d’ailleurs la
valeur choisie par les auteurs de SAFARI dans leurs simulations.
La diffe´rence principale entre les deux heuristiques est que SAFARI construit l ni-
veaux hie´rarchiques de cellules alors que notre algorithme ne forme qu’un seul niveau
de clusters. Le nombre de niveaux e´tabli par SAFARI s’adapte automatiquement en
fonction de diame`tre du re´seau. La table 5.1 donne le nombre de niveaux construits par
SAFARI sur diffe´rentes topologies. Nous verrons par la suite que le nombre de niveaux
impacte les performances du look-up de SAFARI.
Topologie Nombre de niveaux
10× 10 Grille a` 4 voisins entre 3 et 4
15× 15 Grille a` 4 voisins 4
Chaıˆne de 50 nœuds entre 4 et 5
Chaıˆne de 75 nœuds 5
Chaıˆne de 100 nœuds 6
Topologie Poisson λ = 500, R ≤ .1 entre 3 et 4
Topologie Poisson λ = 500, R < .1 entre 2 et 3
TAB. 5.1 – Nombre de niveaux de cellules construits par SAFARI en fonction de la
topologie sous-jacente.
Bien que le diame`tre du re´seau intervienne sur le nombre de niveaux hie´rarchiques, seul
le degre´ des nœuds influence les caracte´ristiques des clusters, tout comme dans notre
algorithme, les heuristiques e´tant locales et distribue´es. Les re´sultats de la table 5.2
montrent que les clusters construits par les deux heuristiques ont des caracte´ristiques
moyennes e´quivalentes (nous ne conside´rons que les clusters de niveau 1 pour SA-
FARI). Cependant, comme le montre l’e´cart type du nombre de nœuds par cluster, les
clusters de SAFARI sont moins homoge`nes que ceux de notre heuristique.
Comme nous l’avons e´tudie´ dans le chapitre 3, lorsqu’un nœud inte`gre le re´seau or-
ganise´ avec notre algorithme, il ve´rifie son voisinage, calcule sa densite´ et se choisit
un pe`re. L’algorithme stabilise rapidement en un temps proportionnel a` la hauteur de
l’arbre. Dans SAFARI, lors de la phase d’initialisation, les nœuds attendent un temps
ale´atoire avant de prendre la de´cision d’e´ventuellement augmenter leur niveau. Cette
de´cision est base´e sur les informations contenues dans la DART de chaque nœud. Le
temps de stabilisation de SAFARI est donc lie´ a` la pe´riode initiale d’attente ale´atoire et
a` la fre´quence Ti d’e´mission des beacons (donc a` T1 pour les cellules fondamentales).
Dans nos simulations, les nœuds tirent un temps ale´atoire uniforme´ment entre 0 et 5
unite´s de temps et T1 = 2 unite´s de temps, comme le sugge`rent les auteurs de SAFARI.
De fac¸on a` comparer e´quitablement les deux heuristiques, nous supposons que les bea-
cons de niveau 1 sont e´change´s a` la meˆme fre´quence que les paquets Hello dans notre
5.4. SIMULATIONS 117
heuristique (T1).
λ 500 600 700
Densite´ SAFARI Densite´ SAFARI Densite´ SAFARI
Nb clusters 11.70 16.2 10.08 12.6 8.06 11.4
Taille clusters 39.91 32.58 45.64 39.76 54.43 43.57
σ(taille) 18.66 13.88 17.88 17.83 16.59 20.28
Diame`tre 4.99 4.67 5.52 4.62 5.50 4.76
CH/drum excen. 3.01 2.69 3.09 2.67 3.37 2.80
Temps stab. 5.27 107.67 5.34 113.41 5.33 91.95
σ(Temps stab) 0.63 132.41 0.74 135.56 0.85 123.69
λ 800 900 1000
Densite´ SAFARI Densite´ SAFARI Densite´ SAFARI
Nb clusters 7.03 9.10 6.15 8.10 5.57 7.40
Taille clusters 61.23 54.80 70.41 60.58 73.72 66.21
σ(taille) 15.59 23.20 15.29 25.01 14.27 26.61
Diame`tre 5.65 4.83 6.34 4.77 6.1 4.73
CH/drum excen. 3.17 2.77 3.19 2.72 3.23 2.82
Temps stab. 5.34 90.55 5.43 60.61 5.51 61.97
σ(Temps stab) 0.99 111.18 1.21 115.58 1.44 118.69
TAB. 5.2 – Caracte´ristiques des clusters pour chaque heuristique pour R = .1.
Le temps de stabilisation des algorithmes est pre´sente´ dans la table 5.2. Parfois, nous
avons pu remarquer qu’au bout de 350 unite´s de temps (temps sugge´re´ par les au-
teurs de SAFARI), la structure de SAFARI n’e´tait pas e´tablie. Dans ces cas, SAFARI
ne converge pas. Nous n’avons pris en compte dans ces statistiques que les cas ou`
SAFARI converge. On remarque que l’intensite´ des nœuds n’influence pas le temps
de stabilisation des deux protocoles. SAFARI est beaucoup plus long a` stabiliser que
notre algorithme et son temps de stabilisation est loin d’eˆtre re´gulier comme le montre
l’e´cart type σ. Certaines instances du protocole convergent tre`s rapidement alors que
d’autres n’ont toujours pas converge´ apre`s un temps de 350 unite´s de temps. En effet,
un nœud peut osciller entre diffe´rents e´tats en fonction des valeurs ale´atoires choisies.
La figure 5.7 donne un exemple dans lequel SAFARI ne converge pas. Dans la fi-
gure 5.7(b), le re´seau est en phase d’initialisation. La pe´riode d’attente ale´atoire du
nœud 3 est la premie`re a` expirer : le nœud 3 devient le premier drum de niveau 1. Puis,
les pe´riodes d’attente de plusieurs nœuds expirent. Ceux parmi eux qui entendent un
drum de niveau 1 a` moins de D1 = 3 sauts s’attachent a` lui. Les autres s’auto-e´lisent
drum de niveau 1. Dans notre exemple, la pe´riode du nœud 1 a expire´ avant celles de 4,
12 et 25 et celle de 6 a expire´ avant celles des nœuds 23, 8, 26 et 16. Si au contraire, la
pe´riode du nœud 23 avait expire´ avant celle du nœud 6, par exemple, 23 aurait cre´e´ son
propre cluster et 6 se serait ensuite rattache´ a` 23. D’un autre coˆte´, on peut remarquer
que si la pe´riode du nœud 19 expire avant celle du nœud 1, 19 s’attache dans un premier
temps au drum 3 avant de s’attacher a` 1 lorsque celui-ci se de´clare drum. Ainsi, sur la
118 CHAPITRE 5. LOCALISATION ET ROUTAGE
figure 5.7(c), les nœuds 6 et 1 deviennent des drums de niveau 1, les nœuds 0, 9, 7
s’attachent au nœud 0, les nœuds 21, 19, 12, 4 et 25 s’attachent au nœud 1 et les nœuds
0, 7 et 9 s’attachent a` 3. Ceci montre l’importance du temps d’attente ale´atoire dans la
formation des clusters de SAFARI. Comme il n’existe aucun drum de niveau 2 a` moins
de D2 = 6 sauts du nœud 3, celui-ci devient ensuite un drum de niveau 2. les cellules
de niveau 1 des drums 1 et 6 s’attachent a` la cellule de niveau 2 de 3 (figure 5.7(d)).
Puis, la pe´riode d’attente du nœud 17 expire. Comme celui-ci n’entend aucun drum de
niveau 1 a` moins de D1 sauts, il devient un drum de niveau 1. Lorsque les autres nœuds
se re´veillent, ils s’attachent a` lui. Comme le drum 17 de niveau 1 n’entend aucun drum
de niveau 2 dans son voisinage a` D2 sauts, il devient un drum de niveau 2. Sa cellule de
niveau 2 ne se compose que d’une seule cellule de niveau 1. De la meˆme fac¸on, comme
le drum 3 de niveau 2 n’entend aucun drum de niveau 3 dans son voisinage a` D3 sauts,
il devient un drum de niveau 3. C’est ce que l’on peut voir sur la figure 5.7(f). Dans
SAFARI, si un drum de niveau i n’entend pas au moins deux drums de niveaux i− 1,
il baisse son niveau. Ainsi, dans notre exemple, comme le drum 3 de niveau 3 n’entend
qu’un seul drum de niveau 2 (le drum 17), il re-devient un drum de niveau 2. De meˆme,
comme le drum 17 de niveau 2 n’entend aucun drum de niveau 1, il re-devient drum de
niveau 1. C’est a` dire que nous revenons a` la structure de la figure 5.7(e). La structure
va ensuite e´voluer pour re-devenir celle illustre´e par la figure 5.7(f) et ainsi de suite.
Un cycle apparaıˆt et SAFARI ne converge jamais.
5.4.3 Look-up et routage
Cette section analyse les performances du look-up effectue´ dans chaque algorithme
ainsi que le routage qui s’en suit.
Dans notre algorithme, les requeˆtes de look-up sont route´es a` l’inte´rieur d’un cluster
en effectuant un routage par intervalle sur l’espace virtuel de la DHT (Section 5.3). Les
diame`tres des clusters e´tant relativement petits, la requeˆte ne parcourra qu’un nombre
de sauts borne´ pour atteindre le nœud rendez-vous. Ceci n’est pas le cas dans SAFARI
ou` les nœuds rendez-vous se trouvent dans la plupart des cas dans d’autres clusters.
De plus, comme nous l’avons de´ja` e´voque´, dans un cas de re´seau statique, avec une
couche MAC ide´ale, tous les look-ups de notre algorithme re´ussiront, ce qui n’est pas
le cas dans SAFARI. Et meˆme lorsqu’un look-up de SAFARI re´ussit, il peut avoir
utilise´ plusieurs requeˆtes alors qu’une seule suffit a` notre algorithme. Cela s’explique
par le phe´nome`ne suivant. Les drums de niveau i de SAFARI envoient leurs beacons
aux nœuds des cellules de niveau i ayant le meˆme drum i+ 1 qu’eux. Donc, dans une
hie´rarchie de 3 niveaux ou plus, tous les nœuds ne recevront pas les beacons de tous
les drums. Si on prend l’exemple de la figure 5.4.3, le drum de la cellule fondamentale
B envoie ses beacons aux nœuds des cellules A, B et C mais les nœuds des cellules D
ou E ne les rec¸oivent pas.
Quand le nœud d cherche a` s’enregistrer, il hache son identifiant et regarde dans sa
table DART quel nœud v a la coordonne´e la plus proche de la valeur retourne´e par la
DHT. En effectuant le look-up sur son propre identifiant, d finit par s’enregistrer aupre`s
d’un nœud h. Cependant, il faut noter que h est le nœud trouve´ a` partir de la DART
5.4. SIMULATIONS 119
21 1
0
19
25 11
drum de niveau 0 (simple noeud) 3 9
4
22
7 24
5 12 15 20
drum de niveau 1 2 18cellule fondamentale 14 8 26
23 17
drum de niveau 2 cellule de niveau 2 6 16 10 13
drum de niveau 3 cellule de niveau 3
(a) Le´gende (b)
21 1 21 1
0
19 11 0 19 11
3 9 4
25
9 4 2522 3
7 22
5 12 15
24 7
20 5 12 15
24
20
14 2 26 188 14 2 8 26
18
23 17 23 17
6 16 10 13 6 16 10 13
(c)
(d)
21 1
21 1
0
19
25 11 0
3 9 4 19 1122 9 4 253
7 24 22
5 12 15 7 2420 5 12 15 20
14 2 8 26
18
14 2 18
23 17 8 2623 17
6 16 10 13 6 16 10 13
(e) (f)
FIG. 5.7 – Exemple ou` SAFARI oscille et ne converge jamais.
120 CHAPITRE 5. LOCALISATION ET ROUTAGE
de d. h n’a pas toujours exactement la meˆme coordonne´e que celle retourne´e par la
DHT, il est juste un nœud dont la coordonne´e est proche. Le proble`me vient alors du
fait que les nœuds posse`dent une table DART diffe´rente les uns des autres lorsque le
cluster est organise´ en plus de 2 niveaux hie´rarchiques. En effet, quand un nœud s veut
envoyer un message a` d, il hache l’identifiant de d et ainsi obtient des coordonne´es. Il
va alors envoyer sa requeˆte aux nœuds de sa DART dont les coordonne´es sont les plus
proches de celles retourne´es par la DHT. Il va atteindre un nœud n. Or d ne s’est pas
enregistre´ aupre`s de n car n de figure pas dans la DART de d et n’est pas atteignable
depuis la DART de d. De meˆme, les nœuds h aupre`s desquels d s’est enregistre´ ne
sont pas toujours contenus dans la table DART de s et dans ces cas-la`, le look-up, ne
peut re´ussir. Ainsi, plus le nombre de niveaux hie´rarchiques est e´leve´, plus le taux de
re´ussite des look-ups de SAFARI est faible.
level−0 drum (regular node)
1
level−1 drum
level−2 drum d
level−3 drum C h
fondamental cell B
level−2 cell
level−3 cell F A D
G 2
n
E s
FIG. 5.8 – Exemple de clusters de SAFARI.
La table 5.3 pre´sente diffe´rentes valeurs que nous avons releve´es lors de nos simu-
lations de look-up et routage de chacun des deux algorithmes. La` encore, les valeurs
concernant SAFARI ne sont prises en compte que lorsque l’algorithme converge.
Le champ ”Nb de requeˆtes” indique le nombre de requeˆtes qu’un nœud u doit envoyer
en moyenne avant de joindre un nœud qui de´tient l’information recherche´e (avant de
re´ussir le look-up). Ce champ est toujours e´gal a` 1 pour notre heuristique puisqu’une
seule requeˆte est ne´cessaire.
Le champ ”Longueur du Look-up” donne le nombre de sauts que parcourt une requeˆte
de look-up en moyenne dans chaque algorithme. Les nœuds de rendez-vous de notre
algorithme e´tant toujours dans le meˆme cluster que la source de la requeˆte et ceux de
SAFARI e´tant distribue´s sur l’ensemble du re´seau, les routes sont e´videmment plus
courtes dans notre heuristique. A` cela s’ajoute que SAFARI peut lancer une requeˆte de
plus en plus loin en augmentant le niveau apre`s un e´chec de requeˆte de look-up. Ces
valeurs sont influence´es par la densite´ locale du re´seau (degre´ des nœuds) puisque les
5.4. SIMULATIONS 121
λ 500 600 700
Densite´ SAFARI Densite´ SAFARI Densite´ SAFARI
Nb de requeˆtes 1 1.71 1 1.82 1 1.78
Taux de re´ussite 100% 95.70% 100% 92.20% 100% 90.90%
Longueur du Look-up 3.02 14.94 3.07 12.56 3.15 10.68
Longueur des chemins 6.31 7.28 6.67 5.87 6.37 6.17
Longueur globale 12.39 37.16 12.81 30.99 12.67 27.53
λ 800 900 1000
Densite´ SAFARI Densite´ SAFARI Densite´ SAFARI
Nb de requeˆtes 1 1.79 1 1.58 1 1.54
Taux de re´ussite 100% 85.80% 100% 90.50% 100% 91.00%
Longueur du Look-up 3.16 10.36 3.21 8.63 3.24 5.04
Longueur des chemins 6.75 5.88 6.61 5.73 6.66 5.09
Longueur globale 13.07 26.60 13.03 22.99 13.14 15.17
TAB. 5.3 – Comparaison de notre algorithme et de SAFARI.
caracte´ristiques des clusters en de´coulent. Cependant, ce facteur de´pend e´galement de
l’e´talement du re´seau pour SAFARI car plus le re´seau est e´tendu, plus le nœud rendez-
vous peut eˆtre e´loigne´.
Le champ ”Longueur des chemins” donne le nombre de sauts a` parcourir dans la
deuxie`me phase du routage indirect, en suivant les sche´mas de routage propose´s dans
chacun des algorithmes. Le champ ”Longueur globale” donne le nombre moyen de
sauts a` parcourir avant d’atteindre enfin le nœud destination. Il est e´gal a` la longueur
des routes de la deuxie`me e´tape plus deux fois la longueur des routes du look-up car la
requeˆte de look-up doit effectuer un aller-retour.
On remarque que les chemins de look-up dans SAFARI sont plus longs que les chemins
emprunte´s par les messages lors de la deuxie`me phase du routage indirect, ce qui peut
induire une latence importante. Ce n’est pas le cas dans notre approche ou` les requeˆtes
de look-up sont contenues dans un cluster et donc suivent un chemin dont la taille est
borne´e par le diame`tre des clusters, lui-meˆme borne´ par une constante. (Cf. chapitre 3).
Les longueurs des routes (suivies par les requeˆtes de look-up et par les messages de
donne´es) de´pendent bien suˆr de la densite´ locale du re´seau comme toutes les autres
caracte´ristiques e´tudie´es pour ces deux protocoles. Cependant, les routes emprunte´es
dans la deuxie`me phase du routage indirect de´pendent e´galement de l’e´talement du
re´seau. Plus le re´seau est grand, plus la distance se´parant deux nœuds du re´seau est
grande. Dans SAFARI, il en est de meˆme pour la taille des routes suivies par les
requeˆtes de look-up. Dans notre approche, la longueur des routes du look-up reste
constante lorsque le re´seau s’e´tale car elle est limite´e par le diame`tre des clusters qui
lui-meˆme reste constant. Ainsi, meˆme si pour les re´sultats de simulation obtenus, la
longueur des routes de look-up dans notre approche repre´sente pre`s de la moitie´ de
la taille du chemin global, elle tend a` devenir ne´gligeable devant la taille des routes
vers le nœud destination lorsque le re´seau s’e´tale, ce qui n’est pas le cas de SAFARI
pour lequel le ratio longueur look−uplongueur totale reste constant avec l’e´talement du re´seau. Les
122 CHAPITRE 5. LOCALISATION ET ROUTAGE
comparaisons mene´es ici peuvent sembler avoir e´te´ mene´es sur un re´seau trop peu
e´tendu. Cependant, le but recherche´ ici e´tait de comparer notre algorithme a` SAFARI
et pour un re´seau plus large, SAFARI construit un plus grand nombre de niveaux et ne
converge plus. C’est pourquoi, nous n’avons pu simuler le routage sur un re´seau plus
e´tendu qu’avec notre me´trique. Les re´sultats donne´s dans la table 5.4 sont obtenus sur
un re´seau ou` le degre´ moyen des nœuds (et donc l’intensite´ λ du processus de Poisson)
est constant mais avec une taille de re´seau de plus en plus importante. Les re´sultats sont
donne´s pour λ = 500 (δ ≈ 15.7) mais le comportement de l’algorithme est le meˆme
quelle que soit l’intensite´ conside´re´e.
Les re´sultats montrent qu’effectivement, bien que le re´seau grandisse, la longueur des
routes emprunte´es par les requeˆtes de look-up reste constante et que seule la longueur
totale des routes pour joindre le nœud destinataire augmente.
Les routes emprunte´es lors de la deuxie`me phase du routage indirect ne sont pas op-
timales dans la mesure ou` elles ne sont pas calcule´es sur la topologie des nœuds mais
sur la topologie de clusters On retrouve le meˆme principe que dans BGP 4. ou` les
se´quences des AS (Autonomous System) ne donnent pas toujours le nombre de sauts
optimal entre clusters. Le champ ”E´ tirement” donne l’e´carte en nombre de sauts entre
la longueur des routes emprunte´es lors de la deuxie`me phase du routage indirect et la
longueur des routes dans le graphe (plus courts chemins) en nombre de sauts. On re-
marque que le facteur d’e´tirement survenant dans la seconde phase du routage indirect
est ne´gligeable devant la longueur totale des routes. Seul l’ajout des sauts ne´cessaires
au look-up importe.
Nb de nœuds 500 600 700 800 900 1000
Nb de Clusters 11.70 14.20 15.80 17.50 21.42 24.30
Longueur du Look-up 3.02 2.97 3.07 3.05 2.99 3.07
Longueur des chemins 6.31 6.88 7.08 8.06 8.69 9.05
E´ tirement 0.69 0.74 0.78 0.82 0.86 0.92
Longueur globale 12.39 12.90 13.55 13.97 14.98 15.43
TAB. 5.4 – Proprie´te´s de notre approche de routage avec λ = 500 (degre´ moyen des
nœuds constant δ = 15.7) lorsque le re´seau s’e´tale.
5.5 Conclusion
Dans ce chapitre, nous avons propose´ un protocole de routage hie´rarchique pou-
vant s’appliquer sur notre organisation de cluster. Cette approche hie´rarchique suit le
sche´ma inverse que ceux commune´ment de´crits dans la litte´rature. En effet, nous pro-
posons d’appliquer un protocole de routage re´actif a` l’inte´rieur des clusters et pro-actif
entre les clusters. Une telle approche suppose un routage indirect utilisant une table de
4www.freesoft.org/CIE/RFC/1772/
5.5. CONCLUSION 123
hachage distribue´e. Notre approche tire avantage des caracte´ristiques intrinse`ques du
me´dium radio et des clusters pour a` la fois proposer un sche´ma d’e´tiquetage efficace
des sommets des arbres de clustering pour distribuer les partitions de l’espace logique
d’adressage de la DHT et permettre un routage global impliquant une taille me´moire
sur les nœuds en O(1). Les requeˆtes de look-up peuvent ensuite eˆtre route´es graˆce a`
un routage par intervalle sur cet espace. La deuxie`me phase du routage indirect se fait
alors dans l’espace physique avec des chemins quasi-optimaux.
Afin d’e´valuer les performances de notre algorithme, nous l’avons compare´ au
seul autre protocole de notre connaissance qui utilise le meˆme sche´ma de routage
hie´rarchique : SAFARI. Il s’est ave´re´ que notre approche offre de meilleures ca-
racte´ristiques sur diffe´rents crite`res : temps de stabilisation, succe`s des look-ups, taille
des chemins, etc. Cependant, ces re´sultats sont a` mode´rer de par le fait qu’il n’existe
encore que tre`s peu de protocoles proposant cette approche de routage hie´rarchique.
Dans la continuite´ de cette approche, nous souhaiterions analyser plus en profondeur
les pe´riodes de rafraıˆchissement des enregistrements des nœuds, en fonction de leur
mobilite´. Comme les algorithmes pre´sente´s dans cette the`se peuvent eˆtre qualifie´s de
”quasi-locaux” et que la structure de clusters sous-jacente a pre´sente´ de bons compor-
tements face a` la mobilite´ des nœuds, nous espe´rons qu’il en sera de meˆme pour le
protocole de localisation/routage.
Comme nous l’avons vu, seulement peu de propositions utilisent une approche pro-
active entre les clusters et re´active a` l’inte´rieur des clusters. Nous avons compare´
notre approche a` une autre qui utilisait ce meˆme mode`le. Cependant, il peut e´galement
s’ave´rer inte´ressant d’e´tablir des comparaisons avec une approche ”classique” de la
litte´rature, c.a`.d. qui propose un routage re´active entre clusters et pro-actif au sein d’un
cluster.
124 CHAPITRE 5. LOCALISATION ET ROUTAGE
5.6 Publications
1. Journaux et revues avec comite´ de lecture :
(a) Distributed Node Location in clustered multi-hop wireless networks. Na-
thalie Mitton et E´ ric Fleury. GESTS International Transaction on Computer
Science and Engineering, Volume 21, De´cembre 2005.
2. Colloques et confe´rences internationaux avec comite´ de lecture :
(a) Distributed Node Location in clustered multi-hop wireless networks. Na-
thalie Mitton, E´ ric Fleury. Asian Internet Engineering Conference (AIN-
TEC’05), 13-15 De´cembre 2005, Bangkok, Thailande.
(b) Distributed Node Location in clustered multi-hop wireless networks. Na-
thalie Mitton, E´ ric Fleury. LOCALITY’05, 26 Septembre 2005, Cracovie,
Pologne.
3. Rapports de recherche :
(a) Distributed Node Location in clustered multi-hop wireless networks. Na-
thalie Mitton et E´ ric Fleury. RR-5723. Octobre 2005.
4. Se´minaires, pre´sentations, expose´s :
(a) Localisation dans les re´seaux sans fil multi-sauts grandes e´chelles. Natha-
lie Mitton, E´ ric Fleury. Se´minaire ACI Pair a` Pair - Arcachon - France - 5-6
Septembre 2005.
Chapitre 6
Conclusion et perspectives
6.1 Conclusion
Mon objectif, au travers de cette the`se, a e´te´ de de´velopper une solution d’utilisation
des re´seaux sans fil sur de larges e´chelles afin de re´pondre aux besoins naissants de
notre socie´te´. Pour cela, il me paraissait important d’e´tudier les diffe´rentes contraintes
de tels re´seaux avant de pouvoir proposer une solution viable et fonctionnelle, meˆme
sur de grandes e´chelles.
J’ai pour cela propose´ une solution distribue´e qui se de´compose en plusieurs e´tapes.
Chacune des e´tapes re´pond a` une application de tels re´seaux tout en en conside´rant
les contraintes. Chaque algorithme est ne´ d’une e´tude des contraintes ou des structures
et se compose d’algorithmes distribue´s, auto-stabilisants et robustes, ne´cessitant peu
de ressources en e´nergie, bande passante ou taille me´moire. Toutes ces e´tapes ont e´te´
e´tudie´es analytiquement et par simulation. Chaque solution a e´te´ compare´e a` d’autres
solutions propose´es dans la litte´rature et s’ave`re soit offrir de meilleurs re´sultats, soit
de meilleurs compromis.
La premie`re e´tape permet de structurer logiquement le re´seau en clusters. A partir de
l’e´tude de la structure ainsi forme´e, plusieurs caracte´ristiques ont pu eˆtre de´gage´es. Ces
caracte´ristiques ont alors guide´ la conception des algorithmes des e´tapes suivantes. La
seconde e´tape a cre´e´ des liens entre ces clusters afin de pouvoir effectuer des diffusions
ge´ne´rales d’information de fac¸on efficace. L’algorithme de diffusion en soi est simple,
il se´lectionne un sous-ensemble de nœuds autorise´s a` relayer le message. Cette sim-
plicite´ intrinse`que est d’autant plus riche qu’elle utilise une structure existante, sans
en cre´er de nouvelles. L’algorithme de diffusion e´conomise ainsi des messages et des
ressources.
Enfin, la dernie`re e´tape permet a` deux entite´s individuelles de communiquer, quelles
que soient leurs positions dans le re´seau. Ce processus de routage pre´sente plusieurs
originalite´s. En effet, dans un premier temps, il conside`re une approche inverse a`
125
126 CHAPITRE 6. CONCLUSION ET PERSPECTIVES
celle propose´e jusqu’a` maintenant afin de pre´server une faible taille me´moire sur les
nœuds. Ensuite, il emprunte des solutions algorithmiques a` d’autres domaines comme
les tables de hachage distribue´es issues du domaine du Pair a` Pair et le routage par
intervalle issu des re´seaux filaires.
6.2 Perspectives
Les diffe´rents algorithmes propose´s dans chaque e´tape de ma proposition pre´sentent
tous des caracte´ristiques qui peuvent eˆtre e´tudie´es plus en profondeur ou des points
qui me´riteraient certaines optimisations. Par exemple, le comportement de chaque al-
gorithme pourrait eˆtre analyse´ dans un environnement plus mobile. Un autre point im-
portant est que toutes les analyses re´alise´es sur les diffe´rents algorithmes de ma propo-
sition ont e´te´ conduites en supposant une couche MAC ide´ale et un mode`le ”Unit Disk
Graph” pour de´finir le voisinage des nœuds. Conside´rer une couche MAC ide´ale per-
met de n’e´tudier que les caracte´ristiques propres a` l’algorithme conside´re´, ce qui e´tait le
but recherche´ dans cette the`se. Cependant, un protocole de niveau 3 est utilise´ conjoin-
tement avec des protocoles de niveaux infe´rieurs. De meˆme, l’aire de transmission d’un
nœud est rarement un cercle puisque la propagation des ondes de´pend du milieu et des
obstacles que peut rencontrer le signal. Il serait donc inte´ressant d’e´valuer les diffe´rents
algorithmes propose´s dans ce manuscrit, en conside´rant diffe´rents protocoles pour les
couches infe´rieures et diffe´rents modes de propagation des ondes suivant les environ-
nements, aussi bien en ce qui concerne les analyses par simulation que les analyses
the´oriques. En effet, dans nos analyses the´oriques, nous avons e´galement conside´re´ le
mode`le ”Unit Disk Graph” mais d’autres mode`les d’e´tude ont e´te´ propose´s comme par
exemple dans [27] ou [9] qui conside`re le mode`le CDMA utilise´ dans 802.11. De plus,
comme dans un environnement sans fil re´el, de nombreux parame`tres d’environnement
entrent en jeu pour assurer ou non l’existence d’un lien, on peut e´galement conside´rer
un mode`le ou` un lien existe avec une certaine probabilite´.
Par ailleurs, les re´seaux sans fil couvrent une large famille de re´seaux, comme les
re´seaux ad hoc ou les re´seaux de capteurs. Bien que posse´dant tous des caracte´ristiques
semblables, chacun a une utilisation plus pre´cise et des proprie´te´s supple´mentaires. La
solution d’utilisation grande e´chelle que j’ai de´crite ici est ge´ne´rique et peut s’appliquer
a` tout type de re´seau sans fil. Cependant, il me semble que pour concevoir un re´seau
efficace, il faut e´galement conside´rer l’application du re´seau. Ainsi, j’aimerais par la
suite conside´rer plusieurs applications plus cible´es et un type de re´seau plus pre´cis
comme par exemple les re´seaux de capteurs.
En effet, les re´seaux de capteurs offrent un certain nombre de de´fis et de verrous scienti-
fiques. Ils sont le reflet de l’e´volution a` la fois des syste`mes, des re´seaux, de leurs com-
posants mais aussi de leur organisation et des inter-actions et communications entre
syste`mes. Malgre´ des tailles souvent petites, ils inte`grent une forte complexite´, notam-
ment de par l’infrastructure logicielle qui se retrouve distribue´e a` une grande e´chelle et
qui se doit d’offrir des services d’auto-adaptabilite´.
6.2. PERSPECTIVES 127
Les re´seaux de capteurs sont de plus en plus de´ploye´s et offrent des perspectives nou-
velles chaque jour. Aujourd’hui, on cherche a` de´ployer un re´seau de capteurs pour la
surveillance des feux de foreˆts par exemple, afin de pre´venir d’un incendie et d’inter-
venir avant qu’il n’ait cause´ trop de de´gaˆts. A` moyen terme, on cherche a` inte´grer ces
capteurs dans les structures des baˆtiments et ne les faire s’activer que si le baˆtiment
s’e´croule afin de guider les secours. Les contraintes de base restent les meˆmes : e´nergie
et bande passante limite´es. Cependant, avec les nouvelles applications et le de´ploiement
de re´seaux de plus en plus grands, d’autres points sont a` conside´rer, comme la mobilite´
des capteurs (un re´seau de capteurs peut eˆtre embarque´ dans une voiture par exemple
ou servir a` traquer des animaux), la robustesse de la structure globale (il faut s’assurer
que le re´seau de base soit stable avant de penser a` l’e´tendre) ou encore la se´curite´. Pour
une meilleure optimisation, tous ces aspects se doivent d’eˆtre e´tudie´s conjointement.
La solution que j’ai de´veloppe´e dans cette the`se reste applicable, meˆme si les capteurs
pre´sentent des proprie´te´s supple´mentaires par rapport au mode`le ge´ne´rique des re´seaux
sans fil. Par exemple, lorsque l’on conside`re un re´seau de capteurs, bien que la topolo-
gie reste dynamique du fait des apparitions ou disparitions de capteurs dues a` la mort, a`
l’endormissement ou au re´veil des entite´s, les capteurs ne se de´placent pas toujours. De
meˆme, les mode`les de communication sont diffe´rents dans un re´seau de capteur. Deux
capteurs n’ont ge´ne´ralement pas besoin de communiquer directement. On observe sur-
tout des communications de la station de base vers l’ensemble des entite´s (pour une
synchronisation par exemple) ou des entite´s vers la station de base (pour retourner une
mesure prise par un capteur par exemple). Les algorithmes que j’ai propose´s peuvent
eˆtre optimise´s en fonction de ces caracte´ristiques plus pre´cises.
Les contraintes a` e´tudier, quelles qu’elles soient, doivent eˆtre conside´re´es dans toutes
les couches de communication, qu’il s’agisse de la conception au niveau signal, liaison
de donne´es ou routage. Tous les niveaux doivent conside´rer que les capteurs ont des
capacite´s limite´es en e´nergie et en taille me´moire, et non pas seulement la couche
re´seau. Tous ces de´fis rencontre´s dans de tels re´seaux ont e´te´ traite´s a` diffe´rents niveaux.
Les diffe´rentes propositions de protocoles de niveau physique cherchent a` minimiser
l’e´nergie de´pense´e en e´mission et en re´ception. Les protocoles de niveau MAC e´tudient
des re`gles d’endormissement des nœuds afin de ne faire travailler qu’un sous-ensemble
de capteurs a` la fois. Les protocoles de routage cherchent a` minimiser les inondations
de de´couverte et maintenance des routes et a` limiter le nombre de nœuds participant a`
ces diffusions. Cependant, toutes ces recherches d’optimisation restent inde´pendantes
les unes des autres et ne sont pas toujours compatibles. Par exemple, les protocoles de
routage peuvent avoir de´signe´ certains capteurs pour diffuser un message que la couche
MAC aura endormis. Dans ce cas, les messages ne seront pas relaye´s, ce qui peut avoir
de graves conse´quences suivant l’usage du re´seau de capteurs. De la meˆme fac¸on, la
couche la plus haute et la couche la plus basse ne peuvent eˆtre totalement de´corre´le´es,
les capteurs physiques devant re´pondre aux contraintes des applications.
Ainsi, chaque couche a besoin des informations des autres couches. Pour optimiser
au maximum les communications dans les re´seaux de capteurs, toutes ces couches ne
peuvent rester inde´pendantes les unes des autres et travailler seules. Il faudrait parvenir
a` supprimer ce de´coupage en couche et a` fusionner les qualite´s logicielles et mate´rielles
des capteurs. Le routage et les applications doivent pouvoir eˆtre de´termine´s en fonction
128 CHAPITRE 6. CONCLUSION ET PERSPECTIVES
des capacite´s physiques des capteurs et vice-versa. Les applications du re´seau de cap-
teurs doivent e´galement guider les fonctionnalite´s qui doivent apparaıˆtre aux niveaux
infe´rieurs. Ceci sera d’autant plus important quand on en viendra a` faire communi-
quer des objets he´te´roge`nes qui auront des fonctions de surveillance diffe´rentes dans
le re´seau. En effet, il faudra maintenir l’inter-ope´rabilite´ entre les composants et le bon
fonctionnement global du re´seau. Si toutes les couches sont fusionne´es, les diffe´rences
entre ces objets seront masque´es a` la vue des capteurs.
Bibliographie
[1] I. Abraham, D. Malkhi, and O. Dobzinski. LAND : Locality Aware Networks
for Distributed Hash Tables. In ACM-SIAM Symposium on Discrete Algorithms
(SODA’04), New Orleans, LA, USA, 2004.
[2] K. Alzoubi, P. Wan, and O. Frieder. New distributed algorithm for connected
dominating set in mobile ad hoc networks. In 35th Annual Hawaii International
Conference on System Sciences (HICSS’02), Hawaii, USA, January 2002.
[3] A. Amis and Prakash. Load-balancing clusters in wireless ad hoc networks. In
ASSET, Richardson, Texas, USA, March 2000.
[4] A. Amis, R. Prakash, T. Vuong, and D. Huynh. Max-Min d-cluster formation in
wireless ad hoc networks. In INFOCOM, Tel-Aviv, Israe¨l, March 2000. IEEE.
[5] B. An and S. Papavassiliou. A mobility-based clustering approach to support
mobility management and multicast routing in mobile Ad-hoc wireless networks.
International Journal of Network Management, 11(6) :387–395, November 2001.
[6] F. Araujo, L. Rodrigues, J. Kaiser, L. Changling, and C. Mitidieri. CHR : A Distri-
buted Hash Table for Wireless Ad Hoc Networks. In 4th International Workshop
on Distributed Event-based Systems (DEBS’05), Columbus, Ohio, USA, June
2005.
[7] E. Baccelli. OLSR trees : A simple clustering mechanism for OLSR. In MED-
HOC-NET 05, Porquerolles, France, June 2005.
[8] E. Baccelli and P. Jacquet. Flooding techniques in mobile Ad-Hoc networks.
Technical Report RR-5002, INRIA, 2003.
[9] F. Baccelli, B. Błaszczyszyn, and M. Karray. Up and downlink admis-
sion/congestion control and aximal load in large homogeneous CDMA networks.
In Proc. of WiOpt, Sophia Antipolis, France, 2003. to appear in MONET Special
Issue on Optimization of Wireless and Mobile Networks 10(2), April 2005.
[10] H. Balakrishnan, M. F. Kaashoek, D. Karger, R. Morris, and I. Stoica. Looking
up data in P2P systems. Communications of the ACM, 46(2) :43–48, February
2003.
[11] S. Banerjee and S. Khuller. A clustering scheme for hierarchical control in multi-
hop wireless networks. In INFOCOM, Anchorage, Alaska, USA, April 2001.
129
130 BIBLIOGRAPHIE
[12] S. Basagni. Distributed clustering for ad hoc networks. In International Sym-
posium on parallel architectures algorithms and networks (I-SPAN’99), pages
310–315, Fremantle, Australia, June 1999.
[13] P. Basu, N. Khan, and T. Little. A mobility based metric for clustering in mobile
ad hoc networks. In Distributed Computing Systems Workshop (DISC), 2001.
[14] D. Bertsekas and R. Gallager. Data Networks. Prentice-Hall, 1987.
[15] L. Blazevic, L. Buttyan, S. Capkun, S. Giordano, and J.-Y. Le Boudec. Self-
organization in mobile ad-hoc networks : the approach of Terminodes. IEEE
Communications Magazine, 39(6) :166–174, June 2001.
[16] L. Blazevic, S. Giordano, and J.-Y. Le Boudec. Self-organized Terminode rou-
ting. Journal of Cluster Computing, 5(2), April 2002.
[17] S. Capkun, M. Hamdi, and J.-P. Hubaux. GPS-free positioning in mobile ad-hoc
networks. In Proceedings of The 34th Hawaii International Conference on System
Sciences (HICSS-34), Maui, Hawaii, USA, January 2001.
[18] J. Cartigny. Contributions a` la diffusion dans les re´seaux ad hoc. PhD thesis,
LiFL, Lille, December 2003.
[19] J. Cartigny, F. Ingelrest, and D. Simplot-Ryl. RNG relay subset flooding protocol
in mobile ad-hoc networks. IJFCS, pages 253–265, 2003.
[20] M. Chatterjee, S. K. Das, and D. Turgut. WCA : A weight based distributed
clustering algorithm for mobile ad hoc networks. Journal of Cluster Computing
(Special Issue on Mobile Ad hoc Networks), 5(2) :193–204, April 2002.
[21] G. Chelius, E. Fleury, B. Sericola, and L. Toutain. On the NAP Protocol. Techni-
cal Report 5701, INRIA, 2005.
[22] B. Chen and R. Morris. L+ : Scalable landmark routing and address lookup for
multi-hop wireless networks. MIT LCS technical report 837, MIT, March 2002.
[23] G. Chen, F. Garcia, J. Solano, and I. Stojmenovic. Connectivity-based k-hop
clustering in wireless networks. In 35th Annual Hawaii International Conference
on System Sciences (HICSS’02), Hawaii, USA, January 2002.
[24] C. Chiang, H. Wu, W. Liu, and M. Gerla. Routing in clustered multihop, mobile
wireless networks with fading channel. In ICCS/ISPACS’96, Singapore, Novem-
ber 1996.
[25] T. Clausen, P. Jacquet, A. Laouiti, P. Muhlethaler, A. Qayyum, and L. Viennot.
Optimized Link State Routing Protocol, October 2003. RFC 3626.
[26] F. Dai and J. Wu. Distributed dominant pruning in ad hoc networks. In ICC’03,
Anchorage, Alaska, USA, May 2003.
[27] O. Dousse, F. Baccelli, and P. Thiran. Impact of interferences on the connectivity
of Ad Hoc networks. In Proc. of IEEE INFOCOM, San Francisco, USA, 2003. to
appear in IEEE Transactions on Networking.
[28] A. Ephremides, J. Wieselthier, and D. Baker. A design concept for reliable mobile
radio networks with frequency hoping signaling. In IEEE 75, pages 56–73, 1987.
[29] P. Erdo¨s and A. Renyi. On Random Graphs. Publicationes Mathematicae, 1959.
BIBLIOGRAPHIE 131
[30] J. Eriksson, M. Faloutsos, and S. Krishnamurthy. Scalable ad hoc routing : The
case for dynamic addressing. In INFOCOM, Hong Kong, China, March 2004.
[31] L. M. Feeney and M. Nilsson. Investigating the energy consumption of a wi-
reless network interface in an ad hoc networking environment. In INFOCOM,
Anchorage, Alaska, USA, April 2001.
[32] Y. Fernandess and D. Malkhi. k-clustering in wireless ad hoc networks. In ACM
international workshop on Principles of mobile computing, Toulouse, France,
2002.
[33] P. Fraigniaud and P. Gauron. An overview of the content-addressable network
D2B. In Proceedings of the 22nd ACM Symposium on Principles of Distributed
Computing (PODC’03). ACM, July 2003.
[34] M. R. Garey and D. S. Johnson. Computers and intractability : a guide to the
theory of NP-completeness. W.H. Freeman & Company, New York, 1979.
[35] M. Gerla and G. Pei. Fisheye State Routing Protocol (FSR). DRAFT draft-ietf-
manet-fsr-02.txt, IETF, December 2001.
[36] M. Gerla and J. T.-C. Tsai. Multicluster, mobile, multimedia radio network.
ACM/Baltzer Journal of Wireless Networks, 1(3) :255–265, July 1995.
[37] P. Gupta and P. Kumar. The capacity of wireless network. IEEE Trans. On
Information Theory, 46(2) :388–404, March 2000.
[38] T. Herman and S. Tixeuil. A distributed TDMA slot assignment for wireless
sensor networks. In Proceedings of the First Workshop on Algorithmic Aspects of
Wireless Sensor Networks (AlgoSensors’2004), number 3121 in Lecture Notes in
Computer Science, Turku, Finland, July 2004. Springer-Verlag.
[39] T.-C. Hou and T.-J. Tsai. An access-based clustering protocol for multihop wi-
reless ad hoc networks. IEEE Journal on Selected Areas in Communications,
19(7) :1201–1210, July 2001.
[40] P. Jacquet, A. Laouiti, P. Minet, and L. Viennot. Performance analysis of OLSR
multipoint relay flooding in two ad hoc wireless network models. Technical Re-
port RR-4260, INRIA, September 2001.
[41] P. Jacquet, A. Laouiti, P. Minet, and L. Viennot. Performance of multipoint re-
laying in ad hoc mobile routing protocols. In Networking, Pisa, Italy, 2002.
[42] M. Jiang, J. Li, and Y. Tay. Cluster Based Routing Protocol (CBRP). DRAFT
draft-ietf-manet-cbrp-spec-01.txt, IETF, July 1999.
[43] D. Johnson, D. A. Maltz, and Y.-C. Hu. Dynamic Source Routing (DSR), Fe-
bruary 2003.
[44] L. Kai and L. Jiandong. Mobile cluster protocol in wireless ad hoc networks. In
International Conference on Communication Technology (ICCT’2000) Procee-
dings, August 2000.
[45] P. Krishna, N. H. Vaidya, M. Chatterjee, and D. K. Pradhan. A cluster based
approach for routing in dynamic networks. In ACM SIGCOMM, pages 49–65.
ACM, April 1997.
132 BIBLIOGRAPHIE
[46] B.-J. Kwak, N.-O. Song, and L. Miller. On the scalability of ad hoc networks.
Communications Letters, IEEE, 8 :503– 505, 2004.
[47] T. J. K. Kwon and M. Gerla. Efficient flooding with passive clustering (PC) - an
overhead-free selective forward mechanism for ad hoc/sensor networks. Procee-
dings of IEEE, 91 :1210–1220, 2003.
[48] J. Li, R. Morris, J. Jannotti, D. S. Decouto, and D. R. Karger. A scalable location
service for geographic ad hoc routing. In Proceedings of the 6th ACM Internatio-
nal Conference on Mobile Computing and Networking (Mobicom’00), pages 120
– 130. ACM, August 2000.
[49] H. Lim and C. Kim. Multicast tree construction and flooding in wireless ad hoc
networks. In ACM MSWiM Workshop at MobiCom 2000, Boston, MA, USA,
August 2000.
[50] C. R. Lin and M. Gerla. Adaptive clustering for mobile wireless networks. IEEE
Journal of Selected Areas in Communications, 15(7) :1265–1275, 1997.
[51] H.-C. Lin and Y.-H. Chu. A clustering technique for large multihop mobile wi-
reless networks. In Vehicular Technology Conference (VTC’00), Tokyo, Japan,
May 2000.
[52] D. Malkhi, M. Naor, and D. Ratajczak. Viceroy : A scalable and dynamic emula-
tion of the butterfly. In Proceedings of the 21st ACM Symposium on Principles of
Distributed Computing (PODC’02), 2002.
[53] B. Mans and N. Shrestha. Performance evaluation of approximation algorithms
for multipoint relay selection. In The Third Annual Mediterranean Ad Hoc Net-
working Workshop, MED-HOC-NET 04, Bodrum, Turkey, June 2004.
[54] P. Maymounkov and D. Mazie`res. Kademlia : A peer-to-peer information system
based on the XOR metric. In Electronic Proceedings for the 1st International
Workshop on Peer-to-Peer Systems (IPTPS ’02), MIT Faculty Club, Cambridge,
MA, USA, March 2002.
[55] N. Mitton, E. Fleury, I. Gue´rin-Lassous, B. Se´ricola, and S. Tixeuil. On fast
randomized colorings in sensor networks. Research Report LRI-1416, LRI, June
2005.
[56] R. Morris, J. Jannotti, L. Jinyang, and D. S. J. Decouto. Carnet : A scalable ad
hoc wireless network system. In Proceedings of the 9th ACM SIGOPS European
Workshop : Beyond the PC : New challenges for the operating system, September
2000.
[57] E. T. Ng and H. Zhang. Predicting Internet network distance with coordinates-
based approaches. In INFOCOM, New-York, USA, June 2002.
[58] D. Niculescu and B. Nath. Ad hoc positioning system (APS). In Proceedings of
GLOBECOM’01, November 2001.
[59] N. Nikaein, H. Labiod, and C. Bonnet. DDR-distributed dynamic routing algo-
rithm for mobile ad hoc networks. In MobiHoc, Boston, MA, USA, November,
20th 2000.
BIBLIOGRAPHIE 133
[60] T. Ohta, S. Inoue, and Y. Kakuda. An adaptive multihop clustering scheme for
highly mobile ad hoc networks. In IEEE International Symposium on Autono-
mous Decentralized Systems (ISADS’03), pages 293–300, April 2003.
[61] C. Perkins. Ad hoc networking. Addison-Wesley, 2001.
[62] C. Perkins, E. Belding-Royer, and S. Das. Ad hoc On-demand Distance Vector
Routing, July 2003. RFC 3561.
[63] J. Polastre, R. Szewczyk, and D. Culler. Telos : Enabling ultra-low power wireless
research. In IPSN/SPOTS’05, Los Angeles, CA, USA, April 2005.
[64] H. Pucha, S. M. Das, and Y. C. Hu. Ekta : An efficient DHT substrate for dis-
tributed applications in mobile ad hoc networks. In WMCSA, pages 163–173,
2004.
[65] A. Qayyum, L. Viennot, and A. Laouiti. Multipoint relaying : An efficient tech-
nique for flooding in mobile wireless networks. In HICSS’02, Hawaii, USA,
January 2002.
[66] R. Rajaraman. Topology control and routing in ad hoc networks : a survey. ACM
SIGACT News, 33(2) :60–73, June 2002.
[67] A. Ramalingam, S. Subramani, and K. Perumalsamy. Associativity-based clus-
ter formation and cluster management in ad hoc networks. In 9th International
conference on high performance computing (HiPC’02), Bangalore, India, De-
cember 2002.
[68] S. Ratnasamy, P. Francis, M. Handley, R. Karp, and S. Schenker. A scalable
content-addressable network. In Proceedings of the 2001 conference on applica-
tions, technologies, architectures, and protocols for computer communications,
pages 161–172. ACM Press, 2001.
[69] R. Riedi, P. Druschel, Y. C. Hu, D. B. Johnson, and R. Baraniuk. SAFARI : A self-
organizing hierarchical architecture for scalable ad hoc networking networking.
Research report TR04-433, Rice University, February 2005.
[70] A. Rowstron and P. Druschel. Pastry : Scalable, distributed object location
and routing for large-scale peer-to-peer systems. In Proceedings of the 18th
IFIP/ACM International Conference on Distributed Systems Platforms (Middle-
ware 2001), Heidelberg, Germany, November 2001.
[71] C. Santivanez, B. McDonald, I. Stavrakakis, and R. R. Ramanathan. On the sca-
lability of ad hoc routing protocols. In INFOCOM, New-York, USA, June 2002.
[72] N. Santoro and R. Khatib. Labeling and implicit routing in networks. The com-
puter Journal, 28 :5–8, 1985.
[73] I. Stoica, R. Morris, D. Karger, M. F. Kaashoek, and H. Balakrishnan. Chord : A
scalable peer-to-peer lookup service for Internet applications. In Proceedings of
the 2001 conference on applications, technologies, architectures, and protocols
for computer communications (Sigcomm’01), pages 149–160. ACM Press, 2001.
[74] I. Stojmenovic, M. Seddigh, and J. Zunic. Dominating sets and neighbor
elimination-based broadcasting algorithms in wireless networks. IEEE TPDS,
13(1), January 2002.
134 BIBLIOGRAPHIE
[75] I. Stojmenovic and J. Wu. Broadcasting and activity scheduling in ad hoc net-
works. IEEE Mobile Ad Hoc Networking, pages 205–229, 2004.
[76] D. Stoyan, S. Kendall, and J. Mecke. Stochastic geometry and its applications,
second edition. John Wiley & Sons, 1995.
[77] J. Van Leeuven and R. Tan. Interval routing. The computer Journal, 30 :298–307,
1987.
[78] A. C. Viana, M. Dias de Armorim, S. Fdida, and J. Ferreira de Rezende. Indirect
routing using distributed location information. In PERCOM ’03 : Proceedings of
the First IEEE International Conference on Pervasive Computing and Communi-
cations, page 224, Washington, DC, USA, 2003. IEEE Computer Society.
[79] A. C. Viana, M. Dias de Armorim, S. Fdida, and J. Ferreira de Rezende. Self-
organization in spontaneous networks : the approach of DHT-based routing pro-
tocols. Ad Hoc Networks Journal, 2005.
[80] J. Wu and H. Li. A dominating set based routing scheme in ad hoc wireless
networks. Telecommunication Systems, pages 13–36, 2001.
[81] J. Wu and W. Lou. Forward node set based broadcast in clustered mobile ad
hoc networks. Wireless Communications and Mobile Computing, 3(2) :141–154,
2003.
[82] J. Y. Yu and P. H. Chong. 3hBAC (3-hop between adjacent clusterheads) : A novel
non-overlapping clustering algorithm for mobile ad hoc networks. In PacRim’03,
Victoria, Canada, August 2003.
[83] H. Zhai, Y. Kwon, and Y. Fang. Performance analysis of IEEE 802.11 MAC
Protocols in wireless LANs. Wireless communications and mobile computing,
4 :917–931, 2004.
[84] B. Y. Zhao, L. Huang, J. Stribling, S. C. Rhea, A. D. Joseph, and J. Kubiatowicz.
Tapestry : A resilient global-scale overlay for service deployment. IEEE Journal
on Selected Areas in Communications, 22(1), January 2004.
